{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7장 로지스틱 회귀를 이용한 분류\n",
    "\n",
    "자료 출처: [ISLP (An Introduction to Statistical Learning with Applications in Python)](https://www.statlearning.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 배운 선형 회귀 모델에서는 종속변수 또는 반응변수(response variable) $Y$가 정량적(quantitative)이지만, 많은 상황에서 반응변수는 **정성적**(qualitative)이다. 정성적 변수를 범주형(categorical)이라고도 한다.\n",
    "\n",
    "정성적 반응에 대한 추정 및 예측을 **분류**(classification)라고 부른다. 가령 스팸 메일 예를 생각해보자. 이 경우 정성적 반응을 예측하는 것은 메일이 스팸인지 햄인지 예측하는 것으로서 관측을 어떤 범주나 등급에 할당하는 것이기 때문에 분류로 지칭될 수 있다.\n",
    "\n",
    "분류 기법에는 여러가지 있다. 로지스틱 회귀(logistic regression), 선형판별 분석(linear discriminant analysis), K-최근접이웃(K-nearest neighbors) 등이 널리 사용되는 분류 기법이다. 또한 일반가산 모델(generalized additive model), 트리(tree), 랜덤 포레스트(random forest), 부스팅(boosting), 서포트 벡터 머신(support vector machine) 등 컴퓨팅 집약적인 방법도 사용된다. 본 장에서는 이 중에서 로지스틱 회귀를 다룬다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 문제 예\n",
    "\n",
    "- 온라인 뱅킹 서비스는 사용자의 IP 주소, 과거 거래 내역 등을 기반으로 어떤 사이트에서 수행중인 거래가 **금융사기**인지 여부를 파악할 수 있어야 한다.\n",
    "\n",
    "\n",
    "- 생물학자는 여러 환자에 대한 DNA 염기 서열 데이터를 바탕으로 어떤 DNA 변이가 **해로운지**(질병을 유발하는지), 그렇지 않은지를 파악하려고 한다.\n",
    "\n",
    "\n",
    "- 어떤 사람이 **세 가지 질환** 중 하나에 기인할 수 있는 일련의 증상을 가지고 응급실에 도착한다. 이 사람은 세 가지 질환 중 어떤 것에 속하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default 데이터세트 사례\n",
    "\n",
    "ISLP에서 제공하는 \"Default.csv\" 데이터세트를 불러들인다. 우리는 이 데이터를 사용해 사람들이 신용카드 결제에서 디폴트(`default`: 채무불이행 또는 연체)가 발생할지 예측하는 데 관심이 있다. **시뮬레이션** 데이터세트이며, 예측변수로는 개인들의 연간 소득(`income`)과 월간 신용카드 사용액(`balance`) 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "pd.set_option(\"display.precision\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526</td>\n",
       "      <td>44361.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180</td>\n",
       "      <td>12106.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549</td>\n",
       "      <td>31767.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.251</td>\n",
       "      <td>35704.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.656</td>\n",
       "      <td>38463.496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student   balance     income\n",
       "0      No      No   729.526  44361.625\n",
       "1      No     Yes   817.180  12106.135\n",
       "2      No      No  1073.549  31767.139\n",
       "3      No      No   529.251  35704.494\n",
       "4      No      No   785.656  38463.496"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/Default.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default 데이터세트 변수**\n",
    "\n",
    "- `default`: 채무불이행 여부(`Yes`/`No`)\n",
    "- `student`: 학생 여부(`Yes`/`No`)\n",
    "- `balance`: 월간 신용카드 사용액\n",
    "- `income`: 연간 소득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9667</td>\n",
       "      <td>7056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>835.375</td>\n",
       "      <td>33516.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>483.715</td>\n",
       "      <td>13336.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>771.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>481.731</td>\n",
       "      <td>21340.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>823.637</td>\n",
       "      <td>34552.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1166.308</td>\n",
       "      <td>43807.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2654.323</td>\n",
       "      <td>73554.233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       default student    balance     income\n",
       "count    10000   10000  10000.000  10000.000\n",
       "unique       2       2        NaN        NaN\n",
       "top         No      No        NaN        NaN\n",
       "freq      9667    7056        NaN        NaN\n",
       "mean       NaN     NaN    835.375  33516.982\n",
       "std        NaN     NaN    483.715  13336.640\n",
       "min        NaN     NaN      0.000    771.968\n",
       "25%        NaN     NaN    481.731  21340.463\n",
       "50%        NaN     NaN    823.637  34552.645\n",
       "75%        NaN     NaN   1166.308  43807.729\n",
       "max        NaN     NaN   2654.323  73554.233"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default 데이터세트 시각적 분석**\n",
    "\n",
    "아래 그림 7.1은 `income`(연간 소득)과 `balance`(카드 사용액)에 대해 디폴트가 발생한 그룹과 그렇지 않은 그룹을 구별하여 산점도 및 상자그림(boxplot)을 그린 것이다. 왼쪽 그림에서 오렌지색은 디폴트인 경우이고 파란색은 그렇지 않은 경우를 나타낸다.(전체 데이터에서 디폴트 비율이 약 3%로 너무 적어서 채무를 이행한 사람들은 전체가 아니라 일부만 표시한 것임) 디폴트인 경우가 그렇지 않은 경우에 비해 카드 사용액이 더 많은 경향이 있는 것을 알 수 있다. 그림 오른쪽의 상자그림에서 첫 번째는 디폴트 그룹과 디폴트가 아닌 그룹 각각에 대해 `balance`의 분포를 보여주고, 두 번째는 `income`의 분포를 보여준다. `balance`의 경우에는 두 그룹의 차이가 크지만, `income`의 경우에는 두 그룹 간에 큰 차이가 없는 것을 알 수 있다. \n",
    "\n",
    "**그림 7.1.** Default 데이터세트. `income`과 `balance`에 대해 디폴트 여부별로 산점도 및 상자그림을 그린 것이다.\n",
    "\n",
    "![Default 데이터세트](https://raw.githubusercontent.com/pilsunchoi/images/main/7-1.png)\n",
    "\n",
    "- 그림 출처: ISLP, FIGURE 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default 데이터세트에서 우리의 관심은 신용카드 사용자들의 디폴트(채무불이행) 여부를 잘 예측하는 것이다. `default` 변수가 Yes/No의 범주형 변수이기 때문에 회귀 분석을 위해서는 이를 **더미 변수**(dummy variable)로 바꿔야 한다. `default` 변수값이 Yes인 경우 1, No인 경우 0의 값을 부여해 이를 반응변수 $Y$라 하자. \n",
    "\n",
    "$$\n",
    "Y=\n",
    "\\begin{cases}\n",
    "0, & \\text{if default=No} \\\\[2ex]\n",
    "1, & \\text{if default=Yes} \\\\[2ex]\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "위와 같은 이항(binary) 반응의 경우, 앞에서 배운 **선형 회귀 모델로 추정하는 것도 나름대로 의미**가 있다. 선형 회귀를 사용하여 얻은 **적합값 $ \\hat Y = X \\hat\\beta$을 채무불이행의 확률**, 즉 $\\Pr(Y=1)$에 대한 추정값으로 해석하는 것이다. 이 경우 $Y$, 즉 채무이행 여부에 대한 예측 작업도 수행할 수 있는데, $\\hat Y >0$.5이면 채무불이행, 그렇지 않으면 채무이행으로 예측할 수 있다. \n",
    "\n",
    "그러나 선형 회귀를 사용하는 경우, 아래 그림 7.2의 왼쪽 그림에서 보듯이 일부 추정치가 0과 1 사이의 범위를 벗어나는 문제가 발생한다.(추정선이 수평선이 아닌 한, 0과 1 사이의 범위를 벗어나는 구간이 발생할 것이다.) 즉, 확률이 마이너스가 되거나 1보다 큰 경우가 발생할 수 있다. \n",
    "\n",
    "이런 경우를 없애고 아래 그림 7.2의 오른쪽 그림과 같이 되도록 모델을 설정한 것이 **로지스틱 모델**이다. 로지스틱 회귀의 경우, 아래 그림에서 보듯이 `balance` 값이 낮은 수준일 때, 디폴트 확률이 0에 가깝지만 절대 0보다 낮게 예측되지는 않는다. 또한 `balance` 값이 높은 경우, 디폴트 확률이 1에 가까울 수 있지만 그보다 높게 예측되지는 않는다. \n",
    "\n",
    "**그림 7.2.** Default 데이터 분류. 양쪽 그림에서 0과 1의 수평 점선 상에 표시된 오렌지색 눈금 표시들은 각 관측들의 디폴트 여부(No 또는 Yes)를 의미하는 0과 1의 값이다. 왼쪽 패널에서 파란색 직선은 선형 회귀를 사용하여 추정된 디폴트 확률로서 일부 추정 확률이 음수이다! 오른쪽 패널에서 파란색 곡선은 로지스틱 회귀를 사용하여 추정된 디폴트 확률로서 모든 확률은 0과 1 사이에 있다.\n",
    "\n",
    "![Default 데이터 분류](https://raw.githubusercontent.com/pilsunchoi/images/main/7-2.png)\n",
    "\n",
    "- 그림 출처: ISLP, FIGURE 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀\n",
    "\n",
    "`Default` 데이터세트에서 반응변수 $Y$는 0(채무이행)과 1(채무불이행)의 값을 갖는 범주형 변수이다. 로지스틱 회귀 분석은 $Y$를 직접 모델링하는 대신 $Y$가 **1의 범주에 속할 확률을 모델링**한다.\n",
    "\n",
    "디폴트 확률을 예측하는 예측변수로 `balance`(카드 사용액) 변수 하나만 생각해보자. `balance`가 주어졌을 때의 디폴트 확률을 $\\Pr⁡(Y=1 \\mid \\text{balance})$로 표현할 수 있다. 이를 간단히 $p⁡(\\text{balance})$로 표기하기로 한다. 이 값은 확률이므로 0과 1 사이이다. 추정 후 `balance` 값이 주어지면 디폴트 여부를 예측할 수 있다. 예를 들어, $p⁡(\\text{balance})>0.5$이면, $Y=1$로 예측하는 식이다. 만약 디폴트 위험을 보수적으로 예측하기를 원하는 경우에는 가령 $p(\\text{balance})>0.1$ 등 더 낮은 분계점(threshold)을 선택할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서도 설명했듯이 0 또는 1로 코딩된 이항 반응을 **직선으로 피팅**하는 경우, ($X$값에 제한이 있지 않는 한) 기본적으로 $X$의 일부 값에 대해 $p(x)<0$을 예측하고, 또 다른 값에 대해서는 $p(x)>1$을 예측할 가능성이 발생한다. 이 문제를 피하기 위해서는 이항 반응을 직선 함수로 피팅하는 대신 항상 0과 1 사이의 값을 갖도록 하는 함수로 피팅시키면 된다. 아래 그림 7.3과 같은 모양을 가진 **로지스틱 함수**(logistic function)를 사용한 것이 바로 로지스틱 모델이다.\n",
    "\n",
    "**그림 7.3.** 로지스틱 함수.\n",
    "\n",
    "![로지스틱 함수](https://raw.githubusercontent.com/pilsunchoi/images/main/7-3.png)\n",
    "\n",
    "- 그림 출처: Wikipedia, \"[Logistic function](https://en.wikipedia.org/wiki/Logistic_function)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 함수를 식으로 표현하면 다음과 같다.\n",
    "\n",
    "$$\n",
    "f(x) = \\frac {1}{1+e^{-x}}~~또는~~\\frac {e^{x}}{1+e^{x}}\n",
    "$$\n",
    "\n",
    "위 식의 $x$에 어떤 값을 집어 넣든 $f(x)$는 0과 1 사이의 범위를 벗어나지 않는다. 따라서 위 식의 $x$에 예측변수의 선형결합(linear combination)인 $\\beta_0 + \\beta_1 X$를 대입한 것이 로지스틱 회귀 모델로서 다음과 같다.\n",
    "\n",
    "$$\n",
    "p(X) = \\frac {e^{\\beta_0 + \\beta_1 X}}{1+e^{\\beta_0 + \\beta_1 X}} \\tag{7.1}\n",
    "$$\n",
    "\n",
    "앞에서 로지스틱 회귀 분석은 $Y$를 직접 모델링하는 대신 $Y$가 1의 범주에 속할 확률을 모델링한다고 언급했는데, 식 7.1에서 그 의미를 알 수 있을 것이다. 좌변이 $Y$가 아니라 $p(X)$, 즉 $\\Pr⁡(Y=1 \\mid X)$이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식 7.1을 약간 변형하면 다음과 같이 된다.\n",
    "\n",
    "$$\n",
    "{\\rm ln}\\left(\\frac {p(X)}{1−p(X)}\\right) =\\beta_0 + \\beta_1 X  \\tag{7.2}\n",
    "$$\n",
    "\n",
    "선형 회귀 모형에서 $\\beta_1$은 $X$가 1단위 증가시 $Y$의 평균적 변화이다. 하지만 식 7.1과 7.2에서 알 수 있듯이 로지스틱 모형에서는 $p(X)$와 $X$의 관계가 직선이 아니기 때문에 $\\beta_1$은 $X$의 $p(X)$에 대한 한계효과(marginal effect)에 해당하지 않는다. 식 7.2의 좌변은 **log-odds** 또는 **logit**으로 불리며, 이에 따라 로지스틱 모델을 **로짓(logit)** 모델이라고도 부른다. \n",
    "\n",
    "위 식 7.1에서 알 수 있듯이 로지스틱 회귀 모델에서 $X$의 $p(X)$에 대한 한계효과는 $X$의 현재 값에 따라 달라지는 등 선형 회귀와는 다르다. 그러나 어찌됐든 $\\beta_1$이 플러스이면 $X$ 증가시 $p(X)$가 높아지고, $\\beta_1$이 마이너스이면 $X$ 증가시 $p(X)$가 낮아진다는 사실은 선형 회귀와 동일하다. 반면 $p(X)$와 $X$ 사이에 직선 관계가 없으며, $X$의 단위 변화 당 $p(X)$의 변화가 $X$값이 무엇이냐에 따라 달라진다는 점은 선형 회귀와 다른 점이다. 이는 앞 그림 7.2의 오른쪽 패널에서도 시각적으로 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최대가능도 추정\n",
    "\n",
    "선형 회귀 모형은 OLS(통상최소제곱) 방법으로 미지의 선형 회귀 계수를 추정한다. 이에 반해 로지스틱 회귀 모델은 **최대가능도**(maximum likelihood) 방법으로 추정하는데, 기본 직관은 다음과 같다. 앞의 로지스틱 회귀 모델 식을 사용하여 각 카드 사용자에 대해 디폴트 확률을 추정하게 되는데, 그 추정 확률 $\\hat p(x_i)$을 실제 관측된 디폴트 여부와 가능한 한 가깝게 $\\beta_0$ 및 $\\beta_1$에 대한 추정치를 구하는 것이다. 다시 말해, $p(X)$ 모형에 $\\hat \\beta_0$ 및 $\\hat \\beta_1$을 집어 넣었을 때, 디폴트가 발생한 모든 카드 사용자에 대해서는 가능한 한 1에 가까운 숫자가 나오게 하고, 그렇지 않은 모든 카드 사용자에게는 가능한 한 0에 가까운 숫자가 나오게 하도록 하려는 것이다.\n",
    "\n",
    "이 직관은 **가능도함수**(likelihood function)라는 다음의 식을 최대화하는 $\\hat \\beta_0$ 및 $\\hat \\beta_1$을 선택하는 것을 의미한다.\n",
    "\n",
    "$$\n",
    "l(\\beta_0,\\beta_1)=\\mathop{\\prod}_{y_i=1} p(x_i) \\mathop{\\prod}_{y_i=0} (1-p(x_i))\n",
    "$$\n",
    "\n",
    "최대가능도는 **비선형** 모델에 적합한 방법이며, 매우 광범위하게 사용되는 접근 방식이다. 선형 회귀 모형의 최소제곱 접근은 최대가능도 방법의 특별한 경우에 해당한다. 최대가능도 추정은 파이썬이나 R과 같은 통계 소프트웨어 패키지를 사용하여 쉽게 실행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 회귀 vs 로지스틱 회귀 예시\n",
    "\n",
    "먼저 예시적으로 간단한 `x`, `y` 데이터를 만들어 `data`라는 데이터프레임으로 지정한다. 그런 다음 산점도를 그린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  0  0\n",
       "1  1  0\n",
       "2  2  0\n",
       "3  3  0\n",
       "4  4  0\n",
       "5  5  1\n",
       "6  6  1\n",
       "7  7  0\n",
       "8  8  1\n",
       "9  9  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "        'y': [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]}\n",
    "data = pd.DataFrame(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAE6CAYAAACWDhLFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjZUlEQVR4nO3dfVRVdaLG8efIyzm+wClBURIR00kSTYUyQO1WEy4t13Bv18y6vjTVihuOgo1LyblaThN3mJXasgtGb469GKusxpnrbTjTjK84o3LVMXRNL2qQQgjNcPBlUGHfP1qe2xngFyC6D/L9rLX/4Hf2Pvs5G/Xxt8/e5zgsy7IEAABa1MPuAAAABDKKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihK4RH/605/0z//8zxo8eLCcTqeioqKUnJysJ5544rLts6SkRE899ZT+9re/NXssPz9f69atu2z7bsk//dM/yeFw+JaePXvqpptu0urVq9XU1ORbb+7cuRoyZEiH9mHH6wIkihK4JP/93/+tlJQUeb1e5eXlqbi4WM8//7xSU1NVVFR02fZbUlKip59+OmCKUpKGDh2qXbt2adeuXSoqKtJ1112n7Oxs5eTkdMrzU5SwS7DdAYCuLC8vT3Fxcfrtb3+r4OD//+t0//33Ky8vz8ZkncuyLP39739Xz549W12nZ8+euvXWW30/T5kyRSNGjNALL7ygZ555RiEhIVciKtDpmFECl6C2tlaRkZF+JXlRjx7N/3q99dZbSk5OVp8+fdSnTx+NGTNGr7zyiu9xj8ejH/zgBxo0aJBcLpeGDRumxx57TDU1Nb51nnrqKS1atEiSFBcX5zvduWXLFg0ZMkRlZWXaunWrb/zbpzq9Xq9+/OMfKy4uTqGhobruuuuUlZWl06dP++V0OByaN2+e1q5dq/j4eDmdTv3yl79s17EJCQlRYmKizpw5o5MnT7a63t///nfl5OT4ZcrMzPSbLX/X6wIuJ2aUwCVITk7Wyy+/rPnz5+vBBx/UuHHjWp05LVu2TD/96U/1L//yL3riiSfkdrv18ccf64svvvCt8/nnnys5OVmPPPKI3G63jh07ppUrV2rChAk6ePCgQkJC9Mgjj+jrr7/WmjVr9N5772ngwIGSpBtvvFHvv/++/vVf/1Vut1v5+fmSJKfTKUk6c+aMbrvtNn355Zd68sknNXr0aJWVlWnZsmU6ePCgfve738nhcPiyfPDBB9q+fbuWLVumAQMGqH///u0+Pp9//rmCg4N17bXXtvi4ZVlKT0/XRx99pJycHE2cOFF//vOftXz5ct9pXKfTaXxdwGVnAeiwmpoaa8KECZYkS5IVEhJipaSkWLm5uVZ9fb1vvSNHjlhBQUHWgw8+2Obnbmpqss6fP2998cUXliTrV7/6le+xX/ziF5Yk6+jRo822GzlypHXbbbc1G8/NzbV69Ohh7dmzx2/83XfftSRZmzdv9o1Jstxut/X111+3Kettt91mjRw50jp//rx1/vx568SJE9aSJUssSdb06dN9682ZM8eKjY31/fzhhx9akqy8vDy/5ysqKrIkWYWFhd/5uoDLjVOvwCWIiIjQ9u3btWfPHv3nf/6nfvCDH+iTTz5RTk6ORo0a5Ttl6vF41NjYqMzMTOPzVVdXKyMjQzExMQoODlZISIhiY2MlSYcPH76krL/5zW+UkJCgMWPG6MKFC75l8uTJvlO333bHHXe0OhNsSVlZmUJCQhQSEqLo6Gg999xzevDBB/XSSy+1us3vf/97Sd9cDftt06dPV+/evfXRRx+1ef/A5cKpV6ATJCUlKSkpSZJ0/vx5LV68WKtWrVJeXp7y8vJ879ENGjSo1edoampSWlqaTpw4of/4j//QqFGj1Lt3bzU1NenWW2/V2bNnLynjV199pc8++6zVU8Pffh9Uku+Ubltdf/31evvtt+VwOORyuRQXF6devXoZt6mtrVVwcLD69evnN+5wODRgwADV1ta2KwNwOVCUQCcLCQnR8uXLtWrVKn388ceS5CuCL7/8UjExMS1u9/HHH+vAgQNat26d5syZ4xv/7LPPOiVXZGSkevbsqVdffbXVx7/t2+9XtoXL5fL9Z6GtIiIidOHCBZ08edKvLC3LUlVVlW6++eZ2PR9wOXDqFbgElZWVLY5fPE0aHR0tSUpLS1NQUJAKCgpafa6LxfSPF6m8+OKLzda9uE5Ls0yn09ni+D333KPPP/9cERERvhnwtxc7riK98847JUlvvPGG3/jGjRt1+vRp3+NS668LuNyYUQKXYPLkyRo0aJCmTZumESNGqKmpSfv379dzzz2nPn36aMGCBZK+ub3hySef1E9/+lOdPXtWM2fOlNvt1qFDh1RTU6Onn35aI0aM0PXXX68lS5bIsiz17dtXv/71r+XxeJrtd9SoUZKk559/XnPmzFFISIhuuOEGhYWFadSoUXr77bdVVFSkoUOHyuVyadSoUcrKytLGjRs1adIkZWdna/To0WpqalJ5ebmKi4v1xBNPaPz48Vf0+N11112aPHmyFi9eLK/Xq9TUVN9Vr2PHjtWsWbP8XnNLrwu47Oy+mgjoyoqKiqwHHnjAGj58uNWnTx8rJCTEGjx4sDVr1izr0KFDzdZfv369dfPNN1sul8vq06ePNXbsWOu1117zPX7o0CHrrrvussLCwqxrr73Wmj59ulVeXm5JspYvX+73XDk5OVZ0dLTVo0cPS5L1hz/8wbIsyzp27JiVlpZmhYWFWZL8rjI9deqU9ZOf/MS64YYbrNDQUMvtdlujRo2ysrOzraqqKt96kqzMzMw2H4eLV71+l3+86tWyLOvs2bPW4sWLrdjYWCskJMQaOHCg9e///u/WX//6V7/1TK8LuJwclmVZtjY1AAABjPcoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCgKAEAMOh2HzjQ1NSkEydOKCwsrN0f0QUAuHpYlqX6+npFR0e3+P2xF3W7ojxx4kSrn7UJAOh+KioqjF9Y0O2KMiwsTNI3ByY8PNzmNAAAu3i9XsXExPh6oTXdrigvnm4NDw+nKAEA3/k2HBfzAABgQFECAGBAUQIAYGBrUW7btk3Tpk1TdHS0HA6HPvjgg+/cZuvWrUpMTJTL5dLQoUO1du3ayx8UgNGRk6f0h79U62jNabujNBPI2QJZIB+3K53N1ot5Tp8+rZtuukkPPfSQ7r333u9c/+jRo5o6daoeffRRvfHGG9q5c6cef/xx9evXr03bA+hcfztzTvM37Ne2T0/6xiYN76c1M8fK3SvExmSBnS2QBfJxsytbwHwfpcPh0Pvvv6/09PRW11m8eLE2bdqkw4cP+8YyMjJ04MAB7dq1q0378Xq9crvdqqur46pX4BLNfmW3dn5Wo8Zv/TMS5HAodVik1j98i43JAjtbIAvk49bZ2draB13qPcpdu3YpLS3Nb2zy5Mnau3evzp8/3+I2DQ0N8nq9fguAS3fk5Clt+/Sk3z9aktRoWdr26UlbT9kFcrZAFsjHzc5sXaooq6qqFBUV5TcWFRWlCxcuqKampsVtcnNz5Xa7fQufygN0ji++PmN8/Fitff+oBnK2QBbIx83ObF2qKKXmN4ZePHPc2g2jOTk5qqur8y0VFRWXPSPQHcT27WV8fEhE7yuUpLlAzhbIAvm42ZmtSxXlgAEDVFVV5TdWXV2t4OBgRUREtLiN0+n0fQoPn8YDdJ6h/fpo0vB+CvqH/6QGORyaNLyf4iLt+0c1kLMFskA+bnZm61JFmZycLI/H4zdWXFyspKQkhYRwFRtwpa2ZOVapwyL9xlKHRWrNzLE2Jfp/gZwtkAXycbMrm61XvZ46dUqfffaZJGns2LFauXKlbr/9dvXt21eDBw9WTk6Ojh8/rvXr10v65vaQhIQEPfbYY3r00Ue1a9cuZWRkaMOGDW2+PYSrXoHOd7TmtI7VntaQiN4BN1sL5GyBLJCPW2dla2sf2FqUW7Zs0e23395sfM6cOVq3bp3mzp2rY8eOacuWLb7Htm7dquzsbJWVlSk6OlqLFy9WRkZGm/dJUQIApC5SlHagKAEA0lV6HyUAAFcaRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAICB7UWZn5+vuLg4uVwuJSYmavv27cb133zzTd10003q1auXBg4cqIceeki1tbVXKC0AoLuxtSiLioqUlZWlpUuXat++fZo4caKmTJmi8vLyFtffsWOHZs+erYcfflhlZWV65513tGfPHj3yyCNXODkAoLuwtShXrlyphx9+WI888oji4+O1evVqxcTEqKCgoMX1//jHP2rIkCGaP3++4uLiNGHCBD322GPau3fvFU4OAOgubCvKc+fOqbS0VGlpaX7jaWlpKikpaXGblJQUffnll9q8ebMsy9JXX32ld999V3fffXer+2loaJDX6/VbAABoK9uKsqamRo2NjYqKivIbj4qKUlVVVYvbpKSk6M0339SMGTMUGhqqAQMG6JprrtGaNWta3U9ubq7cbrdviYmJ6dTXAQC4utl+MY/D4fD72bKsZmMXHTp0SPPnz9eyZctUWlqqDz/8UEePHlVGRkarz5+Tk6O6ujrfUlFR0an5AQBXt2C7dhwZGamgoKBms8fq6upms8yLcnNzlZqaqkWLFkmSRo8erd69e2vixIl65plnNHDgwGbbOJ1OOZ3Ozn8BAIBuwbYZZWhoqBITE+XxePzGPR6PUlJSWtzmzJkz6tHDP3JQUJCkb2aiAAB0NltPvS5cuFAvv/yyXn31VR0+fFjZ2dkqLy/3nUrNycnR7NmzfetPmzZN7733ngoKCnTkyBHt3LlT8+fP1y233KLo6Gi7XgYA4Cpm26lXSZoxY4Zqa2u1YsUKVVZWKiEhQZs3b1ZsbKwkqbKy0u+eyrlz56q+vl4vvPCCnnjiCV1zzTW644479POf/9yulwAAuMo5rG52ztLr9crtdquurk7h4eF2xwEA2KStfWD7Va8AAAQyihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAAD24syPz9fcXFxcrlcSkxM1Pbt243rNzQ0aOnSpYqNjZXT6dT111+vV1999QqlBQB0N8F27ryoqEhZWVnKz89XamqqXnzxRU2ZMkWHDh3S4MGDW9zmvvvu01dffaVXXnlFw4YNU3V1tS5cuHCFkwMAuguHZVmWXTsfP368xo0bp4KCAt9YfHy80tPTlZub22z9Dz/8UPfff7+OHDmivn37dmifXq9XbrdbdXV1Cg8P73B2AEDX1tY+sO3U67lz51RaWqq0tDS/8bS0NJWUlLS4zaZNm5SUlKS8vDxdd911+t73vqcf//jHOnv2bKv7aWhokNfr9VsAAGgr20691tTUqLGxUVFRUX7jUVFRqqqqanGbI0eOaMeOHXK5XHr//fdVU1Ojxx9/XF9//XWr71Pm5ubq6aef7vT8AIDuwfaLeRwOh9/PlmU1G7uoqalJDodDb775pm655RZNnTpVK1eu1Lp161qdVebk5Kiurs63VFRUdPprAABcvWybUUZGRiooKKjZ7LG6urrZLPOigQMH6rrrrpPb7faNxcfHy7Isffnllxo+fHizbZxOp5xOZ+eGBwB0G7bNKENDQ5WYmCiPx+M37vF4lJKS0uI2qampOnHihE6dOuUb++STT9SjRw8NGjTosuYFAHRPtp56XbhwoV5++WW9+uqrOnz4sLKzs1VeXq6MjAxJ35w2nT17tm/9Bx54QBEREXrooYd06NAhbdu2TYsWLdIPf/hD9ezZ066XAQC4itl6H+WMGTNUW1urFStWqLKyUgkJCdq8ebNiY2MlSZWVlSovL/et36dPH3k8Hv3oRz9SUlKSIiIidN999+mZZ56x6yUAAK5ytt5HaQfuowQASF3gPkoAALoCihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAA4oSAAADihIAAAOKEgAAg3YX5dy5c7Vt27bLkQUAgIDT7qKsr69XWlqahg8frmeffVbHjx+/HLkAAAgI7S7KjRs36vjx45o3b57eeecdDRkyRFOmTNG7776r8+fPX46MAADYpkPvUUZERGjBggXat2+fdu/erWHDhmnWrFmKjo5Wdna2Pv30087OCQCALS7pYp7KykoVFxeruLhYQUFBmjp1qsrKynTjjTdq1apVnZURAADbtLsoz58/r40bN+qee+5RbGys3nnnHWVnZ6uyslK//OUvVVxcrNdff10rVqy4HHkBALiigtu7wcCBA9XU1KSZM2dq9+7dGjNmTLN1Jk+erGuuuaYT4gEAYK92F+WqVas0ffp0uVyuVte59tprdfTo0UsKBgBAIGh3Uc6aNety5AAAICDxyTwAABhQlAAAGFCUAAAYUJQAABhQlAAAGFCUAAAYUJQAABhQlAAAGFCUAAAYUJQAABjYXpT5+fmKi4uTy+VSYmKitm/f3qbtdu7cqeDg4BY/lB0AgM5ia1EWFRUpKytLS5cu1b59+zRx4kRNmTJF5eXlxu3q6uo0e/Zs3XnnnVcoKQCgu3JYlmXZtfPx48dr3LhxKigo8I3Fx8crPT1dubm5rW53//33a/jw4QoKCtIHH3yg/fv3t3mfXq9XbrdbdXV1Cg8Pv5T4AIAurK19YNuM8ty5cyotLVVaWprfeFpamkpKSlrd7rXXXtPnn3+u5cuXt2k/DQ0N8nq9fgsAAG1lW1HW1NSosbFRUVFRfuNRUVGqqqpqcZtPP/1US5Ys0Ztvvqng4LZ9Q1hubq7cbrdviYmJueTsAIDuw/aLeRwOh9/PlmU1G5OkxsZGPfDAA3r66af1ve99r83Pn5OTo7q6Ot9SUVFxyZkBAN1Hu7+4ubNERkYqKCio2eyxurq62SxTkurr67V3717t27dP8+bNkyQ1NTXJsiwFBweruLhYd9xxR7PtnE6nnE7n5XkRAICrnm0zytDQUCUmJsrj8fiNezwepaSkNFs/PDxcBw8e1P79+31LRkaGbrjhBu3fv1/jx4+/UtEBAN2IbTNKSVq4cKFmzZqlpKQkJScnq7CwUOXl5crIyJD0zWnT48ePa/369erRo4cSEhL8tu/fv79cLlezcQAAOoutRTljxgzV1tZqxYoVqqysVEJCgjZv3qzY2FhJUmVl5XfeUwkAwOVk632UduA+SgCA1AXuowQAoCugKAEAMKAoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCgKAEAMKAoAQAwoCgBADCwvSjz8/MVFxcnl8ulxMREbd++vdV133vvPd11113q16+fwsPDlZycrN/+9rdXMC0AoLuxtSiLioqUlZWlpUuXat++fZo4caKmTJmi8vLyFtfftm2b7rrrLm3evFmlpaW6/fbbNW3aNO3bt+8KJwcAdBcOy7Isu3Y+fvx4jRs3TgUFBb6x+Ph4paenKzc3t03PMXLkSM2YMUPLli1r0/per1dut1t1dXUKDw/vUG4AQNfX1j6wbUZ57tw5lZaWKi0tzW88LS1NJSUlbXqOpqYm1dfXq2/fvq2u09DQIK/X67cAANBWthVlTU2NGhsbFRUV5TceFRWlqqqqNj3Hc889p9OnT+u+++5rdZ3c3Fy53W7fEhMTc0m5AQDdi+0X8zgcDr+fLctqNtaSDRs26KmnnlJRUZH69+/f6no5OTmqq6vzLRUVFZecGQDQfQTbtePIyEgFBQU1mz1WV1c3m2X+o6KiIj388MN655139P3vf9+4rtPplNPpvOS8AIDuybYZZWhoqBITE+XxePzGPR6PUlJSWt1uw4YNmjt3rt566y3dfffdlzsmAKCbs21GKUkLFy7UrFmzlJSUpOTkZBUWFqq8vFwZGRmSvjltevz4ca1fv17SNyU5e/ZsPf/887r11lt9s9GePXvK7Xbb9joAAFcvW4tyxowZqq2t1YoVK1RZWamEhARt3rxZsbGxkqTKykq/eypffPFFXbhwQZmZmcrMzPSNz5kzR+vWrbvS8QEA3YCt91HagfsoAQBSF7iPEgCAroCiBADAgKIEAMCAogQAwICiBADAgKIEAMCAogQAwICiBADAgKIEAMCAogQAwICiBADAgKIEAMCAogQAwICiBADAgKIEAMCAogQAwICiBADAgKIEAMCAogQAwICiBADAgKIEAMCAogQAwICiBADAgKIEAMCAogQAwICiBADAgKIEAMCAogQAwICiBADAgKIEAMCAogQAwMD2oszPz1dcXJxcLpcSExO1fft24/pbt25VYmKiXC6Xhg4dqrVr116hpP6OnDylP/ylWkdrTtuyfxOydUwgZ5MCPx/aj99p1xBs586LioqUlZWl/Px8paam6sUXX9SUKVN06NAhDR48uNn6R48e1dSpU/Xoo4/qjTfe0M6dO/X444+rX79+uvfee69I5r+dOaf5G/Zr26cnfWOThvfTmplj5e4VckUytIZsHRPI2aTAz4f243fatTgsy7Ls2vn48eM1btw4FRQU+Mbi4+OVnp6u3NzcZusvXrxYmzZt0uHDh31jGRkZOnDggHbt2tWmfXq9XrndbtXV1Sk8PLzdmWe/sls7P6tR47cOW5DDodRhkVr/8C3tfr7ORLaOCeRsUuDnQ/vxOw0Mbe0D2069njt3TqWlpUpLS/MbT0tLU0lJSYvb7Nq1q9n6kydP1t69e3X+/PkWt2loaJDX6/VbOurIyVPa9ulJvz/cktRoWdr26UlbT5+QrWMCOZsU+PnQfvxOux7birKmpkaNjY2KioryG4+KilJVVVWL21RVVbW4/oULF1RTU9PiNrm5uXK73b4lJiamw5m/+PqM8fFjtfb9ASdbxwRyNinw86H9+J12PbZfzONwOPx+tiyr2dh3rd/S+EU5OTmqq6vzLRUVFR3OGtu3l/HxIRG9O/zcl4psHRPI2aTAz4f243fa9dhWlJGRkQoKCmo2e6yurm42a7xowIABLa4fHBysiIiIFrdxOp0KDw/3WzpqaL8+mjS8n4L+oZSDHA5NGt5PcZH2/QEnW8cEcjYp8POh/fiddj22FWVoaKgSExPl8Xj8xj0ej1JSUlrcJjk5udn6xcXFSkpKUkjIlblSbM3MsUodFuk3ljosUmtmjr0i+zchW8cEcjYp8POh/fiddi22XvVaVFSkWbNmae3atUpOTlZhYaFeeukllZWVKTY2Vjk5OTp+/LjWr18v6ZvbQxISEvTYY4/p0Ucf1a5du5SRkaENGza0+faQS73q9aKjNad1rPa0hkT0Drj/AZKtYwI5mxT4+dB+/E7t1dY+sLUopW8+cCAvL0+VlZVKSEjQqlWrNGnSJEnS3LlzdezYMW3ZssW3/tatW5Wdna2ysjJFR0dr8eLFysjIaPP+OqsoAQBdW5cpyiuNogQASF3gPkoAALoCihIAAAOKEgAAA1s/FN0OF9+SvZSPsgMAdH0Xe+C7LtXpdkVZX18vSZf0UXYAgKtHfX293G53q493u6tem5qadOLECYWFhRk/Ku+7eL1excTEqKKigqtn24Hj1nEcu47huHVMdzhulmWpvr5e0dHR6tGj9Xciu92MskePHho0aFCnPd+lfixed8Vx6ziOXcdw3Drmaj9uppnkRVzMAwCAAUUJAIABRdlBTqdTy5cvl9PptDtKl8Jx6ziOXcdw3DqG4/b/ut3FPAAAtAczSgAADChKAAAMKEoAAAwoSgAADCjKDsjPz1dcXJxcLpcSExO1fft2uyMFvNzcXN18880KCwtT//79lZ6err/85S92x+pycnNz5XA4lJWVZXeUgHf8+HH927/9myIiItSrVy+NGTNGpaWldscKeBcuXNBPfvITxcXFqWfPnho6dKhWrFihpqYmu6PZhqJsp6KiImVlZWnp0qXat2+fJk6cqClTpqi8vNzuaAFt69atyszM1B//+Ed5PB5duHBBaWlpOn36tN3Ruow9e/aosLBQo0ePtjtKwPvrX/+q1NRUhYSE6H/+53906NAhPffcc7rmmmvsjhbwfv7zn2vt2rV64YUXdPjwYeXl5ekXv/iF1qxZY3c023B7SDuNHz9e48aNU0FBgW8sPj5e6enpys3NtTFZ13Ly5En1799fW7du1aRJk+yOE/BOnTqlcePGKT8/X88884zGjBmj1atX2x0rYC1ZskQ7d+7kbE8H3HPPPYqKitIrr7ziG7v33nvVq1cvvf766zYmsw8zynY4d+6cSktLlZaW5jeelpamkpISm1J1TXV1dZKkvn372pyka8jMzNTdd9+t73//+3ZH6RI2bdqkpKQkTZ8+Xf3799fYsWP10ksv2R2rS5gwYYI++ugjffLJJ5KkAwcOaMeOHZo6darNyezT7T4U/VLU1NSosbFRUVFRfuNRUVGqqqqyKVXXY1mWFi5cqAkTJighIcHuOAHv7bff1v/+7/9qz549dkfpMo4cOaKCggItXLhQTz75pHbv3q358+fL6XRq9uzZdscLaIsXL1ZdXZ1GjBihoKAgNTY26mc/+5lmzpxpdzTbUJQd8I9fz2VZ1iV9ZVd3M2/ePP35z3/Wjh077I4S8CoqKrRgwQIVFxfL5XLZHafLaGpqUlJSkp599llJ0tixY1VWVqaCggKK8jsUFRXpjTfe0FtvvaWRI0dq//79ysrKUnR0tObMmWN3PFtQlO0QGRmpoKCgZrPH6urqZrNMtOxHP/qRNm3apG3btnXq151drUpLS1VdXa3ExETfWGNjo7Zt26YXXnhBDQ0NCgoKsjFhYBo4cKBuvPFGv7H4+Hht3LjRpkRdx6JFi7RkyRLdf//9kqRRo0bpiy++UG5ubrctSt6jbIfQ0FAlJibK4/H4jXs8HqWkpNiUqmuwLEvz5s3Te++9p9///veKi4uzO1KXcOedd+rgwYPav3+/b0lKStKDDz6o/fv3U5KtSE1NbXb70SeffKLY2FibEnUdZ86cafYlxkFBQd369hBmlO20cOFCzZo1S0lJSUpOTlZhYaHKy8uVkZFhd7SAlpmZqbfeeku/+tWvFBYW5puVu91u9ezZ0+Z0gSssLKzZ+7i9e/dWREQE7+8aZGdnKyUlRc8++6zuu+8+7d69W4WFhSosLLQ7WsCbNm2afvazn2nw4MEaOXKk9u3bp5UrV+qHP/yh3dHsY6Hd/uu//suKjY21QkNDrXHjxllbt261O1LAk9Ti8tprr9kdrcu57bbbrAULFtgdI+D9+te/thISEiyn02mNGDHCKiwstDtSl+D1eq0FCxZYgwcPtlwulzV06FBr6dKlVkNDg93RbMN9lAAAGPAeJQAABhQlAAAGFCUAAAYUJQAABhQlAAAGFCUAAAYUJQAABhQlAAAGFCUAAAYUJQAABhQlAAAGFCXQTZw8eVIDBgzwfZmxJP3pT39SaGioiouLbUwGBDY+FB3oRjZv3qz09HSVlJRoxIgRGjt2rO6++26tXr3a7mhAwKIogW4mMzNTv/vd73TzzTfrwIED2rNnj1wul92xgIBFUQLdzNmzZ5WQkKCKigrt3btXo0ePtjsSENB4jxLoZo4cOaITJ06oqalJX3zxhd1xgIDHjBLoRs6dO6dbbrlFY8aM0YgRI7Ry5UodPHhQUVFRdkcDAhZFCXQjixYt0rvvvqsDBw6oT58+uv322xUWFqbf/OY3dkcDAhanXoFuYsuWLVq9erVef/11hYeHq0ePHnr99de1Y8cOFRQU2B0PCFjMKAEAMGBGCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIABRQkAgAFFCQCAAUUJAIDB/wHKBqEiqWrnGAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.rcParams['font.size'] = '8' # 전체적으로(globally) 폰트 크기 조정\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.scatter(data['x'], data['y'], s=20)\n",
    "plt.title('Scatter Plot', fontsize=12)\n",
    "plt.xlabel('x', fontsize=10)\n",
    "plt.ylabel('y', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**선형 회귀 모델**\n",
    "\n",
    "위 시뮬레이션 데이터에 대해 선형 회귀 모델을 피팅한 다음, 각 `x`값에 대해서 확률 추정값(적합값)을 구해 산점도 위에 그린다. 이 경우 앞에서 우려한 대로 일부 적합값이 마이너스 값을 갖는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('y ~ x', data)\n",
    "olsfit = model.fit()\n",
    "y_pred = olsfit.predict(data['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.scatter(data['x'], data['y'], s=20)\n",
    "plt.plot(data['x'], y_pred, color='red')\n",
    "plt.title('Linear Regression', fontsize=12)\n",
    "plt.xlabel('x', fontsize=10)\n",
    "plt.ylabel('y', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**로지스틱 회귀 모델**\n",
    "\n",
    "다음은 `statsmodels.formula.api` 모듈의 `logit()` 함수를 이용한 추정이다. 동일한 시뮬레이션 데이터에 대해 이번에는 로지스틱 회귀 모델을 피팅한 다음, 각 `x`값에 대해서 확률 추정값(적합값)을 구해 산점도 위에 그린다. 이 경우 선형 회귀와 같은 문제가 발생하지 않는 것을 알 수 있다. 즉, 모든 적합값이 0과 1 사이에 위치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.355402\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "model = smf.logit('y ~ x', data)\n",
    "logitfit = model.fit()\n",
    "y_pred = logitfit.predict(data['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.scatter(data['x'], data['y'], s=20)\n",
    "plt.plot(data['x'], y_pred, color='red')\n",
    "plt.title('Logistic Regression', fontsize=12)\n",
    "plt.xlabel('x', fontsize=10)\n",
    "plt.ylabel('y', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default 데이터세트 로지스틱 회귀\n",
    "\n",
    "앞에서 예시적으로 사용한 `Default` 데이터세트에서 우선 `balance` 변수 하나만을 사용해 디폴트 확률을 예측하는 로지스틱 회귀 모델을 실행해보자. 먼저 범주형 변수인 `default` 변수를 **더미 변수**(dummy variable)로 인코딩해야 한다. 즉 `default` 변수 값이 Yes인 경우 1, No인 경우 0의 값을 부여해 이를 `default1` 이름으로 지정한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>default1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526</td>\n",
       "      <td>44361.625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180</td>\n",
       "      <td>12106.135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549</td>\n",
       "      <td>31767.139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.251</td>\n",
       "      <td>35704.494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.656</td>\n",
       "      <td>38463.496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student   balance     income  default1\n",
       "0      No      No   729.526  44361.625         0\n",
       "1      No     Yes   817.180  12106.135         0\n",
       "2      No      No  1073.549  31767.139         0\n",
       "3      No      No   529.251  35704.494         0\n",
       "4      No      No   785.656  38463.496         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['default1'] = [0 if default == 'No' else 1 for default in df.default]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>default1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>835.375</td>\n",
       "      <td>33516.982</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>483.715</td>\n",
       "      <td>13336.640</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>771.968</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>481.731</td>\n",
       "      <td>21340.463</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>823.637</td>\n",
       "      <td>34552.645</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1166.308</td>\n",
       "      <td>43807.729</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2654.323</td>\n",
       "      <td>73554.233</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         balance     income   default1\n",
       "count  10000.000  10000.000  10000.000\n",
       "mean     835.375  33516.982      0.033\n",
       "std      483.715  13336.640      0.179\n",
       "min        0.000    771.968      0.000\n",
       "25%      481.731  21340.463      0.000\n",
       "50%      823.637  34552.645      0.000\n",
       "75%     1166.308  43807.729      0.000\n",
       "max     2654.323  73554.233      1.000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 `smf.logit`를 이용한 로지스틱 회귀 모델 추정 결과이다. 반응변수로는 범주형 변수인 `default`가 아니라 이를 더미변수로 인코딩한 `default1`을 사용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.079823\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               default1   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9998\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Wed, 03 Sep 2025   Pseudo R-squ.:                  0.4534\n",
      "Time:                        06:52:15   Log-Likelihood:                -798.23\n",
      "converged:                       True   LL-Null:                       -1460.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.233e-290\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -10.6513      0.361    -29.491      0.000     -11.359      -9.943\n",
      "balance        0.0055      0.000     24.952      0.000       0.005       0.006\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.13 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "est = smf.logit('default1 ~ balance', data=df).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 보면 $\\beta_1 = 0.0055$이다. 이것은 `balance`의 증가가 디폴트 확률을 증가시키는 방향으로 영향을 미친다는 것을 의미한다. 정확히 말하면 `balance`가 1단위 증가하면 디폴트의 log odds가 0.0055단위 증가하는 것을 의미한다. \n",
    "\n",
    "선형 회귀와 마찬가지로 표준오차를 계산하여 계수 추정의 정확도를 측정할 수 있다. 표에 나와 있는 $z$-통계량은 선형 회귀의 $t$-통계량과 동일한 역할을 한다. 예를 들어 $\\beta_1$의 $z$-통계량은 $\\hat \\beta_1 / SE(\\beta_1)$이다. $z$-통계량이 (절대값으로) 크면 귀무가설 $H_0 : \\beta_1 = 0$에 반하는 증거를 의미한다. 이 귀무가설은 $p(X)$, 즉 디폴트 확률이 `balance`에 의존하지 않는다는 것이다. 위 결과를 보면, `balance`의 $p$값이 작기 때문에 $H_0$을 기각할 수 있다. 즉 `balance`와 디폴트 확률 사이에 연관성이 있다고 결론내릴 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정성적 예측변수 `student`**\n",
    "\n",
    "로지스틱 회귀 모델에서도 앞의 선형 회귀와 마찬가지로 정성적 예측변수를 사용할 수 있다. 아래는 `student` 변수를 사용해 디폴트 확률을 예측하는 로지스틱 회귀 모델이다. 반응변수인 `default`와 달리 예측변수인 `student`는 1/0의 더미변수로 변환시키지 않고 범주형 변수 그대로 사용해도 된다. 이 경우 `smf.logit` 모듈은 `student`가 Yes이면 1을, 그렇지 않으면 0 값을 취하는 `student[T.Yes]` 더미 변수를 만들어 추정한다. \n",
    "\n",
    "아래 결과를 보면, `student`의 추정 계수는 플러스 값이고, 이에 대한 $p$값은 통계적 유의성을 의미한다. 즉, 학생 그룹이 비학생 그룹보다 디폴트 확률이 더 높은 경향이 있음을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.145434\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               default1   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9998\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Wed, 03 Sep 2025   Pseudo R-squ.:                0.004097\n",
      "Time:                        06:52:15   Log-Likelihood:                -1454.3\n",
      "converged:                       True   LL-Null:                       -1460.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0005416\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -3.5041      0.071    -49.554      0.000      -3.643      -3.366\n",
      "student[T.Yes]     0.4049      0.115      3.520      0.000       0.179       0.630\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "est = smf.logit('default1 ~ student', data=df).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  다중 로지스틱 회귀\n",
    "\n",
    "이제 여러 개의 예측변수를 사용하여 0/1의 이항(binary) 반응변수를 예측하는 문제를 생각해보자. 다중 로지스틱 회귀식은 다음과 같으며, 이는 선형 회귀에서 단순 모형을 다중 모형으로 확장하는 것과 유사하다. \n",
    "\n",
    "$$\n",
    "p(X) = \\frac {e^{\\beta_0 + \\beta_1 X_1 +...+ \\beta_p X_p}}{1+e^{\\beta_0 + \\beta_1 X_1 +...+ \\beta_p X_p}}\n",
    "$$\n",
    "\n",
    "이를 다음과 같이 쓸 수도 있다.\n",
    "\n",
    "$$\n",
    "{\\rm ln}\\left(\\frac {p(X)}{1−p(X)}\\right) =\\beta_0 + \\beta_1 X_1 +...+ \\beta_p X_p\n",
    "$$\n",
    "\n",
    "\n",
    "최대가능도법으로 다중 로지스틱 회귀 모델을 추정할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Default` 데이터세트 로지스틱 회귀**\n",
    "\n",
    "아래에 `balance`, `income`, `student`를 사용하여 디폴트 확률을 예측하는 다중 로지스틱 회귀 모델에 대한 계수 추정치가 나와 있다.(`income` 변수는 단위를 1,000달러로 바꿈.) \n",
    "\n",
    "추정 결과를 보면, `balance` 및 `student` 변수의 경우 1% 수준에서 통계적으로 유의하여 이들 변수가 다중 디폴트 확률과 관련이 있음을 나타낸다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078577\n",
      "         Iterations 10\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept        -10.8690      0.492    -22.079      0.000     -11.834      -9.904\n",
      "student[T.Yes]    -0.6468      0.236     -2.738      0.006      -1.110      -0.184\n",
      "balance            0.0057      0.000     24.737      0.000       0.005       0.006\n",
      "income1            0.0030      0.008      0.370      0.712      -0.013       0.019\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "df['income1'] = df.income/1000\n",
    "est = smf.logit('default1 ~ balance + income1 + student', data=df).fit()\n",
    "print(est.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 여기에서 특이한 사실이 하나 발견된다. `student` 변수의 계수가 마이너스로서 학생이 비학생보다 디폴트 가능성이 낮게 나온 것이다. 이는 앞의 단순 로지스틱 회귀에서 `student` 변수의 계수가 플러스인 것과 정반대의 결과이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교란요인\n",
    "\n",
    "단순 회귀와 다중 회귀에서 `student` 더미 변수의 계수 부호가 반대로 나온 사실을 어떻게 이해해야 할까? 아래 그림 7.4는 이 사실을 그림으로 설명한다. 먼저 왼쪽 그림에서 오렌지색과 파란색 실선은 각각 학생과 비학생의 평균 디폴트율이 `balance`(카드 사용액)에 따라 어떻게 달라지는지 보여준다.(이는 다중 로지스틱 회귀 결과를 이용하여 계산한 것이다.) 여기에서 보듯이 모든 카드 사용액에 대해 학생 그룹(오렌지색)의 디폴트율이 비학생 그룹의 디폴트율보다 낮은 것을 알 수 있다. 이것이 다중 로지스틱 회귀에서 `student` 계수의 부호가 마이너스인 것을 반영한다. 즉 `balance` 및 `income`이 고정된 상태에서는 학생이 비학생보다 디폴트 확률이 더 낮다. \n",
    "\n",
    "한편 왼쪽 그림 하단의 수평 점선은 학생과 비학생의 디폴트율을 모든 `balance` 및 `income`에 대해 평균한 것이다. 주목할 점은 여기에서는 학생(오렌지색)의 디폴트율이 비학생(파란색)의 디폴트율보다 약간 더 높다는 것이다. 이것은 앞의 단일 변수 로지스틱 회귀 결과에 해당한다. 즉 `balance` 및 `income`이 고정되지 않은 상태에서는 학생이 비학생보다 디폴트 확률이 높은 것을 나타낸다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**그림 7.4.** Default 데이터에 있어서의 교란(confounding). 왼쪽: 학생(오렌지색) 및 비학생(파란색)에 대한 디폴트율로서 실선은 신용카드 사용액(`balance`)의 함수로 표시된 디폴트율을 나타내고, 아래쪽 수평 점선은 전체 디폴트율이다. 오른쪽: 학생(오렌지색) 및 비학생(파란색)에 대해 신용카드 사용액의 분포를 상자그림으로 그린 것이다.\n",
    "\n",
    "![Default 교란](https://raw.githubusercontent.com/pilsunchoi/images/main/7-4.png)\n",
    "\n",
    "- 그림 출처: ISLP, FIGURE 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 오른쪽 그림이 `student` 더미 변수의 계수 부호가 단순 회귀와 다중 회귀에서 서로 반대로 나온 것에 대한 설명을 제공한다. 한마디로 `student`와 `balance` 변수가 서로 관련돼있는 것이다. 학생 그룹의 카드 사용액이 비학생보다 더 많은 경향이 있으며, 이는 결국 디폴트 가능성을 높인다. 카드 사용액이 동일하다면 학생이 비학생보다 디폴트 가능성이 낮지만, 전체적으로는 학생의 카드 사용액이 더 많은 경향이 있기 때문에 학생이 비학생보다 더 높은 비율로 디폴트가 발생하는 것이다. \n",
    "\n",
    "이 사례에서 보듯이 하나의 예측변수를 사용하여 얻은 결과가 여러 예측변수를 사용하여 얻은 결과와 상당히 다를 수 있다(특히 예측변수 간에 상관관계가 있는 경우). 우리 예에서는 `balance`라는 요인이 `student`와 `default`에 동시에 영향을 미치는 **교란요인**(confounding factor)으로 작용하여 `student`와 `default` 간의 인과관계를 교란시키고 있다. 이러한 교란 문제를 해결하기 위해서는 다중 회귀를 통해 변수들을 **통제**(control)하는 것이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 교란요인 추가 설명  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "통계학에서 **교란요인**(confounding factor 또는 confounder)은 외부 결정요인(extraneous determinant) 또는 잠복변수(lurking variable) 등으로도 불린다(Wikipedia, \"[Confounding](https://en.wikipedia.org/wiki/Confounding)\"). 통계학 사전은 confounding을 \"**중첩**\"으로 번역하는데, 우리는 영어 \"confound\"의 원래 뜻(어리둥절하게 만들다)을 좀 더 살리는 \"**교란**\"으로 표기하기로 한다. \n",
    "\n",
    "교란요인은 종속변수(즉, 반응변수)와 독립변수(즉, 예측변수) 모두에 영향을 미침으로써 종속변수와 독립변수 간에 **거짓 연관성**(spurious association)을 유발하는 변수다. 교란요인이 잘못된 연관성을 야기할 수 있기 때문에 어떤 연관성(또는 상관성)이 있다고 해서 그것이 반드시 인과 관계를 의미하지는 않는다(Wikipedia, \"[Correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation)\"). 변수간 단순 연관성이 아니라 인과성을 규명하는 것을 최종 목표로 하는 **인과 추론**(Wikipedia, \"[Causal inference](https://en.wikipedia.org/wiki/Causal_inference)\")에서 교란요인은 핵심 개념이다.  \n",
    "\n",
    "가령 어떤 약물 X가 환자의 회복(Y)에 미치는 효과를 평가하려고 한다. 즉 다른 조건이 동일할 때, 해당 약물이 환자의 회복에 어떤 효과를 미치는지 평가하기를 원한다. 그런데 아래 그림처럼 성별(Z)이 환자의 약물(X) 선택과 회복 가능성(Y)에 동시에 영향을 미치는 경우를 생각해보자. 가령 남성일수록 약물 X를 많이 선택하고, 또한 동시에 남성일수록 (약물과는 별개로) 신체구조 상 해당 질환에서 회복이 늦은 경우가 있을 수 있다. 이런 경우, 우리는 성별 Z가 X와 Y의 관계를 교란시킨다고 말한다.\n",
    "\n",
    "**그림 7.5.** 교란요인(Z) 예시. \n",
    "\n",
    "![교란요인](https://raw.githubusercontent.com/pilsunchoi/images/main/7-5.png)\n",
    "\n",
    "- 그림 출처: Wikipedia, \"[Confounding](https://en.wikipedia.org/wiki/Confounding)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림에서 X가 독립변수이고, Y가 종속변수일 때, X가 Y에 미치는 영향을 추정하려면 통계학자는 X와 Y 모두에 영향을 미치는 외부 변수의 영향을 억제해야 한다. 만약 외부 요인 Z가 X와 Y 모두에 영향을 미치는 경우, 우리는 X와 Y가 다른 변수 Z에 의해 교란된다(confounded)고 말한다.\n",
    "\n",
    "앞의 Default 데이터세트 예에서 `student`가 X이고, `default`가 Y이며, `balance`가 Z에 해당하는 경우를 생각해 볼 수 있다. `student`가 `default`에 미치는 영향을 평가하려고 하는데, `balance`라는 요인이 `student`와 `default` 모두에 영향을 미침으로써 평가를 교란시키는 것이다. 즉 학생 여부에 따라 `balance`가 달라지고, 그것에 따라 `default`가 영향을 받음으로써 효과가 중첩적으로 발생하게 된다. 이를 해결하기 위해서는 (여러 방법 중 하나로서) `balance` 변수를 회귀식에 포함시킴으로써 `balance`의 영향을 **통제**(control)하는 것이 필요하다. 다중 회귀에서는 각 계수의 의미가 \"다른 조건이 동일할 때\"를 전제로 하기 때문에 이러한 통제를 통해서 우리가 원하는 순수한 효과를 평가할 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교란 사례\n",
    "\n",
    "- 출생 순서(첫째 아이, 둘째 아이 등)와 다운 증후군 간의 관계를 연구한다고 가정해보자. 이 경우 산모의 나이가 교란요인이 될 수 있다. 일반적으로 산모의 연령과 아동의 다운 증후군은 직접적인 관련이 있다. 그런데 산모의 나이는 출생 순서와 직접적으로 관련된다(즉, 쌍둥이 경우를 제외하면, 둘째 아이는 첫째 아이에 비해 어머니가 나이가 많을 때 태어난다). 따라서 출생 순서와 다운 증후군 간의 관계가 산모의 나이라는 요인에 의해 교란된다.\n",
    "</br>\n",
    "\n",
    "- 흡연이 건강에 미치는 영향을 생각해보자. 흡연, 음주, 식생활 등은 서로 관련된 라이프 스타일 활동이다. 흡연의 영향을 살펴볼 때, 알코올 섭취나 식생활을 통제하지 않을 경우 흡연의 위험이 과대평가될 수 있다.\n",
    "</br>\n",
    "\n",
    "- 반대로 흡연에 있어서 나이라는 요인을 생각해보면, 젊은층에 비해 건강도가 떨어지는 고연령층일수록 흡연율이 낮다. 반대로 이야기하면, 흡연율이 낮은 고연령층일수록 건강도는 떨어진다. 따라서 나이를 고려하지 않을 경우, 흡연의 위험이 과소평가될 수 있다. \n",
    "</br>\n",
    "\n",
    "- 과외가 성적에 미치는 효과를 분석하고자 할 때, 과외를 받은 그룹과 그렇지 않은 그룹의 성적 차이가 과연 전적으로 과외 때문인지, 아니면 다른 요인이 개입돼 있는지 생각해봐야 한다. 예컨대 과외 그룹에 속한 학생일수록 대도시에 살고 가계 소득이 높은 경우가 많다면, 두 그룹 간 성적의 차이가 과외 때문인지, 아니면 소득이나 지역적 영향인지 구별할 수 없다. 즉 소득이나 지역적 요인 등이 교란요인으로 작용할 수 있다.\n",
    "</br>\n",
    "\n",
    "- 교육이 임금에 미치는 효과를 분석하고자 할 때, 교육을 더 많이 받을수록 더 높은 임금을 받는 것이 전적으로 교육의 효과인지, 아니면 다른 요인이 개입돼 있는지 생각해 봐야 한다. 대표적으로 능력이 더 우수할수록 교육을 더 많이 받는 경향이 있다면 교육이 임금에 미치는 효과가 순전히 교육의 효과인지, 아니면 능력이라는 (눈에 보이지 않는!) 요인이 개입된 것인지 구별할 수 없다. 즉 교육이 임금에 미치는 효과를 분석할 때, 능력이라는 요인이 교란요인으로 작용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 로지스틱 회귀 예제 \n",
    "\n",
    "**자료**: https://github.com/gperaza/ISLR-Python-Labs 및 https://github.com/emredjan/ISL-python/tree/master/labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주식시장 데이터\n",
    "\n",
    "ISLP에서 제공하는 `Smarket` 데이터세트는 2001년 초부터 2005년 말까지 1,250일 동안 S&P 500 주가지수의 수익률(%)을 기록한 것이다. 이 데이터로 주가의 상승과 하락을 분류하는 로지스틱 모델을 추정해보자.\n",
    "\n",
    "`Today`는 각 날짜의 수익률이고, 각 날짜에 대해 이전 5개 거래일의 수익률을 `Lag1`부터 `Lag5`까지의 이름으로 기록했다. 또한 `Volume`은 전날 거래된 주식 수(단위: 십억)이고, `Direction`은 해당 날짜에 시장이 상승(`Up`) 또는 하락(`Down`)했는지를 나타낸다. `Year`는 각 날짜가 속한 연도이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.191</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.296</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.411</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.206</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "0  2001  0.381 -0.192 -2.624 -1.055  5.010   1.191  0.959        Up\n",
       "1  2001  0.959  0.381 -0.192 -2.624 -1.055   1.296  1.032        Up\n",
       "2  2001  1.032  0.959  0.381 -0.192 -2.624   1.411 -0.623      Down\n",
       "3  2001 -0.623  1.032  0.959  0.381 -0.192   1.276  0.614        Up\n",
       "4  2001  0.614 -0.623  1.032  0.959  0.381   1.206  0.213        Up"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket = pd.read_csv('../Data/Smarket.csv')\n",
    "Smarket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1250.000</td>\n",
       "      <td>1250.000</td>\n",
       "      <td>1250.000</td>\n",
       "      <td>1250.000</td>\n",
       "      <td>1250.000</td>\n",
       "      <td>1250.000</td>\n",
       "      <td>1250.000</td>\n",
       "      <td>1250.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2003.016</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.409</td>\n",
       "      <td>1.136</td>\n",
       "      <td>1.136</td>\n",
       "      <td>1.139</td>\n",
       "      <td>1.139</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.360</td>\n",
       "      <td>1.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2001.000</td>\n",
       "      <td>-4.922</td>\n",
       "      <td>-4.922</td>\n",
       "      <td>-4.922</td>\n",
       "      <td>-4.922</td>\n",
       "      <td>-4.922</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-4.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2002.000</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>1.257</td>\n",
       "      <td>-0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2003.000</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>1.423</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2004.000</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.597</td>\n",
       "      <td>1.642</td>\n",
       "      <td>0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2005.000</td>\n",
       "      <td>5.733</td>\n",
       "      <td>5.733</td>\n",
       "      <td>5.733</td>\n",
       "      <td>5.733</td>\n",
       "      <td>5.733</td>\n",
       "      <td>3.152</td>\n",
       "      <td>5.733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Year      Lag1      Lag2      Lag3      Lag4      Lag5    Volume  \\\n",
       "count  1250.000  1250.000  1250.000  1250.000  1250.000  1250.000  1250.000   \n",
       "mean   2003.016     0.004     0.004     0.002     0.002     0.006     1.478   \n",
       "std       1.409     1.136     1.136     1.139     1.139     1.148     0.360   \n",
       "min    2001.000    -4.922    -4.922    -4.922    -4.922    -4.922     0.356   \n",
       "25%    2002.000    -0.639    -0.639    -0.640    -0.640    -0.640     1.257   \n",
       "50%    2003.000     0.039     0.039     0.038     0.038     0.038     1.423   \n",
       "75%    2004.000     0.597     0.597     0.597     0.597     0.597     1.642   \n",
       "max    2005.000     5.733     5.733     5.733     5.733     5.733     3.152   \n",
       "\n",
       "          Today  \n",
       "count  1250.000  \n",
       "mean      0.003  \n",
       "std       1.136  \n",
       "min      -4.922  \n",
       "25%      -0.639  \n",
       "50%       0.038  \n",
       "75%       0.597  \n",
       "max       5.733  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`corr()` 메서드는 데이터세트의 모든 예측변수 쌍(pair)에 대해 상관계수 행렬을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>0.030</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.539</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today\n",
       "Year    1.000  0.030  0.031  0.033  0.036  0.030   0.539  0.030\n",
       "Lag1    0.030  1.000 -0.026 -0.011 -0.003 -0.006   0.041 -0.026\n",
       "Lag2    0.031 -0.026  1.000 -0.026 -0.011 -0.004  -0.043 -0.010\n",
       "Lag3    0.033 -0.011 -0.026  1.000 -0.024 -0.019  -0.042 -0.002\n",
       "Lag4    0.036 -0.003 -0.011 -0.024  1.000 -0.027  -0.048 -0.007\n",
       "Lag5    0.030 -0.006 -0.004 -0.019 -0.027  1.000  -0.022 -0.035\n",
       "Volume  0.539  0.041 -0.043 -0.042 -0.048 -0.022   1.000  0.015\n",
       "Today   0.030 -0.026 -0.010 -0.002 -0.007 -0.035   0.015  1.000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket.corr(method='pearson', numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상대로 래그(lag) 변수들과 오늘의 수익률(`Today`) 간의 상관계수는 0에 가깝다. 즉, 오늘의 수익률과 전날 수익률간에 상관관계가 거의 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**로지스틱 회귀**\n",
    "\n",
    "\n",
    "시장이 상승했는지 아니면 하락했는지를 나타내는 `Direction`을 예측하기 위해 `Lag1`부터 `Lag5`, 그리고 `Volume` 등 모든 변수들을 사용하여 로지스틱 회귀 모델을 피팅한다. `statsmodels.formula.api`의 `logit()` 함수를 사용하여 피팅한다. 그 전에 반응변수 `Direction`에서 `Up` 및 `Down`을 각각 1과 0으로 변환하는 코딩이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "      <th>DirCoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.191</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.296</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.411</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.206</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction  DirCoded\n",
       "0  2001  0.381 -0.192 -2.624 -1.055  5.010   1.191  0.959        Up         1\n",
       "1  2001  0.959  0.381 -0.192 -2.624 -1.055   1.296  1.032        Up         1\n",
       "2  2001  1.032  0.959  0.381 -0.192 -2.624   1.411 -0.623      Down         0\n",
       "3  2001 -0.623  1.032  0.959  0.381 -0.192   1.276  0.614        Up         1\n",
       "4  2001  0.614 -0.623  1.032  0.959  0.381   1.206  0.213        Up         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket['DirCoded'] = [0 if d == 'Down' else 1 for d in Smarket.Direction]\n",
    "Smarket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691034\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               DirCoded   No. Observations:                 1250\n",
      "Model:                          Logit   Df Residuals:                     1243\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Wed, 03 Sep 2025   Pseudo R-squ.:                0.002074\n",
      "Time:                        06:52:16   Log-Likelihood:                -863.79\n",
      "converged:                       True   LL-Null:                       -865.59\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7319\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1260      0.241     -0.523      0.601      -0.598       0.346\n",
      "Lag1          -0.0731      0.050     -1.457      0.145      -0.171       0.025\n",
      "Lag2          -0.0423      0.050     -0.845      0.398      -0.140       0.056\n",
      "Lag3           0.0111      0.050      0.222      0.824      -0.087       0.109\n",
      "Lag4           0.0094      0.050      0.187      0.851      -0.089       0.107\n",
      "Lag5           0.0103      0.050      0.208      0.835      -0.087       0.107\n",
      "Volume         0.1354      0.158      0.855      0.392      -0.175       0.446\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_fit = smf.logit('DirCoded ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume', Smarket).fit()\n",
    "print(logit_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 보면, 모든 예측변수가 10% 수준에서 유의하지 않다. 그나마 `Lag1` 변수(추정 계수: -0.0731)의 $p$값이 가장 작다. 추정 계수의 부호가 마이너스라는 것은 시장이 어제 플러스 수익을 냈다면 오늘 상승할 가능성이 낮다는 것을 나타낸다. 그러나 $p$값이 0.145로서 비교적 크기 때문에`Lag1`과 `Direction` 사이의 실제 연관성에 명확한 증거가 있다고는 말할 수 없다.\n",
    "\n",
    "다음과 같이 `params` 속성(attribute)을 사용하면 피팅된 모델의 계수에 액세스할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept   -0.126\n",
       "Lag1        -0.073\n",
       "Lag2        -0.042\n",
       "Lag3         0.011\n",
       "Lag4         0.009\n",
       "Lag5         0.010\n",
       "Volume       0.135\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_fit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 `predict()` 메서드를 사용하면 예측변수의 값이 하나의 데이터프레임(여기에서는 `Smarket`)으로 주어졌을 때, 시장이 상승할 확률을 예측할 수 있다. 즉 $\\Pr(Y = 1 \\mid X)$을 출력해준다. `predict()` 함수에 데이터세트가 제공되지 않으면 로지스틱 회귀 모델을 피팅하는 데 사용된 훈련 데이터에 대한 확률이 계산된다. `Up`에 대해 1로 더미변수를 만들었기 때문에 이 값들은 시장이 상승할 확률에 해당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.507\n",
       "1    0.481\n",
       "2    0.481\n",
       "3    0.515\n",
       "4    0.511\n",
       "5    0.507\n",
       "6    0.493\n",
       "7    0.509\n",
       "8    0.518\n",
       "9    0.489\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_probs = logit_fit.predict(Smarket)\n",
    "logit_probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 확률을 1/0의 숫자가 아니라 `Up` 또는 `Down`의 레이블로 만들 수도 있다. 다음 명령은 예측된 상승 확률이 0.5보다 크면 `Up`, 그렇지 않으면 `Down`으로 분류한 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Up\n",
       "1    Down\n",
       "2    Down\n",
       "3      Up\n",
       "4      Up\n",
       "5      Up\n",
       "6    Down\n",
       "7      Up\n",
       "8      Up\n",
       "9    Down\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_pred = pd.Series(['Up' if p > 0.5 else 'Down' for p in logit_probs])\n",
    "logit_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**혼동행렬**\n",
    "\n",
    "관측 중 얼마만큼이 정확하게 분류되었고 얼마만큼이 잘못 분류되었는지를 표로 정리한 것이 **혼동행렬**(confusion matrix)이다.(맨 아래 [부록](#부록:-혼동행렬) 참조.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT Q&A\n",
    "\n",
    ">**혼동행렬(confusion matrix)에 대해 쉽게 설명해줘.**\n",
    "\n",
    "---\n",
    "\n",
    ">혼동행렬(confusion matrix)은 분류(classification) 문제에서 모델의 성능을 평가하는 데 사용되는 도구입니다. 이 행렬은 실제 값과 모델이 예측한 값을 비교하여 얼마나 잘 맞추었는지를 보여줍니다. 주로 이진 분류(binary classification) 문제에서 사용되지만, 다중 클래스 분류(multi-class classification) 문제에도 적용할 수 있습니다.\n",
    ">\n",
    ">혼동행렬은 네 가지 기본 요소로 구성됩니다:\n",
    ">\n",
    ">1. **진짜 양성(True Positive, TP)**: 모델이 양성(positive)이라고 예측했고, 실제로도 양성인 경우입니다.\n",
    ">2. **진짜 음성(True Negative, TN)**: 모델이 음성(negative)이라고 예측했고, 실제로도 음성인 경우입니다.\n",
    ">3. **거짓 양성(False Positive, FP)**: 모델이 양성이라고 예측했지만, 실제로는 음성인 경우입니다. 이를 1종 오류(Type I error)라고도 합니다.\n",
    ">4. **거짓 음성(False Negative, FN)**: 모델이 음성이라고 예측했지만, 실제로는 양성인 경우입니다. 이를 2종 오류(Type II error)라고도 합니다.\n",
    ">\n",
    ">이러한 요소들을 행렬 형태로 배열하면 다음과 같습니다:\n",
    ">\n",
    ">\n",
    ">                                예측값\n",
    ">                         양성             음성  \n",
    ">     실제    양성     TP (진짜 양성)   FN (거짓 음성)  \n",
    ">     값      음성     FP (거짓 양성)   TN (진짜 음성)  \n",
    ">>\n",
    ">혼동행렬을 통해 여러 성능 지표를 계산할 수 있습니다. 예를 들어, 정확도(accuracy), 정밀도(precision), 재현율(recall), F1 점수 등이 있습니다. 이러한 지표들은 모델의 성능을 다양한 관점에서 평가하는 데 도움을 줍니다. 예를 들어, 정밀도는 모델이 양성으로 예측한 것 중 실제로 양성인 비율을, 재현율은 실제 양성 중 모델이 양성으로 정확하게 예측한 비율을 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 혼동행렬을 만든 과정을 잘 살펴보면, 각 열이 \"예측\"에 해당하고 각 행이 \"실제\" 관측에 해당한다. 분류 분계점은 0.5를 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Down</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>145.0</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>141.0</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Down     Up\n",
       "Down  145.0  457.0\n",
       "Up    141.0  507.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 혼동행렬을 직접 계산\n",
    "# pred_table[i,j]: the number of times “i” was observed and the model predicted “j”.\n",
    "table = logit_fit.pred_table(threshold=0.5)  \n",
    "confusion_df = pd.DataFrame(table, ['Down','Up'], ['Down','Up'])\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서는 혼동행렬을 직접 계산했으나 사이킷런(`sklearn`: scikit-learn)이 제공하는 `confusion_matrix()` 함수를 이용하여 만들 수도 있다. 또한 `classification_report()`를 이용하면 혼동행렬과 관련하여 정확도 등 여러 값들을 표로 제공한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  Down   Up\n",
      "True                \n",
      "Down        145  457\n",
      "Up          141  507\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.507     0.241     0.327       602\n",
      "          Up      0.526     0.782     0.629       648\n",
      "\n",
      "    accuracy                          0.522      1250\n",
      "   macro avg      0.516     0.512     0.478      1250\n",
      "weighted avg      0.517     0.522     0.483      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix() 함수로 혼동행렬을 구함\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(Smarket.Direction, logit_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Down','Up'], columns=['Down','Up'])\n",
    "cm_df.index.name = 'True'\n",
    "cm_df.columns.name = 'Predicted'\n",
    "print(cm_df)\n",
    "print()\n",
    "print(classification_report(Smarket.Direction, logit_pred, digits=3))  # 정밀도 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혼동행렬의 대각선 원소는 올바른 예측을 나타내고, 비대각선은 잘못된 예측을 나타낸다. 위 결과를 보면, 우리 모델이 상승을 올바르게 예측한 것은 507 거래일, 하락을 올바르게 예측한 것은 145 거래일로서 총 $507 + 145 = 652$개의 올바른 예측을 했다. 즉 로지스틱 회귀 분석은 전체의 52.16%(=652/1250)에 대해 시장의 움직임을 정확하게 예측했다. 이 계산을 다음과 같이 할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5216"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(logit_pred == Smarket.Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**훈련 세트 vs 테스트 세트**\n",
    "\n",
    "위 결과를 보면, 상승/하락의 예측 정확도가 50%를 넘었다는 점에서 로지스틱 회귀 모델이 무작위 추측(random guessing)보다는 약간 더 잘 작동하는 것으로 생각할 수 있다. 그러나 이런 평가는 잘못이다. 왜냐하면 모델을 테스트한 대상이 다름 아닌 1,250개의 훈련 데이터세트이기 때문이다. 정확도가 52.16%이기 때문에 훈련 오류율(training error rate)은 100 − 52.16 = 47.84%이다. 그런데 훈련 오류율은 종종 너무 낮게 나온다. 즉 훈련 데이터세트에 대해서는 추정 성과가 아주 좋을 수 있다는 것이다.  \n",
    "\n",
    "로지스틱 회귀 모델의 정확도를 더 잘 평가하기 위해서는 데이터의 일부만을 사용하여 모델을 피팅한 다음, 훈련에 사용하지 않은 나머지 데이터에 대해 얼마나 잘 예측하는지를 조사해 봐야 한다. 모델을 피팅하는 데 사용한 데이터가 아니라 시장의 움직임을 알 수 없는 미래의 날짜에 대해 모델의 성능을 평가해 볼 필요가 있다. 즉 **훈련 데이터세트**가 아닌 **테스트 데이터세트**에 대해 오류율을 산출해 볼 필요가 있다. 이를 위해 데이터세트를 두 개로 나누어 2001년부터 2004년까지의 관측을 훈련 세트(`train_df`)로 하고, 2005년의 관측을 테스트 세트(`test_df`)로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = Smarket[Smarket.Year < 2005]\n",
    "test_df = Smarket[Smarket.Year == 2005]\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 2004년까지의 날짜에 해당하는 관측, 즉 훈련 세트만 사용하여 로지스틱 회귀 모델을 피팅한다. 그런 다음 테스트 세트의 각 날짜, 즉 2005년에 대해 주식 시장의 상승 확률을 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691936\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "train_fit = smf.logit('DirCoded ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume', train_df).fit()\n",
    "predicted_probs = train_fit.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이로써 완전히 분리된 두 개의 데이터세트에 대해 모델을 훈련하고 테스트를 수행했다. 훈련은 2004년까지의 데이터만 사용하여 수행되었고, 테스트는 2005년의 데이터만 사용하여 수행되었다. \n",
    "\n",
    "이제 2005년에 대한 예측을 해당 기간 동안 시장의 실제 움직임과 비교해보자. 테스트 세트에 대해 예측의 정확도를 계산한 것과 혼동행렬이 아래 나와 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 모델은 테스트 세트에서 정확한 예측 비율이 48.0%이다\n"
     ]
    }
   ],
   "source": [
    "a = ['Up' if p > 0.5 else 'Down' for p in predicted_probs]\n",
    "test_df = test_df.assign(preds = a)\n",
    "print('이 모델은 테스트 세트에서 정확한 예측 비율이 %0.1f%%이다' \n",
    "      % (100*np.mean(test_df.preds == test_df.Direction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  Down  Up\n",
      "True               \n",
      "Down         77  34\n",
      "Up           97  44\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.443     0.694     0.540       111\n",
      "          Up      0.564     0.312     0.402       141\n",
      "\n",
      "    accuracy                          0.480       252\n",
      "   macro avg      0.503     0.503     0.471       252\n",
      "weighted avg      0.511     0.480     0.463       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_df.Direction, test_df.preds)\n",
    "cm_df = pd.DataFrame(cm, index=['Down','Up'], columns=['Down','Up'])\n",
    "cm_df.index.name = 'True'\n",
    "cm_df.columns.name = 'Predicted'\n",
    "print(cm_df)\n",
    "print()\n",
    "print(classification_report(test_df.Direction, test_df.preds, digits=3))  # 정밀도 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 모델은 훈련 세트에서 부정확한 예측 비율이 52.0%이다\n"
     ]
    }
   ],
   "source": [
    "print('이 모델은 훈련 세트에서 부정확한 예측 비율이 %0.1f%%이다' \n",
    "      % (100*np.mean(test_df.preds != test_df.Direction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과는 다소 실망스럽다. 왜냐하면 테스트 오류율이 52.0%로 무작위 추측보다 더 나쁘기 때문이다! 물론 이 결과는 그다지 놀라운 것은 아니다. 일반적으로 주식시장에서는 전날의 수익률을 사용하여 미래의 시장을 예측할 수 있을 것으로는 기대하지 않기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**일부 예측변수 제거**\n",
    "\n",
    "앞의 로지스틱 회귀 모델 추정 결과를 보면, 모든 예측변수의 $p$값이 상당히 크고, 그나마 가장 작은 $p$값은 `Lag1`에 해당한다. 예측에 도움이 되지 않는 변수를 제거하면 보다 효과적인 모델을 얻을지도 모른다. 반응변수와 관계가 없는 예측변수를 사용하면 테스트 오류율이 나빠지는 경향이 있으므로 이러한 예측변수들을 제거해보기로 하자. \n",
    "\n",
    "아래에서는 원래 로지스틱 회귀 모델에서 그나마 예측력이 괜찮아 보이는 `Lag1`과 `Lag2`만 사용하여 로지스틱 회귀를 재구성했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692085\n",
      "         Iterations 3\n"
     ]
    }
   ],
   "source": [
    "train_fit = smf.logit('DirCoded ~ Lag1 + Lag2', train_df).fit()\n",
    "predicted_probs = train_fit.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 모델은 테스트 세트에서 정확한 예측 비율이 56.0%이다\n"
     ]
    }
   ],
   "source": [
    "a = ['Up' if p > 0.5 else 'Down' for p in predicted_probs]\n",
    "test_df = test_df.assign(preds = a)\n",
    "print('이 모델은 테스트 세트에서 정확한 예측 비율이 %0.1f%%이다' \n",
    "      % (100*np.mean(test_df.preds == test_df.Direction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  Down   Up\n",
      "True                \n",
      "Down         35   76\n",
      "Up           35  106\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.500     0.315     0.387       111\n",
      "          Up      0.582     0.752     0.656       141\n",
      "\n",
      "    accuracy                          0.560       252\n",
      "   macro avg      0.541     0.534     0.522       252\n",
      "weighted avg      0.546     0.560     0.538       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_df.Direction, test_df.preds)\n",
    "cm_df = pd.DataFrame(cm, index=['Down','Up'], columns=['Down','Up'])\n",
    "cm_df.index.name = 'True'\n",
    "cm_df.columns.name = 'Predicted'\n",
    "print(cm_df)\n",
    "print()\n",
    "print(classification_report(test_df.Direction, test_df.preds, digits=3))  # 정밀도 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 결과가 조금 더 나아졌다. 전체 날짜 중 56.0%가 올바르게 예측되었다. 그런데 아래 계산에도 나오지만, 그냥 \"시장이 항상 상승한다\"고 예측해도 전체의 56%는 맞출 수 있다. 그런 의미에서 이런 식의 단순한 예측(시장이 항상 상승한다고 예측하는 것)에 비해 로지스틱 회귀 방법이 오류율 측면에서 더 낫다고 할 수 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5595238095238095"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.DirCoded.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 다른 한편으로 위의 혼동행렬에서 시장이 상승할 것으로 예측한 날만 본다면 로지스틱 회귀의 정확도(즉 정밀도)가 58.24%이다.(총 76+106=182번 상승할 것으로 예측했으며, 이중 106번 제대로 예측하였다.) 따라서 모델이 상승을 예측할 때는 매수하고 하락을 예측할 때는 거래를 피하는 전략을 생각해볼 수 있다. 물론 이 약간의 개선이 진짜인지 아니면 우연한 기회 때문인지는 좀 더 신중하게 판단해야 할 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 캐러밴 보험 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "ISLP에서 제공하는 Caravan 데이터세트는 사람들의 캐러밴 보험(caravan insurance) 가입과 관련된 데이터이다. 조사대상은 총 5,822명이고, 이들에 대해 인구통계적(demographic) 특성과 관련된 85개의 예측변수가 들어있다. 반응변수는 `Purchase`로서 각 개인이 캐러밴 보험을 구매했는지 여부를 나타낸다. 데이터를 보면 조사대상 중 6%만이 캐러밴 보험에 가입했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
       "0       33         1        3         2         8       0       5       1   \n",
       "1       37         1        2         2         8       1       4       1   \n",
       "2       37         1        2         2         8       0       4       2   \n",
       "3        9         1        3         3         3       2       3       2   \n",
       "4       40         1        4         2        10       1       4       1   \n",
       "\n",
       "   MGODGE  MRELGE  ...  APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  APLEZIER  \\\n",
       "0       3       7  ...         0        0        0       1        0         0   \n",
       "1       4       6  ...         0        0        0       1        0         0   \n",
       "2       4       3  ...         0        0        0       1        0         0   \n",
       "3       4       5  ...         0        0        0       1        0         0   \n",
       "4       4       7  ...         0        0        0       1        0         0   \n",
       "\n",
       "   AFIETS  AINBOED  ABYSTAND  Purchase  \n",
       "0       0        0         0        No  \n",
       "1       0        0         0        No  \n",
       "2       0        0         0        No  \n",
       "3       0        0         0        No  \n",
       "4       0        0         0        No  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Caravan = pd.read_csv('../Data/Caravan.csv')\n",
    "Caravan.Purchase = Caravan.Purchase.astype('category')\n",
    "Caravan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purchase\n",
       "No     5474\n",
       "Yes     348\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Caravan.Purchase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05977327378907592"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Caravan.Purchase.value_counts()['Yes']/len(Caravan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caravan 데이터세트에서 처음 85개 변수를 예측변수(`X`)로 하고, `Purchase` 변수를 반응변수(`y`)로 설정한다. 이와 함께 전체 데이터세트에서 처음 1,000개의 관측을 테스트 세트로 하고 나머지 관측을 훈련 세트로 분할한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Caravan.iloc[:, 0:85]\n",
    "y = Caravan.Purchase\n",
    "\n",
    "X_train = X[1000:]\n",
    "y_train = y[1000:]\n",
    "\n",
    "X_test = X[:1000]\n",
    "y_test = y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 관측 1,000명 중 캐러밴 보험에 가입한 비율은 5.9%임을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()['Yes']/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 세트에 로짓 모델을 피팅하고 테스트 데이터에 대해 추정 성과를 평가해보자. 그런데 여기서는 `statsmodels` 대신 사이킷런(`sklearn.linear_model`)의 `LogisticRegression` 모듈을 이용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit_model = LogisticRegression(fit_intercept=True, max_iter=10000)\n",
    "logit_fit = logit_model.fit(X_train, y_train)\n",
    "logit_pred_50 = pd.Series(logit_fit.predict_proba(X_test)[:, 1] \n",
    "                          > 0.5).map({False: 'No', True: 'Yes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   No  Yes\n",
      "True               \n",
      "No         939    2\n",
      "Yes         59    0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.941     0.998     0.969       941\n",
      "         Yes      0.000     0.000     0.000        59\n",
      "\n",
      "    accuracy                          0.939      1000\n",
      "   macro avg      0.470     0.499     0.484      1000\n",
      "weighted avg      0.885     0.939     0.911      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, logit_pred_50)  \n",
    "cm_df = pd.DataFrame(cm, index=['No','Yes'], columns=['No','Yes'])\n",
    "cm_df.index.name = 'True'\n",
    "cm_df.columns.name = 'Predicted'\n",
    "print(cm_df)\n",
    "print()\n",
    "print(classification_report(y_test, logit_pred_50, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**추정 결과 해석**\n",
    "\n",
    "1,000명의 테스트 관측에 대한 로지스틱 회귀의 오류율은 6.1% 수준이다. 언뜻보기에 이것은 상당히 좋은 것처럼 보일 수 있다. 그러나 테스트 세트 고객의 5.9%만이 보험을 구매했기 때문에 예측변수의 값에 상관없이 항상 `No`를 예측하면 오류율을 5.9%로 낮출 수 있어 이것은 좋은 성과라 할 수 없다. \n",
    "\n",
    "그런데 보험을 판매하는 데 어느 정도 비용이 든다고 생각해보자. 예를 들어, 영업 사원이 각 잠재 고객을 방문하는 데는 비용이 든다. 회사가 무작위로 고객에게 보험을 판매하려고 하면 우리 데이터의 경우 성공률은 5.9%에 불과하다. 관련 비용을 고려하면 이 정도의 성공률은 너무 낮은 편이다. 이러한 상황에서 **보험을 구매할 가능성이 있는 고객에게만 보험을 판매하는 전략**을 생각해보자. 이 경우 전체 오류율은 중요하지 않고, 보험을 구매할 것으로 예측된 사람들에 대한 오류율이 중요하다.\n",
    "\n",
    "그런데 위 결과에서 로지스틱 모델이 보험을 구매할 것으로 예상한 고객에 대해서만 살펴보더라도 결과는 아주 나쁜 편이다. 테스트 관측 중 단 2명만 보험을 구매할 것으로 예측되었으며, 더욱이 이 모든 예측이 틀렸기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 예측 성공 확률 분계점으로 위와 같이 0.5를 고집할 이유는 없다. 가령 예상 구매 확률이 0.25를 초과할 때 구매를 하는 것으로 해보자. 아래 결과를 보면, 이 경우 27명이 보험에 가입할 것으로 예측되고, 이 중 8명(29.6%)에 대해 정확하다. 이것은 (모델에 의존하지 않고 무작위로 사람을 골라 보험을 권유하는) 무작위 추측(random guessing)보다 5배 가량 우수한 성과이다.(무작위 추측의 성공 확률은 5.9%임.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred_25 = pd.Series(logit_fit.predict_proba(X_test)[:, 1] \n",
    "                          > 0.25).map({False: 'No', True: 'Yes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   No  Yes\n",
      "True               \n",
      "No         923   18\n",
      "Yes         51    8\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.948     0.981     0.964       941\n",
      "         Yes      0.308     0.136     0.188        59\n",
      "\n",
      "    accuracy                          0.931      1000\n",
      "   macro avg      0.628     0.558     0.576      1000\n",
      "weighted avg      0.910     0.931     0.918      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, logit_pred_25)  \n",
    "cm_df = pd.DataFrame(cm, index=['No','Yes'], columns=['No','Yes'])\n",
    "cm_df.index.name = 'True'\n",
    "cm_df.columns.name = 'Predicted'\n",
    "print(cm_df)\n",
    "print()\n",
    "print(classification_report(y_test, logit_pred_25, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 데이터\n",
    "\n",
    "타이타닉호는 영국의 화이트 스타 라인이 운영한 북대서양 횡단 여객선으로서 1912년 4월 10일 영국의 사우샘프턴을 떠나 미국 뉴욕으로 향하던 첫 항해 중에 4월 15일 빙산과 충돌하여 침몰하였다. 침몰 당시 구명정이 충분하지 않아 2,224명의 승객 및 승무원 중 1,502명이 사망했다.\n",
    "\n",
    "`Titanic` 데이터세트는 Kaggle에서 주최한 머신러닝 대회 \"[Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/overview)\"에서 제공한 것을 사용한다. 대회의 경쟁 내용은 간단하다. 타이타닉호에서 살아남은 승객을 예측하는 통계적 학습 모델을 만드는 것으로 어떤 통계 모델의 예측력이 우수한지를 겨루었다. 훈련 데이터세트는 891명의 승객에 대해 생존 여부를 포함해 총 12개의 변수가 들어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.00</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass                                      Name  \\\n",
       "PassengerId                                                               \n",
       "887                 0       2                     Montvila, Rev. Juozas   \n",
       "888                 1       1              Graham, Miss. Margaret Edith   \n",
       "889                 0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "890                 1       1                     Behr, Mr. Karl Howell   \n",
       "891                 0       3                       Dooley, Mr. Patrick   \n",
       "\n",
       "                Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
       "PassengerId                                                                \n",
       "887            male  27.0      0      0      211536  13.00   NaN        S  \n",
       "888          female  19.0      0      0      112053  30.00   B42        S  \n",
       "889          female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
       "890            male  26.0      0      0      111369  30.00  C148        C  \n",
       "891            male  32.0      0      0      370376   7.75   NaN        Q  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titanic = pd.read_csv('http://bit.ly/kaggletrain', index_col='PassengerId')\n",
    "Titanic.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**변수**\n",
    "\n",
    "- `Survived`: 생존 더미변수(0 = No, 1 = Yes)\n",
    "- `Pclass`: 티켓 등급(1 = 1st, 2 = 2nd, 3 = 3rd) \n",
    "- `Sex`: 성별 \t\n",
    "- `Age`: 나이(년)\t\n",
    "- `SibSp`: 타이타닉에 함께 승선한 형제/배우자 숫자\t\n",
    "- `Parch`: 타이타닉에 함께 승선한 부모/자녀 숫자\n",
    "- `Ticket`: 티켓 번호\n",
    "- `Fare`: 여객 운임\t\n",
    "- `Cabin`: 캐빈 번호\n",
    "- `Embarked`: 승선 항구(C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀에 사용할 `Age` 변수에 데이터가 빠진 관측들을 제외시키면 관측이 714개로 줄어든다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 11)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titanic = Titanic.dropna(subset=['Age'])\n",
    "Titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**단순 선형 회귀 모델 추정**\n",
    "\n",
    "예시적 목적으로 예측변수가 하나만 있는 단순 선형 회귀 모델을 피팅해보기로 하자. 반응변수는 생존 더미변수인 `Survived`이고, 예측변수는 `Age`이다. 이렇게 모델을 피팅한 다음, 각 `Age` 값에 대해서 적합값(생존 확률 추정값)을 구해 산점도 위에 그렸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('Survived ~ Age', data=Titanic)\n",
    "olsfit = model.fit()\n",
    "y_pred = olsfit.predict(Titanic['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.scatter(Titanic['Age'], Titanic['Survived'], s=20)\n",
    "plt.plot(Titanic['Age'], y_pred, color='red')\n",
    "plt.title('Linear Regression', fontsize=12)\n",
    "plt.xlabel('Age', fontsize=10)\n",
    "plt.ylabel('Survived', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**단순 로짓 모델 추정**\n",
    "\n",
    "이번에는 단순 로짓 모델을 피팅해보기로 하자. 앞에서와 마찬가지로 반응변수는 생존 더미변수인 `Survived`이고, 예측변수는 `Age`이다. 로짓 모델을 피팅한 다음, 각 `Age` 값에 대해서 적합값(확률 추정값)을 구해 산점도 위에 그렸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.672429\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "model = smf.logit('Survived ~ Age', data=Titanic)\n",
    "logitfit = model.fit()\n",
    "y_pred = logitfit.predict(Titanic['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.scatter(Titanic['Age'], Titanic['Survived'], s=20)\n",
    "plt.plot(Titanic['Age'], y_pred, color='red')\n",
    "plt.title('Logistic Regression', fontsize=12)\n",
    "plt.xlabel('Age', fontsize=10)\n",
    "plt.ylabel('Survived', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**선형 회귀선 vs. 로지스틱 회귀선 비교**\n",
    "\n",
    "위 선형 모델과 로지스틱 모델은 둘 다 `Age`를 예측변수로 사용하여 생존 확률을 추정한 것이다. `Age`와 `Survived` 평면상의 산점도 위에 그려진 빨간색 선이 각 `Age` 값에 대해서 생존 확률을 추정한 적합값(fitted value)이다. 두 모델의 추정 회귀선을 비교해보면 거의 차이가 없는 것을 알 수 있다. \n",
    "\n",
    "우리는 앞에서 선형 모델의 경우 추정 확률이 0과 1 사이에서 벗어날 가능성이 있기 때문에 로지스틱 모델을 사용한다고 설명했는데, 사실 위 추정 결과를 보면 선형 모델 역시 추정된 생존 확률이 (`Age`의 가능한 범위 내에서) 0과 1 사이의 범위에서 벗어날 가능성은 전혀 없어 보인다. 이항(binary) 반응 데이터를 선형 회귀 모델로 추정하는 것이 완전히 엉뚱한 일은 아니라는 것을 보여준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다중 로짓 모델 추정**\n",
    "\n",
    "이번에는 `Age` 변수뿐만 아니라 `Pclass`(티켓 등급), `Sex`(성별), `Sibsp`(승선한 형제/배우자 숫자), `Parch`(승선한 부모/자녀 숫자), `Fare`(여객 운임), `Embarked`(승선 항구) 등을 포함시켜 로지스틱 모델로 추정해보자. \n",
    "\n",
    "그런데 `Pclass`, `Sex`, `Embarked`는 범주형 변수이다. 앞에서도 설명했듯이 이런 범주형 변수를 예측변수로 사용할 경우, 우리가 굳이 더미변수를 만들어 넣지 않아도 `statsmodels` 모듈이 알아서 더미변수를 만들어 추정한다. 그런데 이때 유의할 점이 하나 있는데, `Pclass`(티켓 등급) 변수의 경우에는 티켓 등급의 범주가 1, 2, 3의 숫자로 돼있다는 점이다. 즉, 등급 범주가 문자로 표시된 것이 아니라 숫자로 돼있다. 이 경우 `Pclass`를 예측변수로 그대로 사용하면, `statsmodels` 모듈은 이것을 범주형 변수가 아니라 정량적 변수로 인식하여 더미변수를 만들지 않고 `Age` 등 다른 정량적 변수와 동일하게 취급한다. 이를 막기 위해서는(즉, 더미변수를 만들어 추정하도록 만들기 위해서는), 아래 나와 있는 것처럼 `Pclass`가 아니라 `C(Pclass)`로 표시해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.444060\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  712\n",
      "Model:                          Logit   Df Residuals:                      702\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Wed, 03 Sep 2025   Pseudo R-squ.:                  0.3419\n",
      "Time:                        06:52:20   Log-Likelihood:                -316.17\n",
      "converged:                       True   LL-Null:                       -480.45\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.249e-65\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          4.4329      0.536      8.271      0.000       3.383       5.483\n",
      "C(Pclass)[T.2]    -1.1896      0.329     -3.614      0.000      -1.835      -0.544\n",
      "C(Pclass)[T.3]    -2.3952      0.343     -6.976      0.000      -3.068      -1.722\n",
      "Sex[T.male]       -2.6379      0.223    -11.829      0.000      -3.075      -2.201\n",
      "Embarked[T.Q]     -0.8234      0.600     -1.372      0.170      -2.000       0.353\n",
      "Embarked[T.S]     -0.4028      0.275     -1.467      0.142      -0.941       0.135\n",
      "Age               -0.0433      0.008     -5.204      0.000      -0.060      -0.027\n",
      "SibSp             -0.3629      0.129     -2.807      0.005      -0.616      -0.110\n",
      "Parch             -0.0604      0.124     -0.487      0.626      -0.303       0.183\n",
      "Fare               0.0015      0.003      0.559      0.576      -0.004       0.007\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "formula = 'Survived ~ C(Pclass) + Sex + Age + SibSp + Parch + Fare + Embarked'\n",
    "model = smf.logit(formula, data = Titanic)\n",
    "logitfit = model.fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**추정 결과 해석**\n",
    "\n",
    "`Embarked`(승선 항구), `Parch`(승선한 부모/자녀 숫자), `Fare`(여객 운임) 변수들은 타이타닉 생존 여부와 관련하여 통계적으로 유의하지 않다. `Pclass`(티켓 등급)의 경우 2등석 그룹은 1등석에 비해 생존 가능성이 더 낮고, 3등석 그룹은 1등석은 물론이고 2등석보다 생존 가능성이 더 낮은 경향이 있는 것으로 나타났다(통계적으로 유의함). 그밖에 남성일수록, 나이가 많을수록, 함께 승선한 형제/배우자 숫자가 많을수록 생존 가능성이 낮은 경향이 있는 것으로 나타났다(통계적으로 유의함)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT Q&A\n",
    "\n",
    ">**다음은 타이타닉호 생존(Survived) 여부를 로짓 모델로 추정한 결과이다. 여기에서 age(나이) 변수의 추정 계수와 표준오차, z값, p값의 의미에 대해 알기 쉽게 설명해줘.**\n",
    ">\n",
    ">coef    std err          z      P>|z|      [0.025      0.975]  \n",
    ">\n",
    ">Intercept          4.4329      0.536      8.271      0.000       3.383       5.483  \n",
    "C(Pclass)[T.2]    -1.1896      0.329     -3.614      0.000      -1.835      -0.544  \n",
    "C(Pclass)[T.3]    -2.3952      0.343     -6.976      0.000      -3.068      -1.722  \n",
    "Sex[T.male]       -2.6379      0.223    -11.829      0.000      -3.075      -2.201  \n",
    "Embarked[T.Q]     -0.8234      0.600     -1.372      0.170      -2.000       0.353  \n",
    "Embarked[T.S]     -0.4028      0.275     -1.467      0.142      -0.941       0.135  \n",
    "Age               -0.0433      0.008     -5.204      0.000      -0.060      -0.027  \n",
    "SibSp             -0.3629      0.129     -2.807      0.005      -0.616      -0.110  \n",
    "Parch             -0.0604      0.124     -0.487      0.626      -0.303       0.183  \n",
    "Fare               0.0015      0.003      0.559      0.576      -0.004       0.007  \n",
    "\n",
    "---\n",
    "\n",
    ">이 로지스틱 회귀 모델에서 'age' (나이) 변수의 추정 계수와 관련된 통계치들은 다음과 같은 의미를 가집니다:\n",
    ">\n",
    ">1. **계수 (coef): -0.0433**\n",
    ">    - 이 값은 나이가 한 살 증가할 때마다 생존 확률의 로그 오즈(log odds)가 평균적으로 -0.0433만큼 변한다는 것을 의미합니다. 로그 오즈는 생존 확률과 사망 확률의 비율의 로그 값입니다. 여기서 계수가 음수이므로, 나이가 증가함에 따라 생존 확률이 감소한다는 것을 암시합니다.\n",
    ">\n",
    ">2. **표준오차 (std err): 0.008**\n",
    ">    - 표준오차는 계수 추정치의 정확도를 나타냅니다. 낮은 표준오차는 더 정확한 추정치를 의미합니다. 여기서 표준오차가 0.008인 것은 이 계수 추정치가 일정한 정확도를 가지고 있음을 나타냅니다.\n",
    ">\n",
    ">3. **z 값: -5.204**\n",
    ">    - z 값은 계수 추정치가 0인지 아닌지를 판단하기 위한 통계적 검정치입니다. 계수가 표준오차의 몇 배인지 나타냅니다. 여기서 z 값이 -5.204인 것은 계수가 표준오차보다 약 5.204배 더 멀리 떨어져 있다는 것을 의미하며, 이는 통계적으로 유의한 결과입니다.\n",
    ">\n",
    ">4. **p 값 (P>|z|): 0.000**\n",
    ">    - p 값은 계수의 통계적 유의성을 나타냅니다. 일반적으로 p 값이 0.05 미만이면 계수가 통계적으로 유의미하다고 간주됩니다. 이 경우 p 값이 0.000으로 나타나므로, 'age' 변수의 계수는 통계적으로 매우 유의미합니다. 이는 나이가 생존 여부에 중요한 영향을 미친다는 것을 의미합니다.\n",
    ">\n",
    ">따라서 이 결과는 타이타닉호 데이터에서 나이가 증가함에 따라 생존 확률이 감소한다는 것을 통계적으로 유의미하게 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**피팅 성과**\n",
    "\n",
    "아래는 훈련 세트에 대해 혼동행렬을 구한 것이다. 생존 확률 분계점은 0.5를 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred = pd.Series(logitfit.predict(Titanic) > 0.5).map({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0    1\n",
      "True               \n",
      "0          365   59\n",
      "1           85  205\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.811     0.861     0.835       424\n",
      "           1      0.777     0.707     0.740       290\n",
      "\n",
      "    accuracy                          0.798       714\n",
      "   macro avg      0.794     0.784     0.788       714\n",
      "weighted avg      0.797     0.798     0.797       714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Titanic.Survived, logit_pred)  \n",
    "cm_df = pd.DataFrame(cm, index=[0,1], columns=[0,1])\n",
    "cm_df.index.name = 'True'\n",
    "cm_df.columns.name = 'Predicted'\n",
    "print(cm_df)\n",
    "print()\n",
    "print(classification_report(Titanic.Survived, logit_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 부록: 혼동행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**혼동행렬**(confusion matrix, 분류결과표)은 다음과 같이 모형이 예측한 범주가 실제 범주와 일치하는지를 표로 나타낸 것이다.\n",
    "\n",
    "![혼동행렬](https://raw.githubusercontent.com/pilsunchoi/images/main/7-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사례\n",
    "\n",
    "**(1) 금융 사기**\n",
    "- True Positive: 사기를 사기라고 정확하게 예측\n",
    "- True Negative: 정상을 정상이라고 정확하게 예측\n",
    "- False Positive: 정상을 사기라고 잘못 예측\n",
    "- False Negative: 사기를 정상이라고 잘못 예측\n",
    "\n",
    "**(2) 코로나19 감염 진단**\n",
    "- True Positive: 양성을 양성으로 정확하게 진단\n",
    "- True Negative: 음성을 음성으로 정확하게 진단\n",
    "- False Positive: 음성을 양성으로 잘못 진단\n",
    "- False Negative: 양성을 음성으로 잘못 진단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다양한 평가기준\n",
    "\n",
    "가령 100명 중 코로나19 바이러스 양성이 1명이고, 나머지 99명은 음성이라고 할 때, 진단 키트가 모든 사람을 무조건 음성이라고 판단할 경우, 정확도가 99%나 되지만 이 진단 키트가 우수하다고 말할 수는 없다. 정확도가 조금 떨어지더라도 양성을 제대로 포착해야 하기 때문이다. 그렇다고 너무 많은 false alarm이 있어서도 안 된다. 이는 우리가 어떤 진단(분류) 장비나 모델을 평가할 때, 정확도만으로 판단할 수는 없고 다양한 기준이 있어야 함을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정확도(accuracy)**\n",
    "\n",
    "전체 관측 중 올바르게 예측한 관측의 비율이다. 정확도가 높을수록 좋은 예측 모형이다.\n",
    "\n",
    "$$\n",
    "\\rm accuracy= \\frac {TP+TN}{TP+TN+FP+FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정밀도(precision)**\n",
    "\n",
    "**양성으로 예측된 관측 중** 실제로 양성인 관측의 비율이다. 정밀도가 높을수록 좋은 예측 모형이다.\n",
    "\n",
    "$$\n",
    "\\rm precision = \\frac {TP}{TP+FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**재현율(recall)**\n",
    "\n",
    "**실제 양성 관측 중** 양성으로 예측된 관측의 비율이다. 재현율이 높을수록 좋은 예측 모형이다. 진양성률(TPR: true positive rate) 또는 **민감도**(sensitivity)라고도 한다.\n",
    "\n",
    "$$\n",
    "\\rm sensitivity = \\frac {TP}{TP+FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**특이도(specificity)**\n",
    "\n",
    "**실제 음성 관측 중** 음성으로 예측된 관측의 비율이다. 특이도가 높을수록 좋은 예측 모형이다. 진음성률(TNR: true negative rate)이라고도 한다. \n",
    "\n",
    "$$\n",
    "\\rm specificity = \\frac {TN}{TN+FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**위양성률(FPR)**\n",
    "\n",
    "위양성률(FPR: false positive rate)은 실제 음성인데 양성으로 예측된 관측의 비율이다. fall-out이라고도 한다. 다른 평가점수와 달리 위양성률은 그 값이 낮을수록 좋다. 1에서 특이도를 빼면 위양성률이 나온다.  \n",
    "\n",
    "$$\n",
    "\\rm FPR = 1 - specificity = \\frac {FP}{TN+FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런 혼동행렬 표 읽는 법\n",
    "\n",
    "사이킷런(`sklearn`)이 제공하는 `classification_report()` 함수를 실행했을 때 반환되는 표의 각 항목들이 어떻게 계산된 것인지 알아보자. \n",
    "\n",
    "다음은 타이타닉 데이터세트를 다중 로짓 모델 추정한 후 `confusion_matrix()` 및 `classification_report()`를 실행한 결과이다.(앞의 마지막 분석 결과를 그대로 다시 가져온 것이다.) 표에 빨간색으로 적힌 1번부터 5번까지 번호 별로 해당 비율이 어떻게 계산되었는지 아래 설명이 나와 있다.\n",
    "\n",
    "![혼동행렬 표](https://raw.githubusercontent.com/pilsunchoi/images/main/7-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) accuracy**\n",
    "\n",
    "전체 관측 중 올바르게 예측한 관측의 비율 => $\\frac {365+205}{365+59+85+205}=0.798$\n",
    "\n",
    "**(2) precision**\n",
    "\n",
    "원래 정의는 양성으로 예측된 관측 중 실제로 양성인 관측의 비율이다. 그런데 어떤 범주가 \"양성(positive)\"인지 모르기 때문에 0과 1 범주 각각에 대해 precision을 계산한다. \n",
    "\n",
    "* 0이 양성일 때의 precision => 0으로 예측된 관측 중 실제로 0인 관측의 비율 => $\\frac{365}{365+85}=0.811$\n",
    "\n",
    "\n",
    "* 1이 양성일 때의 precision => 1로 예측된 관측 중 실제로 1인 관측의 비율 => $\\frac{205}{59+205}=0.777$\n",
    "\n",
    "**(3) recall**\n",
    "\n",
    "원래 정의는 실제 양성 관측 중 양성으로 예측된 관측의 비율이다. 그런데 어떤 범주가 \"양성(positive)\"인지 모르기 때문에 0과 1 범주 각각에 대해 recall을 계산한다. \n",
    "\n",
    "* 0이 양성일 때의 recall => 실제로 0인 관측 중 0으로 예측된 관측의 비율 => $\\frac{365}{365+59}=0.861$\n",
    "\n",
    "\n",
    "* 1이 양성일 때의 recall => 실제로 1인 관측 중 1로 예측된 관측의 비율 => $\\frac{205}{85+205}=0.707$\n",
    "\n",
    "**(4) f1-score**\n",
    "\n",
    "precision과 recall의 조화평균(harmonic mean)을 f1-score라고 하며, 다음과 같이 계산된다.\n",
    "\n",
    "$$\n",
    " \\text{f1-score} \\rm= \\frac {2 \\times precision \\times recall}{precision + recall}\n",
    "$$\n",
    "\n",
    "* 0을 양성으로 간주할 때의 f1-score => $\\frac{2\\times0.811\\times0.861}{0.811+0.861}=0.835$\n",
    "\n",
    "\n",
    "* 1을 양성으로 간주할 때의 f1-score => $\\frac{2\\times0.777\\times0.707}{0.777+0.707}=0.740$\n",
    "\n",
    "**(5) 평가점수 평균**\n",
    "\n",
    "`macro avg`는 단순평균이고, `weighted avg`는 각 범주에 속하는 표본의 개수를 가중치로 하여 가중평균한 것이다. precision에 대해서만 평균을 계산해보면 다음과 같다.\n",
    "\n",
    "* precision의 `macro avg` => $\\frac{0.811+0.777}{2}=0.794$\n",
    "\n",
    "\n",
    "* precision의 `weighted avg` => $\\frac{424}{714}\\times0.811+\\frac{290}{714}\\times0.777=0.797$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
