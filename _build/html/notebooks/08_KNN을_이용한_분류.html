
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>8장 KNN 분류 &#8212; 데이터과학의 첫걸음</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/08_KNN을_이용한_분류';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9장 나이브 베이즈 분류" href="09_%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98.html" />
    <link rel="prev" title="7장 로지스틱 회귀를 이용한 분류" href="07_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EB%B6%84%EB%A5%98.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="00_%EC%84%9C%EB%AC%B8.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="데이터과학의 첫걸음 - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="데이터과학의 첫걸음 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00_%EC%84%9C%EB%AC%B8.html">
                    데이터과학의 첫걸음: 시작하며
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0.html">1장 파이썬 시작하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EC%BD%94%EB%94%A9_%EA%B8%B0%EC%B4%88.html">2장 파이썬 코딩 기초</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_%EC%9D%80%ED%96%89_%ED%85%94%EB%A0%88%EB%A7%88%EC%BC%80%ED%8C%85_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html">3장 은행 텔레마케팅 데이터 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_%EC%A0%84%EC%9E%90%EC%83%81%EA%B1%B0%EB%9E%98_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html">4장 전자상거래 데이터 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_%ED%86%B5%EA%B3%84%EC%A0%81_%ED%95%99%EC%8A%B5.html">5장 통계적 학습</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80.html">6장 선형 회귀</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EB%B6%84%EB%A5%98.html">7장 로지스틱 회귀를 이용한 분류</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">8장 KNN 분류</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98.html">9장 나이브 베이즈 분류</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_%EB%B3%80%EC%88%98%EC%84%A0%ED%83%9D_%EB%B0%8F_%EC%A0%95%EA%B7%9C%ED%99%94.html">10장 변수선택 및 정규화</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_%EC%B6%94%EC%B2%9C_%EC%8B%9C%EC%8A%A4%ED%85%9C.html">11장 추천 시스템</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%EB%A7%8C%EB%93%A4%EA%B8%B0.html">12장 결정 트리 만들기</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_%ED%8A%B8%EB%A6%AC_%EA%B8%B0%EB%B0%98_%EB%AA%A8%ED%98%95.html">13장 트리 기반 모형</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_%EC%84%9C%ED%8F%AC%ED%8A%B8_%EB%B2%A1%ED%84%B0_%EB%A8%B8%EC%8B%A0.html">14장 서포트 벡터 머신</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%9E%85%EB%AC%B8.html">15장 딥러닝 입문</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5%EA%B3%BC_%EC%A3%BC%EC%84%B1%EB%B6%84_%EB%B6%84%EC%84%9D.html">16장 비지도학습과 주성분 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="17_%EC%83%9D%EC%A1%B4%EB%B6%84%EC%84%9D.html">17장 생존분석</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pilsunchoi/book1" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pilsunchoi/book1/issues/new?title=Issue%20on%20page%20%2Fnotebooks/08_KNN을_이용한_분류.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/08_KNN을_이용한_분류.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>8장 KNN 분류</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">8.1 개요</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">베이즈 분류기</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k">K-최근접이웃</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">KNN 그림 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">KNN 기법 숫자 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-q-a">ChatGPT Q&amp;A</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">8.2 데이터 분석 예제</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">주식시장 데이터</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">KNN 분류</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">ChatGPT Q&amp;A</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">혼동행렬</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">캐러밴 보험 데이터</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">데이터 표준화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">KNN 분류</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="knn">
<h1>8장 KNN 분류<a class="headerlink" href="#knn" title="Link to this heading">#</a></h1>
<p>자료 출처: <a class="reference external" href="https://www.statlearning.com/">ISLP (An Introduction to Statistical Learning with Applications in Python)</a></p>
<p><strong>K-최근접이웃(K-nearest neighbors:</strong> KNN)은 1951년 Fix와 Hodges에 의해 처음 개발된 비파라미터적 지도학습(non-parametric supervised learning) 방법이다. 원리가 매우 직관적인데, 어떤 관측의 출력(반응)을 예측함에 있어서 해당 관측의 입력값과 <strong>가장 가까운</strong> <span class="math notranslate nohighlight">\(K\)</span>개의 관측 데이터를 이용한다는 아이디어이다. 분류와 회귀 모두에 사용된다. <strong>분류</strong>(classification)의 경우에 출력은 어떤 범주이기 때문에 이때는 <span class="math notranslate nohighlight">\(K\)</span>개의 가장 가까운 이웃(<span class="math notranslate nohighlight">\(K\)</span>는 양의 정수로 일반적으로 작은 숫자임) 중에서 어떤 범주가 가장 많은지 <strong>다수결 투표 방식</strong>으로 분류된다. 가령 <span class="math notranslate nohighlight">\(K\)</span>가 3이면, 가장 가까운 3개 관측이 어떤 범주이냐에 따라 주어진 관측의 반응 범주가 결정된다. 반면 <strong>회귀</strong>(regression)의 경우에는 출력이 범주가 아니라 어떤 값이기 때문에 이때는 <span class="math notranslate nohighlight">\(K\)</span>개의 최근접이웃 값의 <strong>평균</strong>을 예측값으로 삼는다. 본 장에서는 KNN 회귀는 다루지 않고, KNN 분류에 대해서만 살펴보기로 한다.</p>
<section id="id1">
<h2>8.1 개요<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>분류 문제에서 모형의 정확도를 생각해보자. 훈련 데이터 <span class="math notranslate nohighlight">\({(x_1, y_1), (x_2, y_2),..., (x_n, y_n)}\)</span>으로 <span class="math notranslate nohighlight">\(f\)</span>를 추정하는데, <span class="math notranslate nohighlight">\(y_1, y_2,..., y_n\)</span>이 정성적 변수다. 이럴 때 <span class="math notranslate nohighlight">\(f\)</span> 추정의 정확도를 측정하는 대표적인 방법은 <strong>오류율</strong>(error rate)이다.</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n} \sum_{i=1}^n I\left( y_i \neq \hat y_i \right)
\]</div>
<p>여기서 <span class="math notranslate nohighlight">\(\hat y_i\)</span>는 <span class="math notranslate nohighlight">\(\hat f\)</span>으로 예측한 <span class="math notranslate nohighlight">\(i\)</span>번째 관측에 대한 예측 범주이고, <span class="math notranslate nohighlight">\( I\left( y_i \neq \hat y_i \right)\)</span>은 <span class="math notranslate nohighlight">\(y_i \neq \hat y_i\)</span>이면 값이 1이고, <span class="math notranslate nohighlight">\(y_i = \hat y_i \)</span>이면 값이 0인 소위 지표변수(indicator variable)이다. <span class="math notranslate nohighlight">\( I\left( y_i \neq \hat y_i \right)=0 \)</span>이면, <span class="math notranslate nohighlight">\(i\)</span>번째 관측이 올바르게 분류된 것을 의미하고, 그렇지 않으면 잘못 분류된 것을 의미한다.</p>
<p>결국 위 식은 관측 중에서 분류가 잘못된 것이 몇 개인지를 세어 전체 관측 개수로 나눈 것, 즉 잘못된 분류의 비율이다. 위 식은 훈련 데이터를 기반으로 계산된다는 점에서 훈련 오류율이다. 테스트 데이터에 대한 오류율을 테스트 오류율이라 한다.</p>
<section id="id2">
<h3>베이즈 분류기<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>어떤 식으로 분류해야 오류율을 낮출 수 있을까? 어떤 주어진 관측의 범주를 분류함에 있어서 <strong>가장 가능성이 높은 범주로 분류</strong>해야만 테스트 오류율을 평균적으로 최소화할 수 있다는 것을 이론적으로 증명할 수 있다. 이 분류 방식을 식으로 표현하면, 테스트 관측 <span class="math notranslate nohighlight">\(x_0\)</span>이 주어질 때, 다음의 조건부 확률(conditional probability)이 가장 큰 범주 <span class="math notranslate nohighlight">\(j\)</span>로 테스트 관측의 범주를 예측한다는 것이다.</p>
<div class="math notranslate nohighlight">
\[
{\rm Pr} \left(Y=j~|~X=x_0\right)
\]</div>
<p>이러한 분류 방식을 <strong>베이즈 분류기</strong>(Bayes classifier)라고 한다. 베이즈 분류기는 가능한 가장 낮은 테스트 오류율을 생성하며, 이를 <strong>베이즈 오류율</strong>이라고 한다.</p>
</section>
<section id="k">
<h3>K-최근접이웃<a class="headerlink" href="#k" title="Link to this heading">#</a></h3>
<p>베이즈 분류기를 사용하여 정성적 반응을 예측하고 싶지만, 실제 데이터의 경우 <span class="math notranslate nohighlight">\(X\)</span>가 주어졌을 때 <span class="math notranslate nohighlight">\(Y\)</span>의 조건부 분포를 알지 못하므로 베이즈 분류기를 사용하는 것은 불가능하다. 이에 따라 많은 접근법들은 주어진 <span class="math notranslate nohighlight">\(X\)</span>에 대한 <span class="math notranslate nohighlight">\(Y\)</span>의 조건부 분포를 <strong>추정</strong>한 다음, 추정 확률이 가장 높은 범주로 해당 관측을 분류하는 방식을 취한다. 이러한 방법 중 하나가 <strong>K-최근접이웃(KNN)</strong> 분류기로서 다음과 같은 방식을 취한다.</p>
<ul class="simple">
<li><p>양의 정수 <span class="math notranslate nohighlight">\(K\)</span>와 테스트 관측 <span class="math notranslate nohighlight">\(x_0\)</span>가 주어지면 먼저 훈련 데이터에서 <span class="math notranslate nohighlight">\(x_0\)</span>에 가장 가까운 <span class="math notranslate nohighlight">\(K\)</span>개의 포인트를 식별한다.</p></li>
<li><p>이를 <span class="math notranslate nohighlight">\(\mathcal N_0\)</span>로 표시하면, <span class="math notranslate nohighlight">\(\mathcal N_0\)</span>의 여러 반응에서 <span class="math notranslate nohighlight">\(j\)</span> 범주가 차지하는 비율을 <span class="math notranslate nohighlight">\(j\)</span>에 대한 조건부 확률로 추정한다.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ {\rm Pr} \left(Y=j~|~X=x_0\right)=\frac{1}{K} \sum_{i\in\mathcal N_0}I(y_i=j) \]</div>
<ul class="simple">
<li><p>최종적으로 베이즈 분류 규칙에 따라 각 범주 중 가장 큰 확률을 가진 범주에 테스트 관측 <span class="math notranslate nohighlight">\(x_0\)</span>을 분류한다.</p></li>
</ul>
</section>
<section id="id3">
<h3>KNN 그림 예시<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>아래 그림 8.1은 KNN 접근법을 예시적으로 보여준다. 왼쪽 그림에서 우리의 목표는 검정색 X로 표시된 점의 색깔을 예측하는 것이다. 가령 <span class="math notranslate nohighlight">\(K=3\)</span>을 선택한다면, KNN은 먼저 X에 가장 가까운 3개의 관측을 식별한다. 이 경우 원으로 표시돼있는 X의 이웃(neighborhood)에 파란색 동그라미가 두 개, 그리고 오렌지색이 하나로 구성돼있기 때문에 파란색 범주 확률이 2/3, 오렌지색 범주 확률이 1/3로 추정된다. 따라서 KNN은 X가 파란색 범주에 속할 것으로 예측한다.</p>
<p>그림 8.1의 오른쪽 그림은 <span class="math notranslate nohighlight">\(K=3\)</span>인 KNN 기법을 사용하여 주어진 평면의 모든 격자 점들에 대해 포인트 X를 예측했던 것과 똑같은 방식으로 예측한 결과를 보여준다. 파란색 격자 점들은 해당 포인트가 파란색으로 예측된 것이고, 오렌지색 격자 점들은 오렌지색으로 예측된 것이다. 두 영역을 구분해 놓은 검정색 실선을 <strong>결정 경계</strong>(decision boundary)라고 부른다. 매우 간단한 접근 방식임에도 불구하고 KNN은 종종 최적의 베이즈 분류에 가까운 성과를 보인다.</p>
<p><strong>그림 8.1.</strong> 6개의 파란색 관측과 6개의 오렌지색 관측이 있는 간단한 상황에서 <span class="math notranslate nohighlight">\(K=3\)</span>을 사용하는 KNN 접근 방식.</p>
<p><img alt="KNN 그림 예" src="https://raw.githubusercontent.com/pilsunchoi/images/main/8-1.png" /></p>
<ul class="simple">
<li><p>그림 출처: ISLP, FIGURE 2.14</p></li>
</ul>
<p>KNN 분류는 <span class="math notranslate nohighlight">\(K\)</span>를 어떻게 선택하느냐에 따라 결과가 크게 달라질 수 있다. <span class="math notranslate nohighlight">\(K=1\)</span>인 경우에는 결정 경계가 지나치게 꼬불꼬불할 것이고, <span class="math notranslate nohighlight">\(K\)</span>가 커짐에 따라 유연성(flexibility)이 떨어지고 선형에 가까운 결정 경계를 생성한다. <span class="math notranslate nohighlight">\(K=1\)</span>이면 테스트 데이터에서 가장 가까운 관측의 반응값을 따른다는 것이기 때문에 테스트 데이터의 위치가 조금만 바뀌어도 반응값이 달라질 수 있다. 반면 <span class="math notranslate nohighlight">\(K\)</span>값이 아주 커지면 테스트 데이터 위치가 조금씩 달라지더라도 부근 관측에 의한 다수결의 결과가 달라지지 않을 가능성이 크다. 따라서 이 경우 결정 경계가 선형에 더 가까워지게 된다.</p>
<p>훈련 오류율과 테스트 오류율이 같은 방향으로 움직이지는 않는다. <span class="math notranslate nohighlight">\(K=1\)</span>인 경우 훈련 오류율은 (항상 자신의 올바른 반응 범주를 사용하기 때문에) 0이지만 테스트 오류율은 상당히 높을 수 있다. 일반적으로 유연한 분류 방법을 사용하면 훈련 오류율은 감소하지만 테스트 오류율은 높을 수 있다. 따라서 적절한 수준의 유연성을 선택하는 것이 중요하다.</p>
</section>
<section id="id4">
<h3>KNN 기법 숫자 예시<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>아래 훈련 데이터는 6개의 관측, 3개의 예측변수, 1개의 정성적 반응변수로 이루어져 있다. 이 데이터에 대해 <span class="math notranslate nohighlight">\(K\)</span>-최근접이웃 기법을 사용하여 <span class="math notranslate nohighlight">\(X_1=X_2=X_3=0\)</span>일 때 <span class="math notranslate nohighlight">\(Y\)</span>의 범주가 Red인지 Green인지를 예측하려고 한다.(출처: ISLP, 2장 연습문제 Q7)</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{r|rrrr}
           \rm Obs. &amp; X_1 &amp; X_2 &amp; X_3 &amp; Y      \\ \hline
           1     &amp;  0  &amp;  3  &amp;  0  &amp;  \rm Red   \\
           2     &amp;  2  &amp;  0  &amp;  0  &amp;  \rm Red   \\
           3     &amp;  0  &amp;  1  &amp;  3  &amp;  \rm Red   \\
           4     &amp;  0  &amp;  1  &amp;  2  &amp;  \rm Green \\
           5     &amp; -1  &amp;  0  &amp;  1  &amp;  \rm Green \\
           6     &amp;  1  &amp;  1  &amp;  1  &amp;  \rm Red   \\
\end{array}
\end{split}\]</div>
<p>먼저 테스트 데이터 <span class="math notranslate nohighlight">\(X_1=X_2=X_3=0\)</span>에 대해 주어진 각 관측과의 유클리드 거리를 계산해보자. 두 개의 점 <span class="math notranslate nohighlight">\(\mathbf p =(p_1,p_2,...,p_n)\)</span>와 <span class="math notranslate nohighlight">\(\mathbf q =(q_1,q_2,...,q_n)\)</span>의 유클리드 거리(Euclidean distance)는 다음과 같이 정의된다.</p>
<div class="math notranslate nohighlight">
\[
d(\mathbf p,\mathbf q)=d(\mathbf q,\mathbf p) = \sqrt{(q_1-p_1)^2+(q_2-p_2)^2+ ...+(q_n-p_n)^2}
\]</div>
<p>따라서 각 관측 <span class="math notranslate nohighlight">\((x_1,x_2,x_3)\)</span>와 문제에서 주어진 테스트 관측 <span class="math notranslate nohighlight">\((0,0,0)\)</span> 사이의 유클리드 거리는 다음과 같다.</p>
<div class="math notranslate nohighlight">
\[
d = \sqrt{x_1^2+x_2^2+x_3^2}
\]</div>
<p>여기에서 주어진 예시는 관측이 6개밖에 되지 않아 손으로도 계산이 가능하지만, 연습삼아 코딩으로 계산을 수행해보자. 먼저 데이터를 입력하고 데이터프레임 형태로 저장한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
<span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;X1&#39;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]),</span>
     <span class="s1">&#39;X2&#39;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]),</span>
     <span class="s1">&#39;X3&#39;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]),</span>
     <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="s1">&#39;Red&#39;</span><span class="p">,</span><span class="s1">&#39;Red&#39;</span><span class="p">,</span><span class="s1">&#39;Red&#39;</span><span class="p">,</span><span class="s1">&#39;Green&#39;</span><span class="p">,</span><span class="s1">&#39;Green&#39;</span><span class="p">,</span><span class="s1">&#39;Red&#39;</span><span class="p">])}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>Red</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>Red</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1</td>
      <td>3</td>
      <td>Red</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>Green</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-1</td>
      <td>0</td>
      <td>1</td>
      <td>Green</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>Red</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>각 관측과 <span class="math notranslate nohighlight">\((0,0,0)\)</span> 사이의 유클리드 거리를 계산하여 <code class="docutils literal notranslate"><span class="pre">distance</span></code>라는 이름으로 저장한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;distance&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;X2&#39;</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;X3&#39;</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>Y</th>
      <th>distance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>Red</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>Red</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1</td>
      <td>3</td>
      <td>Red</td>
      <td>3.162278</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>Green</td>
      <td>2.236068</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-1</td>
      <td>0</td>
      <td>1</td>
      <td>Green</td>
      <td>1.414214</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>Red</td>
      <td>1.732051</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>이제 <span class="math notranslate nohighlight">\(K=1\)</span>일 때, 테스트 데이터 <span class="math notranslate nohighlight">\((0, 0, 0)\)</span>의 반응값을 예측해보자. <span class="math notranslate nohighlight">\(K=1\)</span>은 가장 가까운 관측 1개를 이용한다는 것으로서 테스트 데이터와 가장 가까운 관측을 찾으면, 5번(Green) 관측이다. 따라서 테스트 데이터의 <span class="math notranslate nohighlight">\(Y\)</span> 값을 Green으로 예측하게 된다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># sort_values() 메서드를 이용하여 &#39;distance&#39; 기준으로 정렬시킴</span>
<span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;distance&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>Y</th>
      <th>distance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>-1</td>
      <td>0</td>
      <td>1</td>
      <td>Green</td>
      <td>1.414214</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>Red</td>
      <td>1.732051</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>Red</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>Green</td>
      <td>2.236068</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>Red</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1</td>
      <td>3</td>
      <td>Red</td>
      <td>3.162278</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>이번에는 <span class="math notranslate nohighlight">\(K=3\)</span>일 때, 테스트 데이터 <span class="math notranslate nohighlight">\((0, 0, 0)\)</span>의 반응값을 예측해보자. <span class="math notranslate nohighlight">\(K=3\)</span>은 가장 가까운 관측 3개를 이용한다는 것으로서 테스트 데이터와 가장 가까운 관측 3개를 찾으면, 5번(Green) 6번(Red) 2번(Red) 관측이기 때문에 다수결 원칙에 따라 테스트 데이터의 <span class="math notranslate nohighlight">\(Y\)</span>값을 Red로 예측한다.</p>
</section>
<section id="chatgpt-q-a">
<h3>ChatGPT Q&amp;A<a class="headerlink" href="#chatgpt-q-a" title="Link to this heading">#</a></h3>
<p><strong>ChatGPT의 연습문제 풀이(ISLP 2장 연습문제 Q7)</strong></p>
<p><img alt="연습문제 풀이" src="https://raw.githubusercontent.com/pilsunchoi/images/main/8-2.png" /></p>
<blockquote>
<div><p><strong>다음 문제를 풀어줘.(한글로)</strong></p>
<p>The table below provides a training data set containing six observations,<br />
three predictors, and one qualitative response variable.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    Obs.   X1   X2   X3     Y  
     1      0    3    0    Red  
     2      2    0    0    Red  
     3      0    1    3    Red  
     4      0    1    2   Green  
     5     −1    0    1   Green  
     6      1    1    1    Red  
</pre></div>
</div>
<p>Suppose we wish to use this data set to make a prediction for Y when<br />
X1 = X2 = X3 = 0 using K-nearest neighbors.</p>
<p>(a) Compute the Euclidean distance between each observation and<br />
the test point, X1 = X2 = X3 = 0.</p>
<p>(b) What is our prediction with K = 1? Why?</p>
<p>(c) What is our prediction with K = 3? Why?</p>
<p>(d) If the Bayes decision boundary in this problem is highly nonlinear,<br />
then would we expect the best value for K to be large or<br />
small? Why?</p>
</div></blockquote>
<hr class="docutils" />
<blockquote>
<div><p>이 문제는 K-최근접 이웃(K-Nearest Neighbors, KNN) 알고리즘을 사용하여 주어진 데이터 세트를 바탕으로 새로운 관측값에 대한 예측을 하는 것입니다. 주어진 데이터 세트는 6개의 관측치와 3개의 예측변수(X1, X2, X3) 및 1개의 질적 반응 변수(Y)를 가지고 있습니다. 새로운 관측값은 X1 = X2 = X3 = 0입니다.</p>
<p>(a) <strong>유클리디안 거리 계산</strong>:
유클리디안 거리는 두 점 사이의 직선 거리를 계산하는 방법입니다. 각 관측치와 X1 = X2 = X3 = 0 사이의 거리는 다음과 같이 계산됩니다.</p>
<ol class="arabic simple">
<li><p>관측치 1: <span class="math notranslate nohighlight">\(\sqrt{(0-0)^2 + (3-0)^2 + (0-0)^2} = \sqrt{9} = 3\)</span></p></li>
<li><p>관측치 2: <span class="math notranslate nohighlight">\(\sqrt{(2-0)^2 + (0-0)^2 + (0-0)^2} = \sqrt{4} = 2\)</span></p></li>
<li><p>관측치 3: <span class="math notranslate nohighlight">\(\sqrt{(0-0)^2 + (1-0)^2 + (3-0)^2} = \sqrt{10}\)</span></p></li>
<li><p>관측치 4: <span class="math notranslate nohighlight">\(\sqrt{(0-0)^2 + (1-0)^2 + (2-0)^2} = \sqrt{5}\)</span></p></li>
<li><p>관측치 5: <span class="math notranslate nohighlight">\(\sqrt{(-1-0)^2 + (0-0)^2 + (1-0)^2} = \sqrt{2}\)</span></p></li>
<li><p>관측치 6: <span class="math notranslate nohighlight">\(\sqrt{(1-0)^2 + (1-0)^2 + (1-0)^2} = \sqrt{3}\)</span></p></li>
</ol>
<p>(b) <strong>K = 1일 때의 예측</strong>:
K=1일 때, 가장 가까운 하나의 이웃을 기반으로 예측합니다. 위의 계산에 따르면, 가장 가까운 이웃은 관측치 5입니다(거리 = <span class="math notranslate nohighlight">\(\sqrt{2}\)</span>). 관측치 5의 Y 값은 Green이므로, 예측값은 Green입니다.</p>
<p>(c) <strong>K = 3일 때의 예측</strong>:
K=3일 때, 가장 가까운 세 개의 이웃을 기반으로 예측합니다. 가장 가까운 세 관측치는 5번(<span class="math notranslate nohighlight">\(\sqrt{2}\)</span>), 6번(<span class="math notranslate nohighlight">\(\sqrt{3}\)</span>), 그리고 2번(<span class="math notranslate nohighlight">\(\sqrt{4}\)</span>)입니다. 이들의 Y 값은 각각 Green, Red, Red입니다. 다수결에 의해, 예측값은 Red가 됩니다.</p>
<p>(d) <strong>베이즈 결정 경계가 매우 비선형인 경우, K의 최적값</strong>:
베이즈 결정 경계가 매우 비선형인 경우, 작은 K 값을 사용하는 것이 일반적으로 더 좋습니다. 비선형 결정 경계는 로컬한 변화가 많은 복잡한 패턴을 가지고 있기 때문에, 작은 K 값은 이러한 로컬한 패턴을 더 잘 캡처할 수 있습니다. 반면에 큰 K 값은 경계를 너무 단순화하여 복잡한 패턴을 무시할 수 있습니다.</p>
</div></blockquote>
</section>
</section>
<section id="id5">
<h2>8.2 데이터 분석 예제<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p><strong>자료</strong>: <a class="github reference external" href="https://github.com/gperaza/ISLR-Python-Labs">gperaza/ISLR-Python-Labs</a> 및 <a class="github reference external" href="https://github.com/emredjan/ISL-python/tree/master/labs">emredjan/ISL-python</a></p>
<section id="id6">
<h3>주식시장 데이터<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p>ISLP에서 제공하는 <code class="docutils literal notranslate"><span class="pre">Smarket</span></code> 데이터세트는 2001년 초부터 2005년 말까지 1,250일 동안 S&amp;P 500 주가지수의 수익률(%)을 기록한 것이다.</p>
<p><code class="docutils literal notranslate"><span class="pre">Today</span></code>는 각 날짜의 수익률이고, 각 날짜에 대해 이전 5개 거래일의 수익률을 <code class="docutils literal notranslate"><span class="pre">Lag1</span></code>부터 <code class="docutils literal notranslate"><span class="pre">Lag5</span></code>까지의 이름으로 기록했다. 또한 <code class="docutils literal notranslate"><span class="pre">Volume</span></code>은 전날 거래된 주식 수(단위: 십억)이고, <code class="docutils literal notranslate"><span class="pre">Direction</span></code>은 해당 날짜에 시장이 상승(<code class="docutils literal notranslate"><span class="pre">Up</span></code>) 또는 하락(<code class="docutils literal notranslate"><span class="pre">Down</span></code>)했는지를 나타낸다. <code class="docutils literal notranslate"><span class="pre">Year</span></code>는 각 날짜가 속한 연도이다. 앞 장의 로지스틱 회귀에 의한 분류에서 이 데이터세트를 분석했기 때문에 아래 KNN 분류의 성과를 그것과 비교해보기 바란다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 

<span class="n">Smarket</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../Data/Smarket.csv&#39;</span><span class="p">)</span>
<span class="n">Smarket</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>Lag1</th>
      <th>Lag2</th>
      <th>Lag3</th>
      <th>Lag4</th>
      <th>Lag5</th>
      <th>Volume</th>
      <th>Today</th>
      <th>Direction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2001</td>
      <td>0.381</td>
      <td>-0.192</td>
      <td>-2.624</td>
      <td>-1.055</td>
      <td>5.010</td>
      <td>1.1913</td>
      <td>0.959</td>
      <td>Up</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2001</td>
      <td>0.959</td>
      <td>0.381</td>
      <td>-0.192</td>
      <td>-2.624</td>
      <td>-1.055</td>
      <td>1.2965</td>
      <td>1.032</td>
      <td>Up</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2001</td>
      <td>1.032</td>
      <td>0.959</td>
      <td>0.381</td>
      <td>-0.192</td>
      <td>-2.624</td>
      <td>1.4112</td>
      <td>-0.623</td>
      <td>Down</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2001</td>
      <td>-0.623</td>
      <td>1.032</td>
      <td>0.959</td>
      <td>0.381</td>
      <td>-0.192</td>
      <td>1.2760</td>
      <td>0.614</td>
      <td>Up</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2001</td>
      <td>0.614</td>
      <td>-0.623</td>
      <td>1.032</td>
      <td>0.959</td>
      <td>0.381</td>
      <td>1.2057</td>
      <td>0.213</td>
      <td>Up</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Smarket</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1250, 9)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h3>KNN 분류<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>KNN 접근의 예측 정확도를 제대로 평가하기 위해서는 데이터의 일부만을 사용하여 모델을 피팅한 다음, 훈련에 사용하지 않은 나머지 데이터에 대해 얼마나 잘 예측하는지를 조사해 봐야 한다. 즉 모델을 피팅하는 데 사용한 데이터가 아니라 시장의 움직임을 알 수 없는 미래의 날짜에 대해 모델의 성능을 평가해 볼 필요가 있다.</p>
<p>이를 위해 2001년부터 2004년까지의 관측을 훈련 세트로 하고, 2005년의 관측을 테스트 세트로 한다. 또한 예측변수로는 앞 장에서와 마찬가지로 <code class="docutils literal notranslate"><span class="pre">Lag1</span></code>, <code class="docutils literal notranslate"><span class="pre">Lag2</span></code> 변수만 사용해보자.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">Smarket</span><span class="p">[</span><span class="n">Smarket</span><span class="o">.</span><span class="n">Year</span> <span class="o">&lt;</span> <span class="mi">2005</span><span class="p">]</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">Smarket</span><span class="p">[</span><span class="n">Smarket</span><span class="o">.</span><span class="n">Year</span> <span class="o">==</span> <span class="mi">2005</span><span class="p">]</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[[</span><span class="s1">&#39;Lag1&#39;</span><span class="p">,</span><span class="s1">&#39;Lag2&#39;</span><span class="p">]]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Direction&#39;</span><span class="p">]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[[</span><span class="s1">&#39;Lag1&#39;</span><span class="p">,</span><span class="s1">&#39;Lag2&#39;</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;Direction&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code> 함수</strong></p>
<p>이제 <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> 모듈의 <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code> 함수를 사용하여 KNN을 수행해보자. 그런 다음, 테스트 세트의 관측 중 얼마만큼이 정확하게 분류되었고 얼마만큼이 잘못 분류되었는지를 혼동행렬(confusion matrix)로 파악한다.(혼동행렬에 대해서는 7장 부록 참조.)</p>
<p>우선 <span class="math notranslate nohighlight">\(K=1\)</span>을 수행한다. 모델을 피팅하려면 예측변수(<code class="docutils literal notranslate"><span class="pre">X_train</span></code>)와 출력변수(<code class="docutils literal notranslate"><span class="pre">y_train</span></code>)를 입력해야 한다. 그 피팅 결과를 바탕으로 테스트 세트 관측(<code class="docutils literal notranslate"><span class="pre">X_test</span></code>)에 대해 범주를 예측하여, 그것을 테스트 세트 실제 범주(<code class="docutils literal notranslate"><span class="pre">y_test</span></code>)와 비교하는 절차를 거치게 된다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">precision_score</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id8">
<h3>ChatGPT Q&amp;A<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<blockquote>
<div><p><strong>다음 코드를 설명해줘.</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>knn = KNeighborsClassifier(n_neighbors=1)  
pred = knn.fit(X_train, y_train).predict(X_test)
</pre></div>
</div>
</div></blockquote>
<hr class="docutils" />
<blockquote>
<div><p>이 코드는 K-최근접 이웃(K-Nearest Neighbors, KNN) 알고리즘을 사용하여 분류 문제를 해결하기 위한 파이썬 코드의 일부입니다. 코드는 <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> 라이브러리의 <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code> 클래스를 사용하고 있습니다. KNN은 지도 학습의 일종으로, 주어진 데이터 포인트가 주변의 가장 가까운 k개의 이웃 데이터 포인트의 레이블을 기반으로 분류되는 알고리즘입니다.</p>
<p>코드의 각 부분을 살펴보겠습니다:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">knn</span> <span class="pre">=</span> <span class="pre">KNeighborsClassifier(n_neighbors=1)</span></code>: <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code> 클래스의 인스턴스를 생성하고 있습니다. <code class="docutils literal notranslate"><span class="pre">n_neighbors=1</span></code> 매개변수는 가장 가까운 이웃 하나만을 사용하여 분류를 결정하겠다는 것을 의미합니다. 즉, 주어진 데이터 포인트에 가장 가까운 하나의 이웃을 찾고, 그 이웃의 레이블로 데이터 포인트를 분류합니다.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pred</span> <span class="pre">=</span> <span class="pre">knn.fit(X_train,</span> <span class="pre">y_train).predict(X_test)</span></code>: 이 코드 라인은 두 가지 작업을 수행합니다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">knn.fit(X_train,</span> <span class="pre">y_train)</span></code>: <code class="docutils literal notranslate"><span class="pre">fit</span></code> 메서드를 사용하여 모델을 학습 데이터 <code class="docutils literal notranslate"><span class="pre">X_train</span></code>과 해당 레이블 <code class="docutils literal notranslate"><span class="pre">y_train</span></code>에 맞춥니다. 이 과정에서 모델은 학습 데이터의 각 데이터 포인트와 그 레이블 간의 관계를 학습합니다.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.predict(X_test)</span></code>: 학습된 모델을 사용하여 테스트 데이터 <code class="docutils literal notranslate"><span class="pre">X_test</span></code>에 대한 예측을 수행합니다. 이 메서드는 <code class="docutils literal notranslate"><span class="pre">X_test</span></code>의 각 데이터 포인트에 대해 가장 가까운 이웃을 찾고, 그 이웃의 레이블을 기반으로 예측 레이블을 생성합니다.</p></li>
</ul>
</li>
</ol>
<p>결과적으로, 이 코드는 학습 데이터 세트를 사용하여 KNN 모델을 학습시키고, 학습된 모델을 테스트 데이터 세트에 적용하여 예측을 수행합니다. 여기서는 K=1, 즉 가장 가까운 하나의 이웃을 사용하여 예측을 결정합니다. <code class="docutils literal notranslate"><span class="pre">pred</span></code> 변수에는 <code class="docutils literal notranslate"><span class="pre">X_test</span></code> 데이터 포인트 각각에 대한 예측된 레이블이 저장됩니다.</p>
</div></blockquote>
</section>
<section id="id9">
<h3>혼동행렬<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>    <span class="c1"># 혼동행렬 작성</span>
<span class="n">cm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Down&#39;</span><span class="p">,</span><span class="s1">&#39;Up&#39;</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Down&#39;</span><span class="p">,</span><span class="s1">&#39;Up&#39;</span><span class="p">])</span>
<span class="n">cm_df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;True&#39;</span>
<span class="n">cm_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Predicted&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_df</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>    <span class="c1"># 정밀도 등</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted  Down  Up
True               
Down         43  68
Up           58  83

              precision    recall  f1-score   support

        Down      0.426     0.387     0.406       111
          Up      0.550     0.589     0.568       141

    accuracy                          0.500       252
   macro avg      0.488     0.488     0.487       252
weighted avg      0.495     0.500     0.497       252
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(K = 1\)</span>을 사용한 결과는 그다지 좋지 않다. 관측의 50.0%만 올바르게 예측되었기 때문이다. <span class="math notranslate nohighlight">\(K = 1\)</span>이 데이터에 지나치게 유연하게 피팅할 수 있기 때문에 이번에는 <span class="math notranslate nohighlight">\(K = 3\)</span>을 사용하여 분석해보자.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[48 63]
 [55 86]]
              precision    recall  f1-score   support

        Down      0.466     0.432     0.449       111
          Up      0.577     0.610     0.593       141

    accuracy                          0.532       252
   macro avg      0.522     0.521     0.521       252
weighted avg      0.528     0.532     0.529       252
</pre></div>
</div>
</div>
</div>
<p>정확도가 53.2%로 약간 개선되었다. 그러나 <span class="math notranslate nohighlight">\(K\)</span>를 더 늘려도 결과가 더 이상 개선되지 않는 것으로 나타났다.</p>
</section>
<section id="id10">
<h3>캐러밴 보험 데이터<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>ISLP에서 제공하는 Caravan 데이터세트는 캐러밴 보험(caravan insurance) 가입과 관련된 데이터이다. 조사대상은 총 5,822명이고, 이들에 대해 인구통계적(demographic) 특성과 관련된 85개의 예측변수가 들어있다. 반응변수는 <code class="docutils literal notranslate"><span class="pre">Purchase</span></code>로서 각 개인이 캐러밴 보험을 구매했는지 여부를 나타낸다.</p>
<p>앞 장의 로지스틱 회귀에 의한 분류에서 이 데이터세트를 분석했기 때문에 아래 KNN 분류의 성과를 그것과 비교해보기 바란다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Caravan</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../Data/Caravan.csv&#39;</span><span class="p">)</span>
<span class="n">Caravan</span><span class="o">.</span><span class="n">Purchase</span> <span class="o">=</span> <span class="n">Caravan</span><span class="o">.</span><span class="n">Purchase</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
<span class="n">Caravan</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MOSTYPE</th>
      <th>MAANTHUI</th>
      <th>MGEMOMV</th>
      <th>MGEMLEEF</th>
      <th>MOSHOOFD</th>
      <th>MGODRK</th>
      <th>MGODPR</th>
      <th>MGODOV</th>
      <th>MGODGE</th>
      <th>MRELGE</th>
      <th>...</th>
      <th>APERSONG</th>
      <th>AGEZONG</th>
      <th>AWAOREG</th>
      <th>ABRAND</th>
      <th>AZEILPL</th>
      <th>APLEZIER</th>
      <th>AFIETS</th>
      <th>AINBOED</th>
      <th>ABYSTAND</th>
      <th>Purchase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>33</td>
      <td>1</td>
      <td>3</td>
      <td>2</td>
      <td>8</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>3</td>
      <td>7</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1</th>
      <td>37</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>8</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>4</td>
      <td>6</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2</th>
      <td>37</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>8</td>
      <td>0</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>3</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9</td>
      <td>1</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
      <td>4</td>
      <td>5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>4</th>
      <td>40</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
      <td>10</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>4</td>
      <td>7</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 86 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Caravan</span><span class="o">.</span><span class="n">Purchase</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Purchase
No     5474
Yes     348
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
</section>
<section id="id11">
<h3>데이터 표준화<a class="headerlink" href="#id11" title="Link to this heading">#</a></h3>
<p>KNN 분류는 가장 가까운 관측을 식별하여 주어진 테스트 데이터의 범주를 예측하기 때문에 변수의 <strong>척도</strong>(scale)가 중요하다. 척도가 큰 변수는 척도가 작은 변수보다 관측 사이의 거리가 더 크기 때문에 KNN 분류에 더 큰 영향을 미친다.</p>
<p>예를 들어, 월급(달러로 측정)과 나이(연도로 측정)라는 두 가지 변수가 포함된 데이터세트를 생각해보자. 이 경우 어떤 두 사람간에 월급이 1,000달러 차이나는 것은 나이가 50살 차이나는 것에 비해 KNN 분류 작업에서 훨씬 크게 받아들여진다. 결과적으로 월급은 KNN 분류에 큰 영향을 미치는 반면, 나이는 거의 영향을 미치지 않게 된다. 이것은 50살의 나이 차이에 비해 월급 차이 1,000달러는 별로 크지 않다는 우리의 직관과는 상반된다.</p>
<p>KNN 분류에서 척도의 중요성은 또 다른 문제로 이어진다. 즉 월급을 일본 엔으로 측정하거나 나이를 분 단위로 측정하면 이 두 변수를 달러와 년으로 측정하여 얻은 것과는 상당히 다른 결과로 이어질 수 있다. 이 문제를 처리하는 좋은 방법은 모든 변수에 대해 평균이 0이고 표준편차가 1이 되도록 데이터를 <strong>표준화</strong>(standardization) 하는 것이다. 그러면 모든 변수가 비슷한 척도를 갖게 된다.</p>
<p>데이터세트에서 처음 85개 변수를 예측변수(<code class="docutils literal notranslate"><span class="pre">X</span></code>)로 하고, <code class="docutils literal notranslate"><span class="pre">Purchase</span></code> 변수를 반응변수(<code class="docutils literal notranslate"><span class="pre">y</span></code>)로 설정한다. 이와 함께, <code class="docutils literal notranslate"><span class="pre">X</span></code> 변수에 대해 <code class="docutils literal notranslate"><span class="pre">apply(zscore)</span></code>를 사용하여 데이터를 표준화시켰다. 이때 반응변수이자 정성적 변수인 <code class="docutils literal notranslate"><span class="pre">Purchase</span></code> 변수(86번째 열)는 표준화를 시키지 않았다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">Caravan</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">85</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">zscore</span><span class="p">)</span> <span class="c1"># standardize for KNN</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Caravan</span><span class="o">.</span><span class="n">Purchase</span>
</pre></div>
</div>
</div>
</div>
<p>처음 1,000개의 관측을 테스트 세트로 하고 나머지 관측을 훈련 세트로 분할한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># X와 y에서 처음 1,000개를 테스트 세트로 지정</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]</span>

<span class="c1"># X와 y에서 나머지를 훈련 세트로 지정</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<p>테스트 관측 1,000명 중 캐러밴 보험에 가입한 비율은 5.9%임을 확인할 수 있다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_test</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()[</span><span class="s1">&#39;Yes&#39;</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.059
</pre></div>
</div>
</div>
</div>
</section>
<section id="id12">
<h3>KNN 분류<a class="headerlink" href="#id12" title="Link to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(K = 1\)</span>을 사용하여 훈련 세트에 KNN 모델을 피팅하고 테스트 세트에 대해 추정 성과를 평가한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">knn_fit1</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">knn_fit1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="n">cm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;No&#39;</span><span class="p">,</span><span class="s1">&#39;Yes&#39;</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;No&#39;</span><span class="p">,</span><span class="s1">&#39;Yes&#39;</span><span class="p">])</span>
<span class="n">cm_df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;True&#39;</span>
<span class="n">cm_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Predicted&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_df</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">knn_fit1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">digits</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted   No  Yes
True               
No         873   68
Yes         50    9

              precision    recall  f1-score   support

          No      0.946     0.928     0.937       941
         Yes      0.117     0.153     0.132        59

    accuracy                          0.882      1000
   macro avg      0.531     0.540     0.535      1000
weighted avg      0.897     0.882     0.889      1000
</pre></div>
</div>
</div>
</div>
<p>1,000명의 테스트 관측에 대한 KNN 오류율은 11.8%이다. 괜찮은 성과로 보일 수 있지만 테스트 관측 고객의 5.9%만이 보험을 구매했기 때문에 예측변수의 값에 상관없이 항상 <code class="docutils literal notranslate"><span class="pre">No</span></code>로 예측하면 오류율을 5.9%까지 낮출 수 있어 이것은 좋은 성과라 할 수 없다.</p>
<p>그런데 보험을 판매하는 데 어느 정도 비용이 든다고 생각해보자. 예를 들어, 영업 사원이 각 잠재 고객을 방문하는 데는 비용이 든다. 회사가 무작위로 선택한 고객에게 보험을 판매하려고 하면 성공률은 5.9%에 불과하다. 관련 비용을 고려하면 이 정도의 성공률은 너무 낮은 편이다. 이러한 상황에서 보험을 구매할 가능성이 있는 고객에게만 보험을 판매하는 전략을 생각해보자. 이 경우 전체 오류율은 중요하지 않고, 보험을 구매할 것으로 예측된 사람들에 대한 오류율이 중요하다.</p>
<p>이렇게 생각한다면 <span class="math notranslate nohighlight">\(K=1\)</span>인 KNN은 보험을 구매할 것으로 예상되는 고객에 대해서는 무작위 추측(random guessing)보다는 결과가 훨씬 낫다. 위 결과를 보면, 77명의 보험가입 예상 고객 중 9명(11.7%)이 실제로 보험에 가입했기 때문이다. 이것은 무작위 추측으로 얻을 수 있는 성과(즉 5.9%)의 약 두 배에 달한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;K=1일 때, </span><span class="se">\&#39;</span><span class="s1">Yes</span><span class="se">\&#39;</span><span class="s1">에 대한 정밀도는 </span><span class="si">%0.1f%%</span><span class="s1">이다.&#39;</span> 
      <span class="o">%</span> <span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">knn_fit1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">pos_label</span><span class="o">=</span><span class="s1">&#39;Yes&#39;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>K=1일 때, &#39;Yes&#39;에 대한 정밀도는 11.7%이다.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">knn_fit3</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;K=3일 때, </span><span class="se">\&#39;</span><span class="s1">Yes</span><span class="se">\&#39;</span><span class="s1">에 대한 정밀도는 </span><span class="si">%0.1f%%</span><span class="s1">이다.&#39;</span> 
      <span class="o">%</span> <span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">knn_fit3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">pos_label</span><span class="o">=</span><span class="s1">&#39;Yes&#39;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>K=3일 때, &#39;Yes&#39;에 대한 정밀도는 20.0%이다.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">knn_fit5</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;K=5일 때, </span><span class="se">\&#39;</span><span class="s1">Yes</span><span class="se">\&#39;</span><span class="s1">에 대한 정밀도는 </span><span class="si">%0.1f%%</span><span class="s1">이다.&#39;</span> 
      <span class="o">%</span> <span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">knn_fit5</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">pos_label</span><span class="o">=</span><span class="s1">&#39;Yes&#39;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>K=5일 때, &#39;Yes&#39;에 대한 정밀도는 28.6%이다.
</pre></div>
</div>
</div>
</div>
<p>위 결과에서 보듯이 <span class="math notranslate nohighlight">\(K = 3\)</span>을 사용하면, 보험가입 예상 고객 중 실제로 보험에 가입한 비율, 즉 <code class="docutils literal notranslate"><span class="pre">Yes</span></code>에 대한 정밀도(precision)가 20.0%로 증가하고, <span class="math notranslate nohighlight">\(K = 5\)</span>이면 28.6%가 된다. 이것은 무작위 추측 결과의 5배 가까이 되는 수준이다.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="07_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EB%B6%84%EB%A5%98.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">7장 로지스틱 회귀를 이용한 분류</p>
      </div>
    </a>
    <a class="right-next"
       href="09_%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">9장 나이브 베이즈 분류</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">8.1 개요</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">베이즈 분류기</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k">K-최근접이웃</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">KNN 그림 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">KNN 기법 숫자 예시</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-q-a">ChatGPT Q&amp;A</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">8.2 데이터 분석 예제</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">주식시장 데이터</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">KNN 분류</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">ChatGPT Q&amp;A</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">혼동행렬</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">캐러밴 보험 데이터</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">데이터 표준화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">KNN 분류</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 최필선 민인식
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>