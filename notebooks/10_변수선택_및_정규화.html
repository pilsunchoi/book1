
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>10장 변수선택 및 정규화 &#8212; 데이터과학의 첫걸음</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/10_변수선택_및_정규화';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="11장 추천 시스템" href="11_%EC%B6%94%EC%B2%9C_%EC%8B%9C%EC%8A%A4%ED%85%9C.html" />
    <link rel="prev" title="9장 나이브 베이즈 분류" href="09_%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="00_%EC%84%9C%EB%AC%B8.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="데이터과학의 첫걸음 - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="데이터과학의 첫걸음 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00_%EC%84%9C%EB%AC%B8.html">
                    데이터과학의 첫걸음: 시작하며
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0.html">1장 파이썬 시작하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EC%BD%94%EB%94%A9_%EA%B8%B0%EC%B4%88.html">2장 파이썬 코딩 기초</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_%EC%9D%80%ED%96%89_%ED%85%94%EB%A0%88%EB%A7%88%EC%BC%80%ED%8C%85_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html">3장 은행 텔레마케팅 데이터 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_%EC%A0%84%EC%9E%90%EC%83%81%EA%B1%B0%EB%9E%98_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html">4장 전자상거래 데이터 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_%ED%86%B5%EA%B3%84%EC%A0%81_%ED%95%99%EC%8A%B5.html">5장 통계적 학습</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80.html">6장 선형 회귀</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EB%B6%84%EB%A5%98.html">7장 로지스틱 회귀를 이용한 분류</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_KNN%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EB%B6%84%EB%A5%98.html">8장 KNN 분류</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98.html">9장 나이브 베이즈 분류</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">10장 변수선택 및 정규화</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_%EC%B6%94%EC%B2%9C_%EC%8B%9C%EC%8A%A4%ED%85%9C.html">11장 추천 시스템</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%EB%A7%8C%EB%93%A4%EA%B8%B0.html">12장 결정 트리 만들기</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_%ED%8A%B8%EB%A6%AC_%EA%B8%B0%EB%B0%98_%EB%AA%A8%ED%98%95.html">13장 트리 기반 모형</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_%EC%84%9C%ED%8F%AC%ED%8A%B8_%EB%B2%A1%ED%84%B0_%EB%A8%B8%EC%8B%A0.html">14장 서포트 벡터 머신</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%9E%85%EB%AC%B8.html">15장 딥러닝 입문</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5%EA%B3%BC_%EC%A3%BC%EC%84%B1%EB%B6%84_%EB%B6%84%EC%84%9D.html">16장 비지도학습과 주성분 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="17_%EC%83%9D%EC%A1%B4%EB%B6%84%EC%84%9D.html">17장 생존분석</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pilsunchoi/book1" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pilsunchoi/book1/issues/new?title=Issue%20on%20page%20%2Fnotebooks/10_변수선택_및_정규화.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/10_변수선택_및_정규화.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>10장 변수선택 및 정규화</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">10.1 개요</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">10.2 최량 부분집합 선택</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#credit">Credit 데이터세트 적용 예</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#best-subset-selection">Best subset selection 함수 만들기</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Credit 데이터세트 적용</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">최적 모델 선택</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">10.3 단계적 선택</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">전진 단계적 선택</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">후진 단계적 선택</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">10.4 최적 모델 선택</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">정보기준</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-q-a">ChatGPT Q&amp;A</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">검증</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-lasso">10.5 Ridge 및 Lasso</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge">Ridge 회귀</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">Credit 데이터세트 릿지 회귀 실행</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">Lasso</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">부록: 교차검증(Cross-Validation)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">검증 세트 접근방식</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">단일제외 교차검증 접근방식</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">5중 교차검증 접근방식</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>10장 변수선택 및 정규화<a class="headerlink" href="#id1" title="Link to this heading">#</a></h1>
<p>자료 출처: <a class="reference external" href="https://www.statlearning.com/">ISLP (An Introduction to Statistical Learning with Applications in Python)</a> 및 <a class="github reference external" href="https://github.com/gperaza/ISLR-Python-Labs">gperaza/ISLR-Python-Labs</a></p>
<section id="id2">
<h2>10.1 개요<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>선형 모델을 좀 더 복잡한 비선형(non-linear) 모델로 확장시킴으로써 피팅 성과를 높일 수 있다. 그러나 선형 모델은 추론 측면에서 뚜렷한 이점이 있으며, 실제 문제에서 비선형 방법과 비교하여 놀랍도록 경쟁적인 경우가 많다. 따라서 비선형의 세계로 가기 전에 <strong>변수선택이나 정규화를 통해 선형 모델의 추정 성과를 개선</strong>할 수 있는 몇 가지 방법에 대해 살펴보자. 추정 성과를 개선한다는 것은 예측의 정확도와 모델의 해석력(model interpretability)을 높인다는 것이다.</p>
<ul class="simple">
<li><p><strong>예측 정확도</strong>: 추정 계수를 제한하거나 축소함으로써 편향을 일부 희생해서라도 분산을 줄일 필요가 있다. 이를 통해 테스트 세트에 대한 모델의 정확도를 크게 향상시킬 수 있다.</p></li>
<li><p><strong>모델 해석력</strong>: 관련 없는 변수를 모델에 포함시키면 모델이 불필요하게 복잡해진다. 이러한 변수를 제거하면, 즉 해당 계수 추정치를 0으로 설정하게 되면 해석이 보다 쉬운 모델을 얻을 수 있다.</p></li>
</ul>
<p>이 장에서는 선형 모델의 추정 성과를 개선하는 두  가지 방법에 대해 살펴본다.</p>
<p>첫 번째 방법은 예측변수(독립변수)의 <strong>부분집합 선택</strong>(Subset Selection)이다. 이것은 주어진 <span class="math notranslate nohighlight">\(p\)</span>개의 예측변수를 모두 다 사용하는 것이 아니라 그중 반응변수와 가장 밀접한 관련이 있다고 생각되는 변수들을 식별해낸 다음, 그것으로 모델을 피팅하는 방법이다. 부분집합 선택 방법 중 여기에서는 <strong>최량 부분집합 선택</strong>(best subset selection)과 <strong>단계적 모델 선택</strong>(stepwise model selection)에 대해 살펴본다.</p>
<p>두 번째 방법은 <strong>축소</strong>(shrinkage)이다. 이 접근 방식은 일단 <span class="math notranslate nohighlight">\(p\)</span>개 예측변수를 모두 포함하는 모델을 피팅한다. 그러나 추정된 계수는 최소제곱 추정치에 비해 0을 향해 축소된다. 이 축소를 <strong>정규화</strong>(regularization)라고도 하는데, 이렇게 함으로써 추정 계수의 분산을 줄이는 효과가 있다. 수행되는 축소 방식에 따라 일부 계수는 정확히 0으로 추정될 수 있기 때문에 축소를 통해 변수선택을 수행할 수도 있다. 축소 접근법 중 여기에서는 <strong>Ridge 회귀</strong>와 <strong>Lasso</strong> 기법에 대해 소개한다.</p>
</section>
<section id="id3">
<h2>10.2 최량 부분집합 선택<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>최량 부분집합 선택은 다음과 같이 진행된다. 우선 주어진 <span class="math notranslate nohighlight">\(p\)</span>개 예측변수의 모든 가능한 조합에 대해 각각 OLS 피팅을 수행한다. 즉, 예측변수가 하나만 있는 모든 <span class="math notranslate nohighlight">\(p\)</span>개 모델, 두 개의 예측변수만을 포함하는 <span class="math notranslate nohighlight">\({p \choose 2}= p (p-1) / 2\)</span>개의 모델 등, 이런 식으로 예측변수의 개수를 하나씩 늘려가면서 모든 조합에 대해 피팅을 수행한다.</p>
<p>그런 다음, 동일한 수의 예측변수를 가진 모델들(예측변수의 모든 조합)에 대해 RSS 또는 <span class="math notranslate nohighlight">\(R^2\)</span>를 사용하여 서로 비교한다. 그런 식으로 각 개수의 예측변수에 대해 최량의 모델을 선택한 다음, 그것들끼리 다시 비교하여 최상의 모델을 찾는다. 예측변수 개수가 다른 모델을 비교함에 있어서는 AIC, BIC, Adj <span class="math notranslate nohighlight">\(R^2\)</span> 등의 정보기준(information criteria)(아래 <a class="reference internal" href="#10.4.1-%EC%A0%95%EB%B3%B4-%EA%B8%B0%EC%A4%80"><span class="xref myst">10.4.1절</span></a> 참조)을 사용하거나 아니면 훈련 세트 일부를 테스트 세트로 사용하여 모델을 비교하는 소위 교차검증(cross-validation)(<a class="reference internal" href="#%EB%B6%80%EB%A1%9D:-%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Cross-Validation)"><span class="xref myst">부록</span></a> 참조)을 통해 최상의 모델을 선택한다.</p>
<p>예측변수가 <span class="math notranslate nohighlight">\(p\)</span>개일 때, <strong>최량 부분집합 선택은 <span class="math notranslate nohighlight">\(2^p\)</span>개의 모든 가능한 모델 중에서 최상의 모델을 선택</strong>하는 방식이다. 한 가지 문제는 <span class="math notranslate nohighlight">\(p\)</span>가 커짐에 따라 실행에 상당한 시간이 소요된다는 점이다. 예측변수가 20개만 되더라도 모든 가능한 모델의 개수는 <span class="math notranslate nohighlight">\(2^{20}\)</span>, 즉 1,048,576개에 이른다.</p>
<p>우선 이해를 돕기 위해 예측변수가 3개인 경우 최량 부분집합 선택 알고리즘을 생각해보자.</p>
<blockquote>
<div><p><strong>Best subset selection 알고리즘 (<span class="math notranslate nohighlight">\(p=3\)</span>)</strong></p>
<hr class="docutils" />
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal M_0\)</span>는 예측변수를 하나도 포함하지 않는 영(null) 모델로서 관측값의 표본평균을 나타낸다.</p></li>
<li><p>(1) 세 개의 예측변수 각각에 대해 각각 단순 선형 회귀(즉 예측변수 1개) 모델을 피팅한다. 이 세 개의 모델 중에서 최상의 것을 선택하고, 이를 <span class="math notranslate nohighlight">\(\mathcal M_1\)</span>이라고 부른다. 여기서 최상의 모델은 RSS가 가장 작은(또는 이와 동등하게 <span class="math notranslate nohighlight">\(R^2\)</span>가 가장 큰) 것으로 정의된다.<br />
(2) 이번에는 예측변수 2개를 사용한 다중 선형 회귀 모델을 피팅한다. 예측변수가 2개인 모델은 세 가지가 있으며, 이 중 최상의 것을 <span class="math notranslate nohighlight">\(\mathcal M_2\)</span>라고 부른다.<br />
(3) 이번에는 예측변수 3개를 모두 사용한 모델을 피팅한다. 예측변수가 3개인 경우는 하나밖에 없기 때문에 자신이 최상의 것이 되고,이를 <span class="math notranslate nohighlight">\(\mathcal M_3\)</span>라고 부른다.</p></li>
<li><p>정보기준 <span class="math notranslate nohighlight">\(C_p\)</span>(AIC), BIC, adjusted <span class="math notranslate nohighlight">\(R^2\)</span>를 사용하여 <span class="math notranslate nohighlight">\(\mathcal M_0,\mathcal M_1,\mathcal M_2,\mathcal M_3\)</span> 중에서 최적의 모델을 선택한다.(결국 총 <span class="math notranslate nohighlight">\(2^3=8\)</span>개 모델 중에서 가장 우수한 것을 선택하는 것임.)</p></li>
</ol>
</div></blockquote>
<p><img alt="Best subset selection (p=3)" src="https://raw.githubusercontent.com/pilsunchoi/images/main/10-1.png" /></p>
<p>다음은 예측변수가 <span class="math notranslate nohighlight">\(p\)</span>개일 때, 최량 부분집합 선택 알고리즘을 정리한 것이다.</p>
<blockquote>
<div><p><strong>Best subset selection 알고리즘</strong></p>
<hr class="docutils" />
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal M_0\)</span>는 예측변수를 하나도 포함하지 않는 영(null) 모델로서 관측값의 표본평균을 나타낸다.
</br></p></li>
<li><p><span class="math notranslate nohighlight">\(k = 1, 2,. . ., p:\)</span><br />
(1) 정확히 <span class="math notranslate nohighlight">\(k\)</span>개의 예측변수를 포함하는 모든 <span class="math notranslate nohighlight">\(\binom{p}{k}\)</span>개의 모델을 피팅한다.<br />
(2) 이 <span class="math notranslate nohighlight">\(\binom{p}{k}\)</span>개의 모델 중에서 최상의 것을 선택하고, 이를 <span class="math notranslate nohighlight">\(\mathcal M_k\)</span>라고 부른다. 여기서 최상의 모델은 RSS가 가장 작은(또는 이와 동등하게 <span class="math notranslate nohighlight">\(R^2\)</span>가 가장 큰) 것으로 정의된다.
</br></p></li>
<li><p>정보기준 <span class="math notranslate nohighlight">\(C_p\)</span>(AIC), BIC, adjusted <span class="math notranslate nohighlight">\(R^2\)</span>를 사용하여 <span class="math notranslate nohighlight">\(\mathcal M_0,...,\mathcal M_p\)</span> 중에서 단일의 최적 모델을 선택한다.</p></li>
</ol>
</div></blockquote>
<section id="credit">
<h3>Credit 데이터세트 적용 예<a class="headerlink" href="#credit" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Credit</span></code> 데이터세트는 개인들의 신용카드 사용액과 관련된 데이터이다.(여기에서는 인터넷에서 데이터 파일을 불러들이는데 이것은 ISLP에서 제공하는 Credit.csv 파일과 변수 구성이 약간 다르다.)</p>
<p><code class="docutils literal notranslate"><span class="pre">Credit</span></code> 데이터세트에는 <code class="docutils literal notranslate"><span class="pre">Balance</span></code>(각 개인의 월평균 신용카드 사용액)를 비롯해 <code class="docutils literal notranslate"><span class="pre">Income</span></code>(소득, 단위: 천달러), <code class="docutils literal notranslate"><span class="pre">Limit</span></code>(신용 한도), <code class="docutils literal notranslate"><span class="pre">Rating</span></code>(신용 등급), <code class="docutils literal notranslate"><span class="pre">Cards</span></code>(신용카드 개수), <code class="docutils literal notranslate"><span class="pre">Age</span></code>(나이), <code class="docutils literal notranslate"><span class="pre">Education</span></code>(교육 년수), <code class="docutils literal notranslate"><span class="pre">Gender</span></code>(성별), <code class="docutils literal notranslate"><span class="pre">Student</span></code>(학생 여부), <code class="docutils literal notranslate"><span class="pre">Married</span></code>(결혼 여부), <code class="docutils literal notranslate"><span class="pre">Ethnicity</span></code>(백인, 아프리카계 미국인, 아시아인) 등의 변수가 있다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/</span><span class="se">\</span>
<span class="s1">Data/Credit.csv&#39;</span>
<span class="n">Credit</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">12</span><span class="p">)))</span>
<span class="n">Credit</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Income</th>
      <th>Limit</th>
      <th>Rating</th>
      <th>Cards</th>
      <th>Age</th>
      <th>Education</th>
      <th>Gender</th>
      <th>Student</th>
      <th>Married</th>
      <th>Ethnicity</th>
      <th>Balance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>14.891</td>
      <td>3606</td>
      <td>283</td>
      <td>2</td>
      <td>34</td>
      <td>11</td>
      <td>Male</td>
      <td>No</td>
      <td>Yes</td>
      <td>Caucasian</td>
      <td>333</td>
    </tr>
    <tr>
      <th>1</th>
      <td>106.025</td>
      <td>6645</td>
      <td>483</td>
      <td>3</td>
      <td>82</td>
      <td>15</td>
      <td>Female</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>Asian</td>
      <td>903</td>
    </tr>
    <tr>
      <th>2</th>
      <td>104.593</td>
      <td>7075</td>
      <td>514</td>
      <td>4</td>
      <td>71</td>
      <td>11</td>
      <td>Male</td>
      <td>No</td>
      <td>No</td>
      <td>Asian</td>
      <td>580</td>
    </tr>
    <tr>
      <th>3</th>
      <td>148.924</td>
      <td>9504</td>
      <td>681</td>
      <td>3</td>
      <td>36</td>
      <td>11</td>
      <td>Female</td>
      <td>No</td>
      <td>No</td>
      <td>Asian</td>
      <td>964</td>
    </tr>
    <tr>
      <th>4</th>
      <td>55.882</td>
      <td>4897</td>
      <td>357</td>
      <td>2</td>
      <td>68</td>
      <td>16</td>
      <td>Male</td>
      <td>No</td>
      <td>Yes</td>
      <td>Caucasian</td>
      <td>331</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>395</th>
      <td>12.096</td>
      <td>4100</td>
      <td>307</td>
      <td>3</td>
      <td>32</td>
      <td>13</td>
      <td>Male</td>
      <td>No</td>
      <td>Yes</td>
      <td>Caucasian</td>
      <td>560</td>
    </tr>
    <tr>
      <th>396</th>
      <td>13.364</td>
      <td>3838</td>
      <td>296</td>
      <td>5</td>
      <td>65</td>
      <td>17</td>
      <td>Male</td>
      <td>No</td>
      <td>No</td>
      <td>African American</td>
      <td>480</td>
    </tr>
    <tr>
      <th>397</th>
      <td>57.872</td>
      <td>4171</td>
      <td>321</td>
      <td>5</td>
      <td>67</td>
      <td>12</td>
      <td>Female</td>
      <td>No</td>
      <td>Yes</td>
      <td>Caucasian</td>
      <td>138</td>
    </tr>
    <tr>
      <th>398</th>
      <td>37.728</td>
      <td>2525</td>
      <td>192</td>
      <td>1</td>
      <td>44</td>
      <td>13</td>
      <td>Male</td>
      <td>No</td>
      <td>Yes</td>
      <td>Caucasian</td>
      <td>0</td>
    </tr>
    <tr>
      <th>399</th>
      <td>18.701</td>
      <td>5524</td>
      <td>415</td>
      <td>5</td>
      <td>64</td>
      <td>7</td>
      <td>Female</td>
      <td>No</td>
      <td>No</td>
      <td>Asian</td>
      <td>966</td>
    </tr>
  </tbody>
</table>
<p>400 rows × 11 columns</p>
</div></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Gender</span></code>, <code class="docutils literal notranslate"><span class="pre">Student</span></code>, <code class="docutils literal notranslate"><span class="pre">Married</span></code>, <code class="docutils literal notranslate"><span class="pre">Ethnicity</span></code> 등 4개의 범주형 변수에 대해 <code class="docutils literal notranslate"><span class="pre">pd.get_dummies()</span></code> 함수를 이용해 더미변수를 만든다. 그런 다음, 기존의 범주형 변수를 없애고 새로 만든 더미변수를 넣어 <code class="docutils literal notranslate"><span class="pre">df</span></code>라는 새로운 데이터프레임을 만든다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">Credit</span><span class="p">[[</span><span class="s1">&#39;Gender&#39;</span><span class="p">,</span> <span class="s1">&#39;Student&#39;</span><span class="p">,</span> <span class="s1">&#39;Married&#39;</span><span class="p">,</span> <span class="s1">&#39;Ethnicity&#39;</span><span class="p">]])</span>
<span class="n">dummies</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender_ Male</th>
      <th>Gender_Female</th>
      <th>Student_No</th>
      <th>Student_Yes</th>
      <th>Married_No</th>
      <th>Married_Yes</th>
      <th>Ethnicity_African American</th>
      <th>Ethnicity_Asian</th>
      <th>Ethnicity_Caucasian</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">Credit</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Gender&#39;</span><span class="p">,</span> <span class="s1">&#39;Student&#39;</span><span class="p">,</span> <span class="s1">&#39;Married&#39;</span><span class="p">,</span> <span class="s1">&#39;Ethnicity&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">dummies</span><span class="p">[[</span><span class="s1">&#39;Gender_Female&#39;</span><span class="p">,</span> <span class="s1">&#39;Student_Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;Married_Yes&#39;</span><span class="p">,</span> 
                             <span class="s1">&#39;Ethnicity_Asian&#39;</span><span class="p">,</span> <span class="s1">&#39;Ethnicity_Caucasian&#39;</span><span class="p">]]],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Income</th>
      <th>Limit</th>
      <th>Rating</th>
      <th>Cards</th>
      <th>Age</th>
      <th>Education</th>
      <th>Balance</th>
      <th>Gender_Female</th>
      <th>Student_Yes</th>
      <th>Married_Yes</th>
      <th>Ethnicity_Asian</th>
      <th>Ethnicity_Caucasian</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>14.891</td>
      <td>3606</td>
      <td>283</td>
      <td>2</td>
      <td>34</td>
      <td>11</td>
      <td>333</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>106.025</td>
      <td>6645</td>
      <td>483</td>
      <td>3</td>
      <td>82</td>
      <td>15</td>
      <td>903</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>104.593</td>
      <td>7075</td>
      <td>514</td>
      <td>4</td>
      <td>71</td>
      <td>11</td>
      <td>580</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>148.924</td>
      <td>9504</td>
      <td>681</td>
      <td>3</td>
      <td>36</td>
      <td>11</td>
      <td>964</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>55.882</td>
      <td>4897</td>
      <td>357</td>
      <td>2</td>
      <td>68</td>
      <td>16</td>
      <td>331</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>앞에서도 언급했듯이 최량 부분집합 선택 기법은 계산 비용이 크기 때문에 잘 사용되지 않는다.(예측변수가 <span class="math notranslate nohighlight">\(p\)</span>개인 경우 <span class="math notranslate nohighlight">\(2^p\)</span>개의 모델을 비교해야 함.) 그래서 이를 수행하기 위한 내장(built-in) <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> 모듈이 없다. 여기에서는 파이썬으로 함수를 만들어보는 학습 차원에서 직접 함수를 만들어 최량 부분집합 선택을 수행해보자.</p>
</section>
<section id="best-subset-selection">
<h3>Best subset selection 함수 만들기<a class="headerlink" href="#best-subset-selection" title="Link to this heading">#</a></h3>
<p>아래 <code class="docutils literal notranslate"><span class="pre">best_subsets()</span></code> 함수는 각 선형 회귀 모델 크기별로 RSS가 가장 낮은 모델을 찾는 함수를 만든 것이다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">best_subsets</span><span class="p">(</span><span class="n">dataframe</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">max_features</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    주어진 데이터프레임에서 반응변수를 예측변수의 부분집합에 회귀시킨다. </span>
<span class="sd">    예측변수 개수가 동일한 모델끼리 비교하여 RSS가 가장 낮은 모델을 </span>
<span class="sd">    해당 예측변수 개수에 대한 &#39;최량&#39; 모델로 선택한다.</span>
<span class="sd">    </span>
<span class="sd">    PARAMETERS</span>
<span class="sd">    ----------</span>
<span class="sd">    dataframe : 반응 및 예측변수가 들어있는 pandas 데이터프레임</span>
<span class="sd">    predictors : 예측변수로 사용되는 데이터프레임의 열 이름 리스트</span>
<span class="sd">    response : target으로 사용되는 데이터프레임의 열 이름 리스트</span>
<span class="sd">    </span>
<span class="sd">    RETURNS</span>
<span class="sd">    -------</span>
<span class="sd">    최량 모델 리스트(예측변수 개수별로 하나씩)</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">process_linear_model</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        선형 회귀 모델을 구축</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">dataframe</span><span class="p">[</span><span class="n">features</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))</span>  <span class="c1"># bool → float 변환</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">response</span><span class="p">]</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">RSS</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">ssr</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">RSS</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_best_kth_model</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        k-예측변수가 있는 모든 모델에서 RSS가 가장 낮은 모델을 반환</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">combo</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">process_linear_model</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">combo</span><span class="p">)))</span>
        <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">models</span> <span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">max_features</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">get_best_kth_model</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">models</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h3>Credit 데이터세트 적용<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>위에서 만든 <code class="docutils literal notranslate"><span class="pre">best_subsets()</span></code> 함수를 Credit 데이터에 대해 실행한다. 반응변수(종속변수)는 <code class="docutils literal notranslate"><span class="pre">Balance</span></code>이다. 우리의 목표는 <code class="docutils literal notranslate"><span class="pre">Balance</span></code>를 결정하는 최적의 변수들을 찾는 것이다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">predictors</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;Balance&#39;</span><span class="p">)</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">best_subsets</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Balance&#39;</span><span class="p">],</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>각 모델 크기별로 최량의 변수 세트를 출력시킨다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">model_i</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model_i</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">exog_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;const&#39;, &#39;Rating&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Rating&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Rating&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Cards&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Student_Yes&#39;, &#39;Ethnicity_Asian&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Student_Yes&#39;, &#39;Married_Yes&#39;, &#39;Ethnicity_Asian&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Student_Yes&#39;, &#39;Married_Yes&#39;, &#39;Ethnicity_Asian&#39;, &#39;Ethnicity_Caucasian&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Education&#39;, &#39;Gender_Female&#39;, &#39;Student_Yes&#39;, &#39;Married_Yes&#39;, &#39;Ethnicity_Asian&#39;, &#39;Ethnicity_Caucasian&#39;]
</pre></div>
</div>
</div>
</div>
<p>각 모델 크기별로 최량 모델의 <span class="math notranslate nohighlight">\(R^2\)</span> 값도 볼 수 있다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">model_i</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model_i</span><span class="o">.</span><span class="n">rsquared</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7458484180585037
0.8751179476994355
0.94987877963262
0.9535800027954133
0.9541605970612348
0.9546878863974592
0.9548166616899534
0.9548879566476849
0.9549635868719017
0.9550468424377629
0.9551015633651758
</pre></div>
</div>
</div>
</div>
<p>위 결과를 보면, 모델에 하나의 예측변수만 있는 경우가 <span class="math notranslate nohighlight">\(R^2=0.745\)</span>로 가장 낮고, 모든 변수가 포함된 경우에는 <span class="math notranslate nohighlight">\(R^2\)</span>가 0.955로 높아진다. 예측변수 개수가 늘어남에 따라 <span class="math notranslate nohighlight">\(R^2\)</span>가 단조(monotonic) 증가하는 것을 알 수 있다. 이것을 그림으로 그린 것이 아래 그림 10.1에 나와 있다. 이는 결국 <span class="math notranslate nohighlight">\(R^2\)</span> 또는 RSS로는 최적의 모델(즉, 최적의 예측변수 조합)을 찾는 것이 불가능하다는 것을 의미한다. 그래서 <span class="math notranslate nohighlight">\(R^2\)</span>나 RSS 대신 앞에서 언급한 대로 정보기준이나 교차검증을 사용하는 것이다.(아래 <a class="reference internal" href="#10.4-%EC%B5%9C%EC%A0%81-%EB%AA%A8%EB%8D%B8-%EC%84%A0%ED%83%9D"><span class="xref myst">10.4 최적 모델 선택</span></a> 설명 참조)</p>
<p><strong>그림 10.1.</strong> <code class="docutils literal notranslate"><span class="pre">Credit</span></code> 데이터세트의 10개 예측변수의 각 가능한 부분집합 모델에 대해 RSS 및 <span class="math notranslate nohighlight">\(R^2\)</span>가 표시돼 있다. 빨간색 점으로 연결된 선은 각 예측변수 개수별로 최량의 모델을 표시한 것이다. 데이터세트의 예측변수는 10개이지만 범주형 변수 중 하나인 <code class="docutils literal notranslate"><span class="pre">Ethnicity</span></code>(백인, 아프리카계 미국인, 아시아인)가 3개의 범주를 갖고 있어 두 개의 더미변수가 생성되기 때문에 가로축의 범위가 1에서 11까지(즉 11개 변수)로 돼있다.</p>
<p><img alt="Credit 데이터 최량모델" src="https://raw.githubusercontent.com/pilsunchoi/images/main/10-2.png" /></p>
<ul class="simple">
<li><p>그림 출처: ISLP, FIGURE 6.1</p></li>
</ul>
</section>
<section id="id5">
<h3>최적 모델 선택<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p>예측변수 개수별로 구한 가장 우수한 모델 중에서 최고의 모델을 찾는 작업이 남아 있다. 정보기준 접근에 입각하여 adjusted <span class="math notranslate nohighlight">\(R^2\)</span>, AIC(이것은 <span class="math notranslate nohighlight">\(C_p\)</span>와 서로 비례함), BIC를 그림으로 그려 보자. adjusted <span class="math notranslate nohighlight">\(R^2\)</span>의 경우에는 값이 가장 높은 모델이 가장 우수한 반면, AIC 및 BIC의 경우에는 값이 가장 낮은 모델이 가장 우수하다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">aics</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">aic</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
<span class="n">bics</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">bic</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
<span class="n">r_adj</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">rsquared_adj</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">13</span><span class="p">})</span>

<span class="c1"># 최적 모델 선택</span>
<span class="n">min_aic_index</span><span class="p">,</span> <span class="n">min_aic</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">aics</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">min_bic_index</span><span class="p">,</span> <span class="n">min_bic</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">bics</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">max_radj_index</span><span class="p">,</span> <span class="n">max_radj</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">r_adj</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="n">num_predictors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">))</span>

<span class="c1"># 그림 그리기</span>
<span class="n">fig</span><span class="p">,(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">num_predictors</span><span class="p">,</span> <span class="n">aics</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;AIC&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">num_predictors</span><span class="p">,</span> <span class="n">bics</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;BIC&#39;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">min_aic_index</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_aic</span><span class="p">,</span> <span class="s1">&#39;gx&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">markeredgewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">min_bic_index</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_bic</span><span class="p">,</span> <span class="s1">&#39;gx&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">markeredgewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Predictors&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">num_predictors</span><span class="p">,</span> <span class="n">r_adj</span><span class="p">,</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">max_radj_index</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_radj</span><span class="p">,</span> <span class="s1">&#39;gx&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">markeredgewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Predictors&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Adjusted $R^2$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/beeacac39fb28e3e41033e6e0f84e1928a8bb1c6f8d8a2905b85eb7cd538f8ed.png" src="../_images/beeacac39fb28e3e41033e6e0f84e1928a8bb1c6f8d8a2905b85eb7cd538f8ed.png" />
</div>
</div>
<p>위 결과를 보면, 무엇을 기준으로 하든 예측변수가 4개 이상은 필요하다는 것을 알 수 있다. 가령 BIC를 기준으로 할 경우, 예측변수가 4개인 경우가 가장 좋은 모델이다. 이 모델의 추정 계수는 다음과 같다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">models</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>const         -499.727212
Income          -7.839229
Limit            0.266644
Cards           23.175379
Student_Yes    429.606420
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id6">
<h2>10.3 단계적 선택<a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<p>최량 부분집합 선택은 <span class="math notranslate nohighlight">\(p\)</span>가 크면 계산 비용이 너무 커서 적용하기 곤란하다. 또한 최량 부분집합 선택은 <span class="math notranslate nohighlight">\(p\)</span>가 클 때 계수 추정치의 높은 분산 및 과적합 문제로 이어질 수 있다.</p>
<p>이 때문에 훨씬 더 제한된 모델 세트를 탐색하는 <strong>단계적 선택</strong>(stepwise selection) 방법이 최량 부분집합 선택에 대한 매력적인 대안이다. 최량 부분집합은 <span class="math notranslate nohighlight">\(p\)</span>개 예측변수의 <strong>모든</strong> 부분집합에 대해 총 <span class="math notranslate nohighlight">\(2^p\)</span>개의 모델을 고려하는 반면, 단계적 선택은 훨씬 더 작은 모델 집합을 고려한다. 단계적 선택에는 전진(forward) 방식과 후진(backward) 방식이 있다.</p>
<section id="id7">
<h3>전진 단계적 선택<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>전진 단계적 선택은 예측변수가 없는 영(null) 모델에서 시작하여 모든 예측변수가 들어있는 모델에 이를 때까지 <strong>한 번에 하나씩</strong> 예측변수를 모델에 <strong>추가</strong>시킨다. 각 단계에서 피팅을 가장 크게 개선시키는 변수를 모델에 추가시키는 방식이다. 그런 다음, 정보기준 또는 교차검증을 사용하여 서로 다른 개수의 예측변수를 가진 모델들을 비교하여 최적의 모델을 선택한다.</p>
<p>우선 이해를 돕기 위해 예측변수가 3개인 경우에 대해 전진 단계적 선택 알고리즘을 생각해보자.</p>
<blockquote>
<div><p><strong>Forward stepwise selection 알고리즘 (<span class="math notranslate nohighlight">\(p=3\)</span>)</strong></p>
<hr class="docutils" />
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal M_0\)</span>는 예측변수를 포함하지 않는 영(null) 모델을 나타낸다.</p></li>
<li><p>(1) 예측변수가 하나도 없는 <span class="math notranslate nohighlight">\(\mathcal M_0\)</span> 모델에 예측변수를 추가적으로 1개 늘리는 세 가지 모델(즉 세 개의 단순 선형 회귀 모델)을 피팅한다. 이 세 가지 모델 중에서 최상의 것을 선택하고, 이를 <span class="math notranslate nohighlight">\(\mathcal M_1\)</span>이라고 부른다. 여기서 최상의 모델은 RSS가 가장 작거나 <span class="math notranslate nohighlight">\(R^2\)</span>가 가장 큰 것으로 정의된다.<br />
(2) 이번에는 <span class="math notranslate nohighlight">\(\mathcal M_1\)</span>에 예측변수를 추가적으로 한 개 늘리는 두 가지 모델(즉 예측변수가 2개인 두 가지 다중 선형 회귀 모델)을 피팅한다. 이 두 가지 모델 중에서 최상의 것을 선택하고, 이를 <span class="math notranslate nohighlight">\(\mathcal M_2\)</span>라고 부른다.<br />
(3) 이번에는 <span class="math notranslate nohighlight">\(\mathcal M_2\)</span>에 예측변수를 추가적으로 한 개 늘리는 모델(즉 예측변수 3개를 모두 사용한 다중 선형 회귀 모델)을 피팅한다. 예측변수가 3개인 경우는 모델이 하나밖에 없기 때문에 이것이 최상의 것이 되고,이를 <span class="math notranslate nohighlight">\(\mathcal M_3\)</span>라고 부른다.</p></li>
<li><p>정보기준 <span class="math notranslate nohighlight">\(C_p\)</span>(AIC), BIC, adjusted <span class="math notranslate nohighlight">\(R^2\)</span>를 사용하여 <span class="math notranslate nohighlight">\(\mathcal M_0,\mathcal M_1,\mathcal M_2,\mathcal M_3\)</span> 중에서 단일의 최적 모델을 선택한다.(결국 총 7개 모델 중에서 가장 우수한 것을 선택하는 것임.)</p></li>
</ol>
</div></blockquote>
<p><img alt="전진 단계적 선택(p=3)" src="https://raw.githubusercontent.com/pilsunchoi/images/main/10-3.png" /></p>
<p>다음은 예측변수가 <span class="math notranslate nohighlight">\(p\)</span>개일 때, 전진 단계적 선택 알고리즘을 정리한 것이다.</p>
<blockquote>
<div><p><strong>Forward stepwise selection 알고리즘</strong></p>
<hr class="docutils" />
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal M_0\)</span>는 예측변수를 포함하지 않는 영(null) 모델을 나타낸다.
</br></p></li>
<li><p><span class="math notranslate nohighlight">\(k = 0, 1,. . ., p-1:\)</span><br />
(1) <span class="math notranslate nohighlight">\(\mathcal M_k\)</span>에서 예측변수를 추가적으로 하나 늘리는 모든 <span class="math notranslate nohighlight">\(p − k\)</span>개의 모델을 고려한다.<br />
(2) 이 <span class="math notranslate nohighlight">\(p - k\)</span>개의 모델 중에서 최상의 것을 선택하고, 이를 <span class="math notranslate nohighlight">\(\mathcal M_{k+1}\)</span>이라고 부른다. 여기서 최상의 모델은 RSS가 가장 작거나 <span class="math notranslate nohighlight">\(R^2\)</span>가 가장 큰 것으로 정의된다.
</br></p></li>
<li><p>정보기준 <span class="math notranslate nohighlight">\(C_p\)</span>(AIC), BIC, adjusted <span class="math notranslate nohighlight">\(R^2\)</span>를 사용하여 <span class="math notranslate nohighlight">\(\mathcal M_0,...,\mathcal M_p\)</span> 중에서 단일의 최적 모델을 선택한다.</p></li>
</ol>
</div></blockquote>
<p><span class="math notranslate nohighlight">\(2^p\)</span>개의 모델을 피팅해야 하는 최량 부분집합 선택과 달리, 전진 단계적 선택은 <span class="math notranslate nohighlight">\(k = 0, . . . , p  − 1\)</span>에 대해 각각 <span class="math notranslate nohighlight">\(p − k\)</span>개의 모델을 피팅하게 된다. 이것은 영(null) 모델까지 포함해서 총 <span class="math notranslate nohighlight">\(1 + \sum_{k = 0}^{p−1}{(p−k)} = 1 + p (p + 1) / 2\)</span>개이다.</p>
<p>이것은 상당한 차이이다. 가령 <span class="math notranslate nohighlight">\(p = 20\)</span>일 때 최량 부분집합 선택은 1,048,576개의 모델을 피팅해야 하는 반면, 전진 단계적 선택은 211개의 모델만 피팅하면 된다.</p>
<p><strong>전진 단계적 선택 함수 만들기</strong></p>
<p>최량 부분집합 선택과 마찬가지로 전진(forward) 및 후진(backward) 단계적 선택을 수행하기 위해서는 함수를 직접 만들어야 한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward_step_select</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">predictors</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    전진 단계적 알고리즘을 사용하여 반응을 예측변수에 회귀시킨다. 최소 RSS를 기준으로 예측변수이 추가된다.</span>
<span class="sd">    </span>
<span class="sd">    PARAMETERS</span>
<span class="sd">    -----------</span>
<span class="sd">    df : 반응 및 예측변수가 들어있는 pandas 데이터프레임</span>
<span class="sd">    predictors : 예측변수로 사용되는 모든 예측변수 리스트</span>
<span class="sd">    response : 데이터프레임에서 예측변수에 회귀시키는 변수 리스트</span>
<span class="sd">    max_features : 예측변수 리스트에서 사용할 최대 예측변수 개수</span>
<span class="sd"> </span>
<span class="sd">    RETURNS</span>
<span class="sd">    --------</span>
<span class="sd">    max_features까지 예측변수 개수가 증가하는 모델 리스트</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">process_linear_model</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        선형 회귀 모델을 구축</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))</span>  <span class="c1"># bool → float 변환</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">response</span><span class="p">]</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">RSS</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">ssr</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">RSS</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_model</span><span class="p">(</span><span class="n">best_features</span><span class="p">,</span> <span class="n">remaining_features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        새 모델의 RSS를 계산하고 RSS가 가장 낮은 모델을 반환</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">remaining_features</span><span class="p">:</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">process_linear_model</span><span class="p">(</span><span class="n">best_features</span> <span class="o">+</span> <span class="p">[</span><span class="n">feature</span><span class="p">]))</span>
            
        <span class="c1"># RSS 가장 낮은 모델을 선택</span>
        <span class="n">new_model</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span> <span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">new_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">new_model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">index</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>
        
        <span class="k">return</span> <span class="n">new_features</span><span class="p">,</span> <span class="n">new_model</span>
    
    <span class="c1"># models, model features를 위한 empty list를 만듦</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">remaining_features</span> <span class="o">=</span> <span class="n">predictors</span>
    
    <span class="k">while</span> <span class="n">remaining_features</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_features</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_features</span><span class="p">:</span>
        
        <span class="n">new_features</span><span class="p">,</span> <span class="n">new_model</span> <span class="o">=</span> <span class="n">update_model</span><span class="p">(</span><span class="n">best_features</span><span class="p">,</span> <span class="n">remaining_features</span><span class="p">)</span>
        <span class="n">best_features</span> <span class="o">=</span> <span class="n">new_features</span>  
        <span class="n">remaining_features</span> <span class="o">=</span>  <span class="p">[</span><span class="n">feature</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">predictors</span> 
                               <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">best_features</span><span class="p">]</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_model</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">models</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Credit 데이터세트에 대해 실행</strong></p>
<p>위에서 만든 <code class="docutils literal notranslate"><span class="pre">forward_step_select()</span></code> 함수를 Credit 데이터세트(<code class="docutils literal notranslate"><span class="pre">df</span></code>)에 대해 실행한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">predictors</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;Balance&#39;</span><span class="p">)</span>
<span class="n">mods</span> <span class="o">=</span> <span class="n">forward_step_select</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Balance&#39;</span><span class="p">],</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>각 모델 크기에 대해 최상의 변수 세트를 출력시킨다. 아래 결과를 보면, 최상의 단일 변수 모델은 <code class="docutils literal notranslate"><span class="pre">Rating</span></code>만 포함되고, 최상의 2개 변수 모델은 거기에 추가로 <code class="docutils literal notranslate"><span class="pre">Income</span></code>이 포함된다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">model_i</span> <span class="ow">in</span> <span class="n">mods</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model_i</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">exog_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;const&#39;, &#39;Rating&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;, &#39;Student_Yes&#39;, &#39;Limit&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;, &#39;Student_Yes&#39;, &#39;Limit&#39;, &#39;Cards&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;, &#39;Student_Yes&#39;, &#39;Limit&#39;, &#39;Cards&#39;, &#39;Age&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;, &#39;Student_Yes&#39;, &#39;Limit&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;, &#39;Student_Yes&#39;, &#39;Limit&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Ethnicity_Asian&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;, &#39;Student_Yes&#39;, &#39;Limit&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Ethnicity_Asian&#39;, &#39;Married_Yes&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;, &#39;Student_Yes&#39;, &#39;Limit&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Ethnicity_Asian&#39;, &#39;Married_Yes&#39;, &#39;Ethnicity_Caucasian&#39;]
[&#39;const&#39;, &#39;Rating&#39;, &#39;Income&#39;, &#39;Student_Yes&#39;, &#39;Limit&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Ethnicity_Asian&#39;, &#39;Married_Yes&#39;, &#39;Ethnicity_Caucasian&#39;, &#39;Education&#39;]
</pre></div>
</div>
</div>
</div>
<p>아래 표 10.1에는 최량 부분집합 선택과 전진 단계적 선택에 있어서 예측변수가 1~4개인 경우에 어떤 변수들이 선택되었는지 보여준다. 처음 세 개 모델은 동일하지만 네 번째 모델은 서로 다른 것을 알 수 있다.</p>
<p><strong>표 10.1.</strong> Credit 데이터세트에 대한 최량 부분집합 선택 및 전진 단계적 선택에서 변수 개수별로 선택된 최상의 변수 조합.</p>
<p><img alt="Credit 데이터세트 변수선택 결과" src="https://raw.githubusercontent.com/pilsunchoi/images/main/10-4.png" /></p>
<ul class="simple">
<li><p>그림 출처: ISLP, TABLE 6.1</p></li>
</ul>
</section>
<section id="id8">
<h3>후진 단계적 선택<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>후진 단계적 선택은 전진 단계적 선택과 마찬가지로 최량 부분집합 선택에 대한 효율적인 대안을 제공한다. 전진 단계적 선택과 달리 후진 방식을 취하는데, <span class="math notranslate nohighlight">\(p\)</span>개의 예측변수를 모두 포함하는 전체(full) 모델에서 시작하여 한 번에 하나씩 가장 유용하지 않은 예측변수를 반복적으로 제거해 나간다.</p>
<p>우선 이해를 돕기 위해 예측변수가 3개인 경우에 대해 후진 단계적 선택 알고리즘을 생각해보자.</p>
<blockquote>
<div><p><strong>Backward stepwise selection 알고리즘 (<span class="math notranslate nohighlight">\(p=3\)</span>)</strong></p>
<hr class="docutils" />
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal M_3\)</span>는 <span class="math notranslate nohighlight">\(3\)</span>개 예측변수 모두를 포함하는 전체(full) 모델을 나타낸다.</p></li>
<li><p>(1) <span class="math notranslate nohighlight">\(\mathcal M_3\)</span>에서 예측변수를 한 개 뺀 세 가지 모델(즉 예측변수가 2개인 세 가지 다중 선형 회귀 모델)을 피팅한다. 이 세 가지 모델 중에서 최상의 것을 선택하고, 이를 <span class="math notranslate nohighlight">\(\mathcal M_2\)</span>라고 부른다. 여기서 최상의 모델은 RSS가 가장 작거나 <span class="math notranslate nohighlight">\(R^2\)</span>가 가장 큰 것으로 정의된다.<br />
(2) 이번에는 <span class="math notranslate nohighlight">\(\mathcal M_2\)</span>에서 예측변수를 추가적으로 한 개 뺀 두 가지 모델(즉 예측변수가 1개인 두 가지 단순 선형 회귀 모델)을 피팅한다. 이 두 가지 모델 중에서 최상의 것을 선택하고, 이를 <span class="math notranslate nohighlight">\(\mathcal M_1\)</span>이라고 부른다.<br />
(3) 이번에는 <span class="math notranslate nohighlight">\(\mathcal M_1\)</span>에서 예측변수를 추가적으로 한 개 뺀 모델(즉 예측변수가 하나도 들어있지 않은 null 모델)을 피팅하고, 이를 <span class="math notranslate nohighlight">\(\mathcal M_0\)</span>라고 부른다.</p></li>
<li><p>정보기준 <span class="math notranslate nohighlight">\(C_p\)</span>(AIC), BIC, adjusted <span class="math notranslate nohighlight">\(R^2\)</span>를 사용하여 <span class="math notranslate nohighlight">\(\mathcal M_0,\mathcal M_1,\mathcal M_2,\mathcal M_3\)</span> 중에서 단일의 최적 모델을 선택한다.(결국 총 7개 모델 중에서 가장 우수한 것을 선택하는 것임)</p></li>
</ol>
</div></blockquote>
<p><img alt="후진 단계적 선택(p=3)" src="https://raw.githubusercontent.com/pilsunchoi/images/main/10-6.png" /></p>
<p>다음은 예측변수가 <span class="math notranslate nohighlight">\(p\)</span>개일 때, 후진 단계적 선택 알고리즘을 정리한 것이다.</p>
<blockquote>
<div><p><strong>Backward stepwise selection</strong></p>
<hr class="docutils" />
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal M_p\)</span>는 모든 <span class="math notranslate nohighlight">\(p\)</span>개 예측변수를 포함하는 전체(full) 모델을 나타낸다.
</br></p></li>
<li><p><span class="math notranslate nohighlight">\(k = p, p-1,. . ., 1:\)</span><br />
(1) <span class="math notranslate nohighlight">\(\mathcal M_k\)</span>에서 예측변수가 <span class="math notranslate nohighlight">\(k-1\)</span>개로 하나 줄어든 모든 <span class="math notranslate nohighlight">\(k\)</span>개의 모델을 고려한다.<br />
(2) 이 <span class="math notranslate nohighlight">\(k\)</span>개의 모델 중에서 최상의 것을 선택하고, 이를 <span class="math notranslate nohighlight">\(\mathcal M_{k-1}\)</span>이라고 부른다. 여기서 최상의 모델은 RSS가 가장 작거나 <span class="math notranslate nohighlight">\(R^2\)</span>가 가장 큰 것으로 정의된다.
</br></p></li>
<li><p>정보기준 <span class="math notranslate nohighlight">\(C_p\)</span>(AIC), BIC, adjusted <span class="math notranslate nohighlight">\(R^2\)</span>를 사용하여 <span class="math notranslate nohighlight">\(\mathcal M_0,...,\mathcal M_p\)</span> 중에서 단일의 최적 모델을 선택한다.</p></li>
</ol>
</div></blockquote>
<p><strong>후진 단계적 선택 함수 만들기</strong></p>
<p>후진 단계적 선택 함수는 전진 선택 함수와 매우 유사하다. 단지 <code class="docutils literal notranslate"><span class="pre">update_model()</span></code> 함수에서 예측변수를 제거해 나간다는 것이 다른 점이다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">backward_step_select</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">process_linear_model</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        선형 회귀 모델을 구축</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))</span>  <span class="c1"># bool → float 변환</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">response</span><span class="p">]</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">RSS</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">ssr</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">RSS</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_model</span><span class="p">(</span><span class="n">best_features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        새 모델의 RSS를 계산하고 RSS가 가장 낮은 모델을 반환</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">best_features</span><span class="p">:</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">process_linear_model</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">best_features</span> 
                                                 <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">feature</span><span class="p">]))</span>
            
        <span class="c1"># RSS 가장 낮은 모델을 선택</span>
        <span class="n">new_model</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span> <span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">new_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">new_model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">index</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>
        
        <span class="k">return</span> <span class="n">new_features</span><span class="p">,</span> <span class="n">new_model</span>
    
    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_features</span> <span class="o">=</span> <span class="n">predictors</span>
        
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_features</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        
        <span class="n">best_features</span><span class="p">,</span> <span class="n">new_model</span> <span class="o">=</span> <span class="n">update_model</span><span class="p">(</span><span class="n">best_features</span><span class="p">)</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_model</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">models</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Credit 데이터세트에 대해 실행</strong></p>
<p>위에서 만든 <code class="docutils literal notranslate"><span class="pre">backward_step_select()</span></code> 함수를 Credit 데이터세트(<code class="docutils literal notranslate"><span class="pre">df</span></code>)에 대해 실행한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">predictors</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;Balance&#39;</span><span class="p">)</span>
<span class="n">models_b</span> <span class="o">=</span> <span class="n">backward_step_select</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Balance&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>각 모델 크기에 대해 최상의 변수 세트를 출력시킨다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">model_i</span> <span class="ow">in</span> <span class="n">models_b</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model_i</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">exog_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Student_Yes&#39;, &#39;Married_Yes&#39;, &#39;Ethnicity_Asian&#39;, &#39;Ethnicity_Caucasian&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Student_Yes&#39;, &#39;Married_Yes&#39;, &#39;Ethnicity_Asian&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Student_Yes&#39;, &#39;Ethnicity_Asian&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Gender_Female&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Age&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Rating&#39;, &#39;Cards&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Cards&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;, &#39;Student_Yes&#39;]
[&#39;const&#39;, &#39;Income&#39;, &#39;Limit&#39;]
[&#39;const&#39;, &#39;Limit&#39;]
[&#39;const&#39;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id9">
<h2>10.4 최적 모델 선택<a class="headerlink" href="#id9" title="Link to this heading">#</a></h2>
<p>최량 부분집합 선택, 전진 선택, 후진 선택 등은 <span class="math notranslate nohighlight">\(p\)</span>개 예측변수의 부분집합을 지닌 모델을 만들어 비교한다. 따라서 이들 방법을 구현하려면 예측변수 부분집합 별로 고른 최상의 모델 중 어떤 모델이 가장 적합한지 결정하는 방법이 필요하다. 그런데 RSS와 <span class="math notranslate nohighlight">\(R^2\)</span>의 경우 이들이 계산돼 나온 훈련 데이터세트에 있어서는 예측변수의 개수가 많은 모델일수록 RSS는 작아지고 <span class="math notranslate nohighlight">\(R^2\)</span>는 커진다. 즉 훈련 오차가 작아진다.</p>
<p>그러나 우리는 훈련 오차가 아니라 테스트 오차가 작은 모델을 원한다. 훈련 오차만을 고려해서 변수를 선택하게 되면 과적합 문제가 발생할 수 있다. 이 점에서 RSS와 <span class="math notranslate nohighlight">\(R^2\)</span>는 예측변수 개수가 서로 다른 모델 중에서 최적의 모델을 선택하는 데는 적합하지 않다. 이에 대한 대안이 정보기준과 교차검증이다.</p>
<section id="id10">
<h3>정보기준<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>RSS와 <span class="math notranslate nohighlight">\(R^2\)</span>가 갖고 있는 문제를 해결하는 한 가지 방법은 과적합으로 인한 편향(bias)을 감안하여 훈련 오차를 조정하는 방법이다. 훈련 오차를 수학적으로 조정하여 테스트 오차를 추정하는 방법이다. 즉 <strong>테스트 오차를 간접적으로 추정</strong>하려는 것이다. 여기에 속하는 것들이 <span class="math notranslate nohighlight">\(C_p\)</span>, AIC, BIC, Adjusted <span class="math notranslate nohighlight">\(R^2\)</span> 등과 같은 정보기준(또는 모델선택기준)이다. 여기에서는 이 중 Adjusted <span class="math notranslate nohighlight">\(R^2\)</span>에 대해서만 좀 더 자세히 살펴보기로 한다.</p>
<p>예측변수가 <span class="math notranslate nohighlight">\(d\)</span>개 있는 최소 제곱 모형의 경우 Adjusted <span class="math notranslate nohighlight">\(R^2\)</span>는 다음과 같이 계산된다.</p>
<div class="math notranslate nohighlight">
\[
{\rm Adjusted}~ R^2=1-\frac {{\rm RSS}/(n-d-1)}{{\rm TSS}/(n-1)}
\]</div>
<p>식에서 보듯이 Adjusted <span class="math notranslate nohighlight">\(R^2\)</span>를 최대화하는 것은 <span class="math notranslate nohighlight">\(\frac {\rm RSS} {n−d−1}\)</span>을 최소화하는 것과 동일하다. 왜냐하면 <span class="math notranslate nohighlight">\({\rm TSS}\)</span>나 <span class="math notranslate nohighlight">\((n-1)\)</span>은 고정돼 있기 때문이다. 그런데 모델의 변수 개수 <span class="math notranslate nohighlight">\(d\)</span>가 증가하면 <span class="math notranslate nohighlight">\({\rm RSS}\)</span>는 항상 감소하지만, <span class="math notranslate nohighlight">\(\frac {\rm RSS} {n−d−1}\)</span>이 항상 감소하는 것은 아니다(분모에 <span class="math notranslate nohighlight">\(d\)</span>가 있기 때문). 즉 <span class="math notranslate nohighlight">\(R^2\)</span>와 달리 Adjusted <span class="math notranslate nohighlight">\(R^2\)</span>는 모델에 불필요한 변수를 포함하는 경우 그 대가를 지불한다. 이런 식으로 과적합으로 인한 편향을 감안하여 훈련 오차를 조정하는 것이다. 결국 Adjusted <span class="math notranslate nohighlight">\(R^2\)</span>의 값이 클수록 테스트 오차가 작은 것을 의미한다.</p>
</section>
<section id="chatgpt-q-a">
<h3>ChatGPT Q&amp;A<a class="headerlink" href="#chatgpt-q-a" title="Link to this heading">#</a></h3>
<blockquote>
<div><p><strong>AIC, BIC 등의 정보기준에 대해 쉽게 설명해줘.</strong></p>
</div></blockquote>
<hr class="docutils" />
<blockquote>
<div><p>AIC(Akaike Information Criterion)와 BIC(Bayesian Information Criterion)는 모델 선택에서 사용되는 두 가지 중요한 정보 기준입니다. 이들은 모델의 성능을 평가하고, 여러 모델 중에서 최적의 모델을 선택하는 데 도움을 줍니다. 간단하게 말해서, 이 기준들은 모델이 데이터를 얼마나 잘 설명하는지(적합도)와 모델의 복잡성(사용된 파라미터의 수) 사이의 균형을 평가합니다.</p>
<p><strong>AIC (Akaike Information Criterion)</strong></p>
<ul class="simple">
<li><p><strong>AIC = 2k - 2ln(L)</strong></p></li>
<li><p>여기서, <code class="docutils literal notranslate"><span class="pre">k</span></code>는 모델에 있는 파라미터의 수, <code class="docutils literal notranslate"><span class="pre">L</span></code>은 최대 우도(likelihood)입니다.</p></li>
<li><p>AIC는 모델의 복잡성과 적합도를 동시에 고려합니다. 모델이 데이터에 더 잘 적합되면 우도(L)가 증가하고, 모델이 더 복잡해지면(더 많은 파라미터를 사용하면) k가 증가합니다.</p></li>
<li><p>AIC 값이 낮은 모델을 선호합니다. 낮은 AIC 값은 좋은 모델의 적합도와 상대적으로 낮은 모델 복잡성을 의미합니다.</p></li>
</ul>
<p><strong>BIC (Bayesian Information Criterion)</strong></p>
<ul class="simple">
<li><p><strong>BIC = ln(n)k - 2ln(L)</strong></p></li>
<li><p>여기서, <code class="docutils literal notranslate"><span class="pre">n</span></code>은 샘플의 크기, <code class="docutils literal notranslate"><span class="pre">k</span></code>는 모델에 있는 파라미터의 수, <code class="docutils literal notranslate"><span class="pre">L</span></code>은 최대 우도입니다.</p></li>
<li><p>BIC도 AIC와 유사하게 모델의 적합도와 복잡성을 고려하지만, 샘플 크기 <code class="docutils literal notranslate"><span class="pre">n</span></code>을 고려하여 모델의 복잡성에 대해 더 큰 벌칙을 부여합니다.</p></li>
<li><p>BIC 값이 낮은 모델을 선호합니다. BIC는 특히 큰 데이터셋에서 더 복잡한 모델에 대해 더 엄격한 벌칙을 부여하여 과적합을 방지하는 데 도움이 됩니다.</p></li>
</ul>
<p><strong>요약</strong></p>
<p>AIC와 BIC 모두 모델의 적합도와 복잡성 사이의 균형을 찾는 데 사용되며, 값이 낮을수록 좋은 모델로 간주됩니다. BIC는 AIC에 비해 샘플 크기의 영향을 더 많이 받으며, 과적합을 방지하는 데 더 효과적일 수 있습니다. 모델 선택 시에는 이러한 정보 기준 외에도 교차 검증 같은 다른 방법을 함께 고려하는 것이 좋습니다.</p>
</div></blockquote>
</section>
<section id="id11">
<h3>검증<a class="headerlink" href="#id11" title="Link to this heading">#</a></h3>
<p>정보기준 대신 <strong>검증</strong>(validation)을 통해 <strong>테스트 오차를 직접 추정</strong>할 수 있다. 방법은 간단한데, 훈련 관측 일부를 보류해놓은 다음, 그것을 사용하여 테스트 오차를 추정하는 것이다. 즉 보류해 놓은 관측으로 각 후보 모델에 대해 테스트 세트 오차 또는 교차검증 오차를 계산할 수 있다. 그렇게 하여 테스트 오차가 가장 작은 모델을 선택하면 된다. 검증에서 <strong>검증 세트</strong> 접근은 따로 떼어 놓은 훈련 세트의 일부를 전적으로 테스트 세트로 사용하는 방식을 말하고, <strong>교차검증</strong> 접근은 훈련 세트의 일부를 “번갈아 가면서” 테스트 세트로  사용하는 방식을 말한다.(<a class="reference internal" href="#%EB%B6%80%EB%A1%9D:-%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Cross-Validation)"><span class="xref myst">부록: 교차검증(Cross-Validation)</span></a> 참조.)</p>
<p>이 방법은 정보기준 방식에 비해 테스트 오차를 직접 추정하고 기본 모델에 대한 가정을 적게 한다는 이점이 있다. 또한 정보기준을 계산하는 데 필요한 모델 자유도(예: 모델의 예측변수 개수)를 정확하게 파악하기 어렵거나, 오차항 분산 <span class="math notranslate nohighlight">\(\sigma^2\)</span>를 추정하기 어려운 경우에도 사용할 수 있다.</p>
<p>과거에는 <span class="math notranslate nohighlight">\(p\)</span>나 <span class="math notranslate nohighlight">\(n\)</span>이 큰 경우, 교차검증을 수행하는 것이 계산적으로 어려워 교차검증 대신 정보기준을 사용하는 경우가 많았다. 그러나 오늘날 컴퓨터 성능이 좋아짐에 따라 교차검증이 매우 매력적인 접근 방식이 되었다.</p>
<p><strong>Credit 데이터세트에 대해 검증 세트 접근(최량 부분집합 선택)</strong></p>
<p>Credit 데이터세트에 대해 다시 한 번 최량 부분집합 선택을 수행해보자. 이때 최적 모델을 찾는 방법으로 검증을 사용한다. 그 중에서도 검증 세트 접근, 즉 훈련 세트의 일부를 떼어서 테스트 세트로 사용하는 방법을 사용한다. 여기에서는 전체 데이터세트를 임의로 절반으로 나누어 각각 훈련 세트와 테스트 세트로 사용한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>훈련 세트(<code class="docutils literal notranslate"><span class="pre">df_train</span></code>)에 대해 앞에서 만든 <code class="docutils literal notranslate"><span class="pre">best_subsets</span></code> 함수를 적용하여 예측변수 개수 별로 최상의 모델을 선택한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">predictors</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;Balance&#39;</span><span class="p">)</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">best_subsets</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Balance&#39;</span><span class="p">],</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>이제 따로 떼어 놓은 테스트 세트(<code class="docutils literal notranslate"><span class="pre">df_test</span></code>)를 이용하여 각 모델 크기 별로 검증 세트 오차(MSE: Mean Squared Error)를 계산한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
    <span class="n">Balance_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">mses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mses</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">Balance_pred</span> <span class="o">-</span> <span class="n">df_test</span><span class="o">.</span><span class="n">Balance</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MSEs =&#39;</span><span class="p">,</span> <span class="n">mses</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MSEs = [54282.25816835 26135.56555707 11129.23122325 10274.42992706
 10170.0485311  10319.79376989 10167.24353295 10379.68738791
 10219.55383892 10261.6016929  10262.22967703]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">min_index</span><span class="p">,</span> <span class="n">min_mse</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">mses</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">min_index</span><span class="p">,</span> <span class="n">min_mse</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>6 10167.243532952185
</pre></div>
</div>
</div>
</div>
<p>위 결과를 보면, 가장 좋은 모델은 7개의 변수를 가진 모델이다. 각 모델 크기에 대해 MSE 추정치를 그림으로 그려보자. 변수 개수가 3개보다 많아지면 테스트 MSE가 별로 바뀌지 않는 것을 알 수 있다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;8&#39;</span> <span class="c1"># 전체적으로(globally) 폰트 크기 조정</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">num_predictors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">))</span> <span class="c1"># X축에 예측변수 개수 설정</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">num_predictors</span><span class="p">,</span> <span class="n">mses</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">min_index</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_mse</span><span class="p">,</span> <span class="s1">&#39;gx&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">markeredgewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Predictors&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Validation MSE&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/8a3c4843968d41b672a9794dee779c00508eb9cbd9b41009ad5332bf69a72f73.png" src="../_images/8a3c4843968d41b672a9794dee779c00508eb9cbd9b41009ad5332bf69a72f73.png" />
</div>
</div>
<p><strong>Credit 데이터세트에 대해 10중 교차검증 접근(최량 부분집합 선택)</strong></p>
<p>이제 10중 교차검증을 사용하여 최량 부분집합 선택을 수행해보자. 우선 데이터를 10개 폴드로 분할한다. 변수 개수가 11개이기 때문에 총 10개 폴드 각각에 (해당 폴드가 테스트 세트로 사용될 때) 11개 모델에 대한 MSE가 생성된다. 이를 평균하여 교차검증 테스트 MSE를 얻는다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># sklearn의 KFold로 10개 폴드 생성</span>
<span class="n">mses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictors</span><span class="p">)])</span> <span class="c1"># 10Xp 행렬: 모델 크기별로 10개 테스트 세트의 MSE 저장</span>

<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>

    <span class="n">df_train</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
    <span class="n">df_test</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">models</span> <span class="o">=</span> <span class="n">best_subsets</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Balance&#39;</span><span class="p">],</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    
    <span class="c1"># 각 모델의 MSE 계산</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
        <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
        <span class="n">Balance_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">mses</span><span class="p">[:,</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">Balance_pred</span> <span class="o">-</span> <span class="n">df_test</span><span class="o">.</span><span class="n">Balance</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        
<span class="c1"># 모델 크기별로 10개 폴드의 MSE를 평균함</span>
<span class="n">cvs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>교차검증 테스트 오차를 그림으로 그린다. 아래 결과를 보면, 변수가 3개인 모델이 가장 낮은 테스트 MSE를 산출하는 것으로 나타났다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">num_predictors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">))</span> <span class="c1"># X축에 예측변수 개수 설정</span>
<span class="n">min_index</span><span class="p">,</span> <span class="n">min_CV</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">cvs</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># 평균 MSE가 가장 낮은 모델</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">num_predictors</span><span class="p">,</span> <span class="n">cvs</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test MSE&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">min_index</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_CV</span><span class="p">,</span> <span class="s1">&#39;rx&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">markeredgewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Predictors&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;CV Error&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0fd0a3e9b812240e0b446729a55c32f201477cfd8f6ebf32bda973d49a60e14a.png" src="../_images/0fd0a3e9b812240e0b446729a55c32f201477cfd8f6ebf32bda973d49a60e14a.png" />
</div>
</div>
</section>
</section>
<section id="ridge-lasso">
<h2>10.5 Ridge 및 Lasso<a class="headerlink" href="#ridge-lasso" title="Link to this heading">#</a></h2>
<p>앞에서 설명한 부분집합 선택 방법은 예측변수의 최적 세트를 찾는 것으로서 최소제곱 방법을 사용하는 것에는 변함이 없다. 이에 대한 대안으로 (모든 <span class="math notranslate nohighlight">\(p\)</span>개 예측변수를 포함하는 모델을 사용하되) 계수 추정값을 0쪽으로 축소하는 기법을 사용할 수 있다. 이러한 방법이 피팅의 성과를 개선하는 이유가 언뜻 명확하게 다가오지 않을 수 있지만, 계수 크기를 축소시키면 무엇보다 추정 계수의 분산을 크게 줄일 수 있다. 회귀 계수를 0쪽으로 축소시키는 가장 잘 알려진 두 가지 기법은 <strong>릿지(Ridge) 회귀</strong>와 <strong>라쏘(Lasso)</strong> 이다.</p>
<p>릿지와 라쏘를 수행하기 위해 <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> 패키지를 사용한다. 이 패키지의 주요 함수는 Ridge 회귀 모델을 피팅하는 데 사용하는 <code class="docutils literal notranslate"><span class="pre">Ridge()</span></code>, 그리고 Lasso 모델을 피팅하는 <code class="docutils literal notranslate"><span class="pre">Lasso()</span></code>이다. 또한 교차검증과 관련된 <code class="docutils literal notranslate"><span class="pre">RidgeCV()</span></code> 및 <code class="docutils literal notranslate"><span class="pre">LassoCV()</span></code>가 있다.</p>
<section id="ridge">
<h3>Ridge 회귀<a class="headerlink" href="#ridge" title="Link to this heading">#</a></h3>
<p>릿지 회귀는 선형 회귀 모델에 다중공선성(multicollinearity), 즉 예측변수들 사이에 상관성이 높아 최소제곱 추정값에 부정확성이 높아지는 것에 대한 하나의 해법으로 1970년대에 개발되었다. 앞에서 설명했듯이 최소제곱(OLS) 피팅은 다음의 잔차제곱합(RSS)을 최소화하는 방식으로 <span class="math notranslate nohighlight">\(\beta_0, \beta_1,..., \beta_p\)</span>를 추정한다.</p>
<div class="math notranslate nohighlight">
\[
{\rm RSS}= \sum_{i=1}^{n} \left( y_i- \beta_0 -\sum_{j=1}^{p}\beta_j x_{ij} \right)^2 \tag {10.1}
\]</div>
<p>릿지는 최소제곱과 매우 유사하지만 RSS가 아니라 다음을 최소화하는 회귀 계수 추정치 <span class="math notranslate nohighlight">\(\hat\beta{^R_\lambda}\)</span>을 구한다.</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^{n} \left( y_i- \beta_0 -\sum_{j=1}^{p}\beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^{p}\beta_j^2 = {\rm RSS}+ \lambda \sum_{j=1}^{p}\beta_j^2 \tag {10.2}
\]</div>
<p>여기서 <span class="math notranslate nohighlight">\(\lambda ≥ 0\)</span>은 조정 파라미터(tuning parameter)이다.</p>
<p>위 식 10.2는 두 가지 다른 기준을 절충한다. 우선 최소제곱과 마찬가지로 릿지 회귀는 RSS를 작게 만들어 데이터에 잘 맞는 계수 추정치를 찾는다. 그러면서 다른 한편으로 <strong>축소 페널티</strong>(shrinkage penalty)로 불리는 두 번째 항 <span class="math notranslate nohighlight">\(\lambda \sum_{j=1}^p \beta_j^2\)</span>는 <span class="math notranslate nohighlight">\(\beta_j\)</span>의 추정치를 0쪽으로 축소시키는 효과가 있다(절편은 제외). 왜냐하면 <span class="math notranslate nohighlight">\(\beta_1,..., \beta_p\)</span>가 0에 가까울수록 축소 페널티 항이 작아지기 때문이다.</p>
<p>여기에서 조정 파라미터 <span class="math notranslate nohighlight">\(\lambda\)</span>는 회귀 계수 추정치에 대한 위 두 개 항의 상대적 영향을 제어하는 역할을 한다. <span class="math notranslate nohighlight">\(\lambda = 0\)</span>이면 페널티 항은 효과가 없으며, 릿지는 최소제곱 추정값을 생성한다. 반면 <span class="math notranslate nohighlight">\(\lambda \to \infty\)</span>일수록, 축소 페널티의 영향이 커지고 릿지 회귀 계수 추정치가 0에 가까워진다.</p>
<p>하나의 계수 추정 세트만 생성하는 최소제곱과 달리 릿지는 각 <span class="math notranslate nohighlight">\(\lambda\)</span>값 별로 다른 계수 추정 세트 <span class="math notranslate nohighlight">\(\hat\beta{^R_\lambda}\)</span>를 생성한다. 따라서 좋은 <span class="math notranslate nohighlight">\(\lambda\)</span>값을 선택하는 것이 중요하다. 이를 위해서는 교차검증을 활용할 필요가 있다.</p>
</section>
<section id="id12">
<h3>Credit 데이터세트 릿지 회귀 실행<a class="headerlink" href="#id12" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span> 
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">RidgeCV</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">LassoCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Ridge()</span></code> 함수에는 모델을 조정하는 데 사용되는 파라미터 <code class="docutils literal notranslate"><span class="pre">alpha</span></code>(<span class="math notranslate nohighlight">\(\lambda\)</span>에 해당)가 있다. 우리는 매우 큰 값부터 아주 작은 값까지의 숫자를 생성시켜 <span class="math notranslate nohighlight">\(\lambda\)</span>값으로 사용하고자 한다. 이렇게 함으로써 절편만 포함하는 영(null) 모델부터 최소제곱 피팅에 이르기까지 전체 시나리오를 포괄할 수 있다. 즉 <span class="math notranslate nohighlight">\(\lambda\)</span>값이 아주 크면, 축소 페널티의 영향이 커져서 절편을 제외하고는 계수 값이 0쪽으로 축소되고, 반대로 <span class="math notranslate nohighlight">\(\lambda\)</span>값이 아주 작으면, 릿지 회귀는 최소제곱 추정에 가까워진다.</p>
<p>아래에서는 100개의 <span class="math notranslate nohighlight">\(\lambda\)</span>값에 대해 릿지 회귀 계수 벡터를 추정하여 <code class="docutils literal notranslate"><span class="pre">coefs</span></code>라는 이름으로 지정한다. 따라서 <code class="docutils literal notranslate"><span class="pre">coefs</span></code>는 100개의 행(각 <span class="math notranslate nohighlight">\(\lambda\)</span>값에 대해 하나씩)과 11개의 열(Credit 데이터세트 각 예측변수에 대해 하나씩)이 있는 <span class="math notranslate nohighlight">\( 100 \times 11 \)</span> 행렬이다.</p>
<p>추정하기 전에 예측변수가 동일한 척도를 갖도록 표준화시키는 작업을 거쳤다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="mi">3</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span><span class="o">*</span><span class="mf">0.2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1.18098000e+04 9.45920006e+03 7.57645902e+03 6.06845514e+03
 4.86060147e+03 3.89315667e+03 3.11827024e+03 2.49761571e+03
 2.00049507e+03 1.60232036e+03 1.28339759e+03 1.02795260e+03
 8.23350883e+02 6.59472702e+02 5.28212520e+02 4.23078113e+02
 3.38869457e+02 2.71421530e+02 2.17398309e+02 1.74127767e+02
 1.39469710e+02 1.11709926e+02 8.94753968e+01 7.16663854e+01
 5.74020455e+01 4.59768524e+01 3.68257079e+01 2.94959896e+01
 2.36251644e+01 1.89228570e+01 1.51564878e+01 1.21397696e+01
 9.72349310e+00 7.78814768e+00 6.23800970e+00 4.99640821e+00
 4.00193270e+00 3.20539569e+00 2.56739988e+00 2.05638953e+00
 1.64708970e+00 1.31925613e+00 1.05667392e+00 8.46355567e-01
 6.77898578e-01 5.42970945e-01 4.34899050e-01 3.48337577e-01
 2.79005134e-01 2.23472487e-01 1.78992952e-01 1.43366538e-01
 1.14831137e-01 9.19753677e-02 7.36687669e-02 5.90058768e-02
 4.72614602e-02 3.78546298e-02 3.03201169e-02 2.42852590e-02
 1.94515676e-02 1.55799649e-02 1.24789586e-02 9.99517057e-03
 8.00575099e-03 6.41230167e-03 5.13600944e-03 4.11374797e-03
 3.29495546e-03 2.63913385e-03 2.11384571e-03 1.69310991e-03
 1.35611656e-03 1.08619772e-03 8.70003010e-04 6.96839279e-04
 5.58141725e-04 4.47050267e-04 3.58070239e-04 2.86800625e-04
 2.29716379e-04 1.83994071e-04 1.47372244e-04 1.18039555e-04
 9.45451886e-05 7.57270956e-05 6.06545197e-05 4.85819604e-05
 3.89123002e-05 3.11672706e-05 2.49637968e-05 1.99950506e-05
 1.60152740e-05 1.28276246e-05 1.02744388e-05 8.22943421e-06
 6.59146340e-06 5.27951117e-06 4.22868739e-06 3.38701756e-06]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">Balance</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Balance&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="c1"># 변수 표준화</span>

<span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
    <span class="n">ridge</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>    
<span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100, 11)
</pre></div>
</div>
</div>
</div>
<p>각 <span class="math notranslate nohighlight">\(\lambda\)</span>값에 따라 (표준화) 추정 계수가 어떻게 달라지는지 그림으로 그린 결과가 아래 나와 있다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">coefs</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$\lambda$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Standardized Coefficients&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0ac1e8ae94c0711d8f15535d73a8c7f088cb89dd9305fdc627c8c18588431845.png" src="../_images/0ac1e8ae94c0711d8f15535d73a8c7f088cb89dd9305fdc627c8c18588431845.png" />
</div>
</div>
<p><strong>Ridge vs. OLS 테스트 오차 비교</strong></p>
<p>이제 릿지와 OLS(최소제곱)의 예측 성과를 테스트 오차로 측정해보기로 한다. 이를 위해 표본을 훈련 세트와 테스트 세트로 1/2씩 임의로 분할한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>먼저 OLS 회귀를 수행한다. OLS는 <span class="math notranslate nohighlight">\(\lambda=0\)</span>인 릿지 회귀라는 것을 기억하자. 아래 결과에서 보듯이 테스트 MSE는 10,748이다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># 훈련 데이터에 Ridge 회귀 피팅</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># 이 모델을 사용하여 테스트 데이터 예측</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span> <span class="c1"># 추정 계수 프린트</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span> <span class="c1"># 테스트 MSE 계산</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Income                -283.216086
Limit                  330.789952
Rating                 293.345189
Cards                   16.265604
Age                    -12.598182
Education               -4.211196
Gender_Female            0.662339
Student_Yes            127.095619
Married_Yes             -1.089227
Ethnicity_Asian         10.176119
Ethnicity_Caucasian      1.890813
dtype: float64
10748.84285383294
</pre></div>
</div>
</div>
</div>
<p><strong>교차검증으로 조정 파라미터 <span class="math notranslate nohighlight">\(\lambda\)</span> 선택</strong></p>
<p>동일한 훈련 데이터세트에 이번에는 릿지 회귀를 실행한다. 이를 위해서는 조정 파라미터 <span class="math notranslate nohighlight">\(\lambda\)</span>를 선택해야 하는데, 교차검증으로 최적의 <span class="math notranslate nohighlight">\(\lambda\)</span>를 찾기로 하자. 그 방법은 앞에서 만든 100개의 <span class="math notranslate nohighlight">\(\lambda\)</span>값 중에서 교차검증 오차를 가장 작게 만드는 <span class="math notranslate nohighlight">\(\lambda\)</span>를 선택하는 것이다.</p>
<p>교차검증은 <code class="docutils literal notranslate"><span class="pre">RidgeCV()</span></code> 함수를 사용하여 수행할 수 있다. 기본적으로 이 함수는 LOOCV 방식(<a class="reference internal" href="#%EB%B6%80%EB%A1%9D:-%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Cross-Validation)"><span class="xref myst">부록</span></a> 참조)으로 실행되지만 파라미터 <code class="docutils literal notranslate"><span class="pre">cv</span></code>를 사용하여 이를 변경할 수 있다(여기서는 5중 교차검증을 선택함).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridgecv</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">ridgecv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">ridgecv</span><span class="o">.</span><span class="n">alpha_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8463555674388502
</pre></div>
</div>
</div>
</div>
<p>가장 작은 교차검증 오차를 발생시키는 <span class="math notranslate nohighlight">\(\lambda\)</span>값이 0.8463임을 알수 있다. 이 <span class="math notranslate nohighlight">\(\lambda\)</span>값에 해당하는 테스트 MSE를 구해보자.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">ridgecv</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
<span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>10720.74768127418
</pre></div>
</div>
</div>
</div>
<p>앞에서 OLS 회귀의 경우 테스트 MSE가 10,748이었는데, 릿지 회귀는 테스트 MSE가 10,720으로서 추정 성과가 근소하게 개선된 것으로 나타났다.</p>
<p>마지막으로 교차검증을 통해 선택된 <span class="math notranslate nohighlight">\(\lambda\)</span>값을 사용하여 훈련 데이터 세트에 릿지 회귀 모델을 피팅한 계수 추정치를 프린트해보자. 아래 결과를 보면, 정확히 0인 계수는 하나도 없다. 즉, 릿지 회귀는 변수선택을 수행하지는 않는다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Income                -277.316218
Limit                  314.041645
Rating                 303.722287
Cards                   15.741641
Age                    -12.512098
Education               -3.827018
Gender_Female            1.082010
Student_Yes            126.126134
Married_Yes             -0.906208
Ethnicity_Asian         10.239514
Ethnicity_Caucasian      2.375923
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="lasso">
<h3>Lasso<a class="headerlink" href="#lasso" title="Link to this heading">#</a></h3>
<p>릿지 회귀에는 한 가지 명백한 단점이 있다. 변수 중 일부만 포함하는 모델을 선택하는 최량 부분집합, 전진 단계적 선택, 후진 단계적 선택 등과 달리 릿지는 주어진 <span class="math notranslate nohighlight">\(p\)</span>개 예측변수를 모두 다 사용한다는 점이다. 릿지의 페널티 항 <span class="math notranslate nohighlight">\(\lambda \sum\beta_j^2\)</span>는 계수를 0쪽으로 축소시키기는 하지만, (<span class="math notranslate nohighlight">\(\lambda \to \infty\)</span>이 아닌 한) 정확히 0으로 만들지는 않는다. 이는 예측 정확도에는 문제가 되지 않을지 몰라도 변수 개수가 상당히 많은 경우 모델 해석에 문제를 일으킬 수 있다.</p>
<p>릿지의 이러한 단점을 극복하려는 비교적 최근의 대안이 <strong>라쏘</strong>(Lasso: Least absolute shrinkage and selection operator)이다. 라쏘는 다음을 최소화시키는 회귀 계수 추정치를 <span class="math notranslate nohighlight">\(\hat\beta{^L_\lambda}\)</span>을 구하는 방식이다.</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^{n} \left( y_i- \beta_0 -\sum_{j=1}^{p}\beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^{p}|\beta_j| = {\rm RSS}+ \lambda \sum_{j=1}^{p}|\beta_j| \tag {10.3}
\]</div>
<p>식 10.2와 10.3을 비교해보면, 라쏘와 릿지의 두 추정 방식이 상당히 비슷한 것을 알 수 있다. 유일한 차이점은 릿지는 페널티 항에 <span class="math notranslate nohighlight">\(\beta_j^2\)</span>가 들어있는데 반해, 라쏘에서는 그것이 <strong>절대값</strong> <span class="math notranslate nohighlight">\(|\beta_j|\)</span>로 대체되었다는 점이다.</p>
<p>통계학 및 머신러닝에서 라쏘는 변수선택과 정규화를 모두 수행함으로써 통계 모델의 예측 정확도와 해석 가능성을 향상시키는 방법으로 평가받는다. 우리는 앞에서 Credit 데이터세트에서 적절한 <span class="math notranslate nohighlight">\(\lambda\)</span>값을 사용한 릿지가 최소제곱(OLS)보다 예측성과가 약간 더 낫다는 것을 확인했다. 이번에는 동일한 Credit 데이터세트에 대해 라쏘와 릿지를 비교해보자.</p>
<p>라쏘 모델 피팅은 <code class="docutils literal notranslate"><span class="pre">Lasso()</span></code> 함수를 사용한다. 여기에서는 <code class="docutils literal notranslate"><span class="pre">max_iter</span> <span class="pre">=</span> <span class="pre">10000</span></code>으로 설정했다. 계수 추정치를 반복적 최적화(iterative optimization) 방식으로 찾는데, 최대 반복 횟수를 10,000번으로 정한 것이다. 이것 외에는 릿지 모델을 피팅할 때와 마찬가지이다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">max_iter</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
    <span class="n">lasso</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">a</span><span class="p">)</span>
    <span class="n">lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scale</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>    

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">coefs</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$\lambda$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Standardized Coefficients&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9d998628de7b1461e9b0bf61a075a8b8265d41c4a71b2ca0a8c89e417743193d.png" src="../_images/9d998628de7b1461e9b0bf61a075a8b8265d41c4a71b2ca0a8c89e417743193d.png" />
</div>
</div>
<p>위 추정 계수 그림에서 보듯이 조정 파라미터 <span class="math notranslate nohighlight">\(\lambda\)</span>값이 커짐에 따라 일부 계수는 정확히 0이 된다.</p>
<p>이제 5중 교차검증을 수행하여 최적의 <span class="math notranslate nohighlight">\(\lambda\)</span>를 선택하고 모델을 다시 피팅한 다음, 테스트 오차를 계산한다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lassocv</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">alphas</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">)</span>
<span class="n">lassocv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">lasso</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">lassocv</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
<span class="n">lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lasso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>10703.166435003932
</pre></div>
</div>
</div>
</div>
<p>테스트 MSE가 10,703으로서 OLS(10,748)와 릿지(10,720)보다 오차가 더 작은 것으로 나타났다.</p>
<p>마지막으로 교차검증을 통해 선택한 <span class="math notranslate nohighlight">\(\lambda\)</span>값을 사용하여 훈련 데이터 세트에 라쏘 모델을 피팅한 계수 추정치를 프린트해보자. 아래 결과를 보면, 라쏘는 릿지와 달리 11개 계수 추정치 중 3개가 정확히 0이라는 것을 알 수 있다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Income                -275.276030
Limit                  312.652360
Rating                 302.921967
Cards                   14.069159
Age                    -11.186074
Education               -1.990272
Gender_Female            0.000000
Student_Yes            124.971533
Married_Yes             -0.000000
Ethnicity_Asian          7.371007
Ethnicity_Caucasian      0.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="cross-validation">
<h2>부록: 교차검증(Cross-Validation)<a class="headerlink" href="#cross-validation" title="Link to this heading">#</a></h2>
<p>앞에서 테스트 오차와 훈련 오차의 차이에 대해 설명했다. 테스트 오차는 통계적 기법을 훈련하는 데 사용되지 않은 관측에 대한 반응을 예측할 때 발생하는 평균 오차이다. 그런데 현실에서는 테스트 세트가 항상 주어지는 것은 아니다. 이에 반해 훈련 오차의 경우에는 훈련에 사용된 관측에 통계적 학습 방법을 적용하여 쉽게 계산할 수 있다. 그러나 앞에서 보았듯이 훈련 오차는 종종 테스트 오차와 상당히 다르며 특히 전자는 후자를 극적으로 과소평가할 수 있다(즉 과적합 문제).</p>
<p>테스트 오차를 직접 추정하는 데 사용할 수 있는 (매우 큰) 테스트 세트가 없는 경우, 훈련 데이터를 사용하여 이를 추정하는 기법들이 있다. 먼저 훈련 오차를 수학적으로 조정하여 테스트 오차를 <strong>간접</strong> 추정하는 방법이다. AIC, BIC 등이 그것이다. 다른 한편으로는 훈련 관측 일부를 <strong>보류</strong>해 놓은 다음 그것을 사용하여 테스트 오차를 <strong>직접</strong> 추정하는 방법이 있다. 이를 <strong>검증</strong>(validation)이라고 부른다.</p>
<p>검증에는 <strong>검증 세트</strong>(validation set) 접근방식, <strong>단일제외 교차검증</strong>(Leave-one-out CV: LOOCV) 접근방식, <strong>다중 교차검증</strong>(k-fold CV) 접근방식이 있다. 검증 세트 접근은 따로 떼어 놓은 훈련 세트의 일부를 전적으로 테스트 세트로 사용하는 방식을 말하고, “교차”검증은 훈련 세트의 일부를 “번갈아 가면서” 테스트 세트로 사용하는 방식을 말한다.</p>
<section id="id13">
<h3>검증 세트 접근방식<a class="headerlink" href="#id13" title="Link to this heading">#</a></h3>
<p><img alt="검증 세트 접근방식" src="https://raw.githubusercontent.com/pilsunchoi/images/main/10-7.png" /></p>
<ul class="simple">
<li><p>그림 출처: ISLP, FIGURE 5.1</p></li>
</ul>
<p>주어진 <span class="math notranslate nohighlight">\(n\)</span>개의 관측을 <strong>무작위로</strong> 훈련 세트(그림에서 파란색으로 표시된 것으로서 7, 22, 13번 관측이 여기에 포함됨)와 검증 세트(베이지 색으로 표시된 것으로서 91번 관측이 여기에 포함됨)로 분할한다. 훈련 세트에 통계적 학습 기법을 피팅한 다음, 검증 세트에 대해 그 성능을 평가한다.</p>
</section>
<section id="id14">
<h3>단일제외 교차검증 접근방식<a class="headerlink" href="#id14" title="Link to this heading">#</a></h3>
<p><img alt="단일제외 교차검증 접근방식" src="https://raw.githubusercontent.com/pilsunchoi/images/main/10-8.png" /></p>
<ul class="simple">
<li><p>그림 출처: ISLP, FIGURE 5.3</p></li>
</ul>
<p>주어진 <span class="math notranslate nohighlight">\(n\)</span>개의 관측을 훈련 세트(파란색으로 표시)와 검증 세트(베이지 색으로 표시)로 반복적으로 분할하는 방식으로서 첫 번째 분할에서는 1번 관측이 검증 세트이고 1번을 제외한 나머지 모든 관측이 훈련 세트에 포함되고, 두 번째 분할에서는 2번 관측이 검증 세트이고 2번을 제외한 나머지 모든 관측이 훈련 세트에 포함되는 식으로 <span class="math notranslate nohighlight">\(n\)</span>번의 분할을 계속해서 수행하는 방식이다. 테스트 오차는 <span class="math notranslate nohighlight">\(n\)</span>개의 MSE 추정치를 평균하여 추정한다.</p>
</section>
<section id="id15">
<h3>5중 교차검증 접근방식<a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<p><img alt="5중 교차검증 접근방식" src="https://raw.githubusercontent.com/pilsunchoi/images/main/10-9.png" /></p>
<ul class="simple">
<li><p>그림 출처: ISLP, FIGURE 5.5</p></li>
</ul>
<p>주어진 <span class="math notranslate nohighlight">\(n\)</span>개의 관측을 5개의 겹치지 않는 그룹으로 무작위로 분할한다. 각 1/5의 관측이 번갈아 가면서 검증 세트(베이지 색으로 표시)가 되고, 그때마다 나머지 4/5의 관측이 훈련 세트(파란색으로 표시)가 되는 방식이다. 테스트 오차는 5개의 MSE 추정치를 평균하여 추정한다.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="09_%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">9장 나이브 베이즈 분류</p>
      </div>
    </a>
    <a class="right-next"
       href="11_%EC%B6%94%EC%B2%9C_%EC%8B%9C%EC%8A%A4%ED%85%9C.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">11장 추천 시스템</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">10.1 개요</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">10.2 최량 부분집합 선택</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#credit">Credit 데이터세트 적용 예</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#best-subset-selection">Best subset selection 함수 만들기</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Credit 데이터세트 적용</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">최적 모델 선택</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">10.3 단계적 선택</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">전진 단계적 선택</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">후진 단계적 선택</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">10.4 최적 모델 선택</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">정보기준</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-q-a">ChatGPT Q&amp;A</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">검증</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-lasso">10.5 Ridge 및 Lasso</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge">Ridge 회귀</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">Credit 데이터세트 릿지 회귀 실행</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">Lasso</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">부록: 교차검증(Cross-Validation)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">검증 세트 접근방식</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">단일제외 교차검증 접근방식</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">5중 교차검증 접근방식</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 최필선 민인식
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>