
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5장 통계적 학습 &#8212; 데이터과학의 첫걸음</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/05_통계적_학습';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6장 선형 회귀" href="06_%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80.html" />
    <link rel="prev" title="4장 전자상거래 데이터 분석" href="04_%EC%A0%84%EC%9E%90%EC%83%81%EA%B1%B0%EB%9E%98_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="00_%EC%84%9C%EB%AC%B8.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="데이터과학의 첫걸음 - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="데이터과학의 첫걸음 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00_%EC%84%9C%EB%AC%B8.html">
                    데이터과학의 첫걸음: 시작하며
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0.html">1장 파이썬 시작하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EC%BD%94%EB%94%A9_%EA%B8%B0%EC%B4%88.html">2장 파이썬 코딩 기초</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_%EC%9D%80%ED%96%89_%ED%85%94%EB%A0%88%EB%A7%88%EC%BC%80%ED%8C%85_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html">3장 은행 텔레마케팅 데이터 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_%EC%A0%84%EC%9E%90%EC%83%81%EA%B1%B0%EB%9E%98_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html">4장 전자상거래 데이터 분석</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5장 통계적 학습</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80.html">6장 선형 회귀</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EB%B6%84%EB%A5%98.html">7장 로지스틱 회귀를 이용한 분류</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_KNN%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EB%B6%84%EB%A5%98.html">8장 KNN 분류</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98.html">9장 나이브 베이즈 분류</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_%EB%B3%80%EC%88%98%EC%84%A0%ED%83%9D_%EB%B0%8F_%EC%A0%95%EA%B7%9C%ED%99%94.html">10장 변수선택 및 정규화</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_%EC%B6%94%EC%B2%9C_%EC%8B%9C%EC%8A%A4%ED%85%9C.html">11장 추천 시스템</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%EB%A7%8C%EB%93%A4%EA%B8%B0.html">12장 결정 트리 만들기</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_%ED%8A%B8%EB%A6%AC_%EA%B8%B0%EB%B0%98_%EB%AA%A8%ED%98%95.html">13장 트리 기반 모형</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_%EC%84%9C%ED%8F%AC%ED%8A%B8_%EB%B2%A1%ED%84%B0_%EB%A8%B8%EC%8B%A0.html">14장 서포트 벡터 머신</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%9E%85%EB%AC%B8.html">15장 딥러닝 입문</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5%EA%B3%BC_%EC%A3%BC%EC%84%B1%EB%B6%84_%EB%B6%84%EC%84%9D.html">16장 비지도학습과 주성분 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="17_%EC%83%9D%EC%A1%B4%EB%B6%84%EC%84%9D.html">17장 생존분석</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pilsunchoi/book1" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pilsunchoi/book1/issues/new?title=Issue%20on%20page%20%2Fnotebooks/05_통계적_학습.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/05_통계적_학습.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>5장 통계적 학습</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">5.1 개념</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">통계적 학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vs">지도학습 vs. 비지도학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-q-a">ChatGPT Q&amp;A</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">데이터 사례</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">5.2 회귀 모형</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">예측</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">추론</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">추정</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">모형 유연성과 해석력의 상충 관계</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">회귀와 분류</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">5.3 모형의 정확도 평가</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mse">테스트 MSE가 중요한 이유</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">모델의 유연성과 테스트 MSE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">과적합 문제</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">편향-분산 트레이드오프</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>5장 통계적 학습<a class="headerlink" href="#id1" title="Link to this heading">#</a></h1>
<p>자료 출처: <a class="reference external" href="https://www.statlearning.com/">ISLP (An Introduction to Statistical Learning with Applications in Python)</a></p>
<section id="id2">
<h2>5.1 개념<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>어떤 제품에 대해 200개 도시별로 광고지출 금액과 판매량 데이터가 있다고 해보자. 이런 데이터를 이용하여 광고지출과 판매량 간의 관계를 분석하고자 한다. 이런 설정에서 광고지출은 <strong>입력</strong>(input)이고 판매량은 <strong>출력</strong>(output)이다. 입력변수는 일반적으로 기호 <span class="math notranslate nohighlight">\(X\)</span>로 표시한다. 가령 입력변수가 3개로서 <span class="math notranslate nohighlight">\(X_1\)</span>은 TV 광고액, <span class="math notranslate nohighlight">\(X_2\)</span>는 라디오 광고액, <span class="math notranslate nohighlight">\(X_3\)</span>은 신문 광고액이다.</p>
<p>입력변수는 예측변수(predictors), 독립변수( independent variables), <strong>특성</strong>(features) 등으로도 불린다. 출력변수(우리 예에서는 판매량)는 종종 <strong>반응</strong>(response) 또는 종속변수(dependent variable)라고 하며, 일반적으로 기호 <span class="math notranslate nohighlight">\(Y\)</span>를 사용하여 표시된다.</p>
<section id="id3">
<h3>통계적 학습<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p><strong>통계적 학습</strong>(statistical learning)은 통계적 모형(statistical model)을 통해 데이터를 이해하고 학습시키는 것을 말한다. 여기에서 학습이라는 용어는 기계학습(machine learning)과 연관돼있다. 통계적 학습은 간단히 말하면 모형 또는 기계를 통계적 방법으로 학습시키는 것이다.</p>
<p>통계적 학습을 크게 지도학습과 비지도학습으로 나눌 수 있다. <strong>지도학습</strong>(supervised learning)에서는 입력변수들이 있고 어떤 출력변수가 있다. 입력변수를 이용해서 출력변수를 추정 또는 예측하는 통계 모형을 만드는 것이 지도학습니다. 이에 반해 <strong>비지도학습</strong>(unsupervised learning)에서는 입력변수는 있지만 출력변수가 없다. 출력변수가 없음에도 불구하고 우리는 데이터로부터 어떤 관계와 구조를 알아내고자 한다.</p>
</section>
<section id="vs">
<h3>지도학습 vs. 비지도학습<a class="headerlink" href="#vs" title="Link to this heading">#</a></h3>
<p>가령 시장세분화(market segmentation)를 통해 마케팅 전략을 차별화하는 것을 생각해보자. 이를 위해서는 고객에 대한 여러 정보(변수)를 기반으로 고객을 여러 그룹으로 나누는 것이 필요하다. 이 상황에서 만약 고객별로 구매액이라든지 구매 횟수, 방문 횟수 등 어떤 반응변수를 기준으로 시장을 세분화하는 경우에는 지도학습에 속한다. 또한 회사의 매출이나 이익을 극대화하는 것을 목표로 시장을 세분화하는 경우에도 역시 지도학습이다. 이처럼 통계적 학습이 어떤 기준이나 목표 하에서 진행되는 것이 지도학습이다.</p>
<p>이에 반해 비지도학습은 어떤 기준이나 목표라고 할 만한 반응변수가 존재하지 않는 경우이다. 똑같은 시장세분화 문제를 생각해보자. 가령 아직 온라인 쇼핑몰을 오픈하지 않아서 잠재적 고객들에 대한 정보만 있고 자사 제품 구매액이나 방문 횟수 등은 지니고 있지 않다. 이런 상황에서 마케팅 전략을 수립하기 위해 잠재적 고객들을 세분화 해야 하는 상황이 바로 비지도학습이 필요한 상황이다. 측정된 변수만 가지고 고객들을 세분화하는 것이다.</p>
<p>또 다른 예로 넷플릭스의 영화 추천시스템을 생각해보자. 고객들을 수백여 개의 그룹으로 나누어 각 그룹별로 영화를 추천하는 전략을 생각해보자. 이런 경우 고객들을 <strong>군집화</strong>(clustering)함에 있어서 어떤 하나의 기준이나 목표를 찾기가 어렵다. 이처럼 어떤 기준이나 목표 없이 고객들을 비슷한 취향끼리 군집화하는 것이 비지도학습의 예이다.</p>
</section>
<section id="chatgpt-q-a">
<h3>ChatGPT Q&amp;A<a class="headerlink" href="#chatgpt-q-a" title="Link to this heading">#</a></h3>
<blockquote>
<div><p><strong>비지도학습(unsupervised learning)의 쉬운 예를 세 개만 알려줘.</strong></p>
</div></blockquote>
<hr class="docutils" />
<blockquote>
<div><p>비지도학습(unsupervised learning)은 레이블이나 명시적인 정답 없이 데이터의 숨겨진 구조나 패턴을 찾는 머신러닝의 한 방법입니다. 여기에는 주로 클러스터링, 차원 축소, 연관 규칙 학습 등이 포함됩니다. 쉬운 예를 세 가지 들어보겠습니다:</p>
<ol class="arabic simple">
<li><p><strong>고객 세분화 (Customer Segmentation) - 클러스터링</strong>:</p>
<ul class="simple">
<li><p>비지도학습의 대표적인 예로 클러스터링이 있습니다. 예를 들어, 소매업체가 고객 데이터를 분석하여 비슷한 구매 패턴이나 행동을 보이는 고객들을 그룹으로 묶을 수 있습니다. 이를 통해 각 고객 그룹에 맞는 마케팅 전략을 수립할 수 있습니다. K-평균(K-means) 알고리즘은 이러한 클러스터링에 자주 사용됩니다.</p></li>
</ul>
</li>
<li><p><strong>차원 축소 (Dimensionality Reduction) - 주성분 분석 (PCA)</strong>:</p>
<ul class="simple">
<li><p>많은 특성을 가진 데이터셋의 경우, 중요한 정보를 유지하면서 데이터의 차원을 줄이는 차원 축소 기법이 유용합니다. 주성분 분석(PCA)는 데이터의 분산을 최대한 보존하면서 고차원 데이터를 저차원으로 축소하는 방법입니다. 이를 통해 데이터 시각화나 효율적인 저장, 더 빠른 학습 과정 등에 도움을 줄 수 있습니다.</p></li>
</ul>
</li>
<li><p><strong>연관 규칙 학습 (Association Rule Learning) - 시장 바구니 분석 (Market Basket Analysis)</strong>:</p>
<ul class="simple">
<li><p>연관 규칙 학습은 데이터셋 내에서 항목 간의 흥미로운 관계를 찾는 방법입니다. 대표적인 예로, 시장 바구니 분석이 있습니다. 이는 소매점에서 고객이 함께 구매하는 상품의 패턴을 찾아내는 것을 말합니다. 예를 들어, 빵과 버터가 자주 함께 구매된다는 사실을 발견할 수 있습니다. 이러한 정보는 상품 배치, 교차 판매 전략, 재고 관리 등에 활용될 수 있습니다.</p></li>
</ul>
</li>
</ol>
<p>이러한 비지도학습 방법들은 명시적인 지도 없이도 데이터에서 유용한 통찰을 얻을 수 있게 해줍니다.</p>
</div></blockquote>
</section>
<section id="id4">
<h3>데이터 사례<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>임금 데이터</strong>: 미국 남성을 대상으로 조사한 임금(wage) 데이터를 생각해보자. 나이, 연도, 교육수준 등의 변수들이 있을 때, 이런 변수들을 입력변수로 사용해 임금이라는 출력변수를 추정 또는 예측하는 통계 모형하는 구축하는 것이 지도학습의 예이다.(그림 출처: ISLP, FIGURE 1.1)</p></li>
</ul>
<p><img alt="데이터 사례" src="https://raw.githubusercontent.com/pilsunchoi/images/main/5-1.png" /></p>
<ul class="simple">
<li><p><strong>마케팅 데이터</strong>: 현재 고객 또는 잠재 고객에 대한 인구통계적(demographic) 정보가 있다고 해보자. 이 상황에서 고객들을 특성에 따라 그룹화하여 어떤 유형의 고객이 서로 유사한지 파악하고자 한다. 이것을 군집화(clustering) 문제라고 하는데, 여기에서는 입력변수(즉 고객들의 인구통계 정보)는 있으나, 출력변수가 따로 없으며, 이것이 비지도학습의 예이다.</p></li>
</ul>
</section>
</section>
<section id="id5">
<h2>5.2 회귀 모형<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>반응(변수) <span class="math notranslate nohighlight">\(Y\)</span>가 <strong>정량적</strong>(quantitative) 변수이고, <span class="math notranslate nohighlight">\(p\)</span>개의 예측변수 <span class="math notranslate nohighlight">\(X_1, X_2,..., X_p\)</span>가 있다고 하자. 우리는 <span class="math notranslate nohighlight">\(Y\)</span>와 <span class="math notranslate nohighlight">\(X = (X_1, X_2,..., X_p)\)</span> 사이에 다음과 같은 관계가 있다고 가정한다.</p>
<div class="math notranslate nohighlight">
\[Y = f(X) + \epsilon \tag{5.1}\]</div>
<p>여기서 <span class="math notranslate nohighlight">\(f\)</span>는 우리가 모르는(unknown) 어떤 함수이며, <span class="math notranslate nohighlight">\(\epsilon\)</span>은 확률적(random) <strong>오차항</strong>(error term)으로서, <span class="math notranslate nohighlight">\(X\)</span>와 독립적(independent)이며 평균은 0이다. 위 식은 <span class="math notranslate nohighlight">\(X\)</span>가 <span class="math notranslate nohighlight">\(Y\)</span>와 어떤 관계를 맺고 있는데, 그 관계가 확정적이지 않고, 확률적이라는 것을 의미한다. 이와 같이 설정하고 <span class="math notranslate nohighlight">\(X\)</span> 변수와 <span class="math notranslate nohighlight">\(Y\)</span> 변수 간의 관계를 추정하는 것을 <strong>회귀 모형</strong>(regression model)이라고 한다.</p>
<section id="id6">
<h3>예측<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(f\)</span>를 추정하면 다음과 같이 <span class="math notranslate nohighlight">\(Y\)</span>를 <strong>예측</strong>(prediction)하는 것이 가능하다.</p>
<div class="math notranslate nohighlight">
\[\hat Y = \hat f (X) \tag{5.2}\]</div>
<p>여기서 <span class="math notranslate nohighlight">\(\hat f\)</span>은 <span class="math notranslate nohighlight">\(f\)</span>를 추정한 것이며, <span class="math notranslate nohighlight">\(\hat Y\)</span>은 <span class="math notranslate nohighlight">\(Y\)</span>를 추정(예측)한 것이다. 정확한 <span class="math notranslate nohighlight">\(Y\)</span>를 예측하는 것은 불가능하며, 평균적인 <span class="math notranslate nohighlight">\(Y\)</span>를 예측한다. 식 5.1의 <span class="math notranslate nohighlight">\(\epsilon\)</span>은 평균이 0이라서 식 5.2에서 사라졌다.</p>
<p><span class="math notranslate nohighlight">\(Y\)</span>에 대한 예측, 즉 <span class="math notranslate nohighlight">\(\hat Y = \hat f (X) \)</span>에는 오차가 개입될 수밖에 없는데, 이 오차는 <strong>축소가능 오차</strong>(reducible  error)와 <strong>축소불가능 오차</strong>(irreducible error)로 나눌 수 있다. 일반적으로 <span class="math notranslate nohighlight">\(\hat f\)</span>은 <span class="math notranslate nohighlight">\(f\)</span>에 대한 완벽한 추정치가 아니며, 보다 나은 통계적 학습 기법을 사용하여 <span class="math notranslate nohighlight">\(f\)</span>를 추정함으로써 <span class="math notranslate nohighlight">\(\hat f\)</span>의 정확도를 잠재적으로 향상시킬 수 있기 때문에 <strong>축소시키는 것이 가능</strong>하다.</p>
<p>그러나 <span class="math notranslate nohighlight">\(f\)</span>에 대해 완벽한 추정이 가능해서 예측이 <span class="math notranslate nohighlight">\(\hat Y = \hat f (X)\)</span>이 아니라 <span class="math notranslate nohighlight">\(\hat Y = f(X)\)</span> 형식을 취하더라도 우리의 예측에는 여전히 오차가 남을 수밖에 없다. 왜냐하면 <span class="math notranslate nohighlight">\(Y\)</span>는 <span class="math notranslate nohighlight">\(f(X)\)</span>뿐만 아니라 <span class="math notranslate nohighlight">\(\epsilon\)</span>의 함수이기도 하며, 이는 정의상 <span class="math notranslate nohighlight">\(X\)</span>를 사용해 예측할 수 없기 때문이다. 따라서 우리가 <span class="math notranslate nohighlight">\(f\)</span>를 아무리 잘 추정하더라도 <span class="math notranslate nohighlight">\(\epsilon\)</span>에 의해 발생하는 오류를 줄일 수 없으며, 이것이 <strong>축소불가능</strong> 오차이다.</p>
</section>
<section id="id7">
<h3>추론<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p><strong>추론</strong>(inference)이란 <span class="math notranslate nohighlight">\(Y\)</span>가 <span class="math notranslate nohighlight">\(X_1,..., X_p\)</span>와 어떠한 관계를 맺고 있는가에 대한 분석이다. 가령 <span class="math notranslate nohighlight">\(X_1\)</span>의 변화가 <span class="math notranslate nohighlight">\(Y\)</span>에 어떠한 영향을 미치는가의 문제이다. 이와 같이 어떤 예측변수가 반응변수와 연관이 있는가, 그리고 반응변수와 개별 예측변수 간의 구체적인 관계는 무엇인가 등이 추론의 주요 이슈다.</p>
</section>
<section id="id8">
<h3>추정<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>우리의 궁극적인 목표가 예측인지, 추론인지, 또는 이 둘의 조합인지에 따라, <span class="math notranslate nohighlight">\(f\)</span>를 추정하는 방법이 달라질 수 있다. 예를 들어, <strong>선형</strong>(linear) 모형은 비교적 단순하고 해석 가능한 추론을 허용하지만, 다른 접근 방식에 비해 정확한 예측을 제공하지는 않을 수 있다. 반면 고도의 <strong>비선형</strong>(non-linear) 접근법의 경우는 <span class="math notranslate nohighlight">\(Y\)</span>에 대해 매우 정확한 예측을 제공 할 수 있지만, 해석이 더 어려워질 수 있다.</p>
<p><strong>훈련 데이터</strong></p>
<p><span class="math notranslate nohighlight">\(n\)</span>개의 데이터 포인트가 있고, 이를 이용하여 <span class="math notranslate nohighlight">\(f\)</span>를 추정할 때, 이들 <span class="math notranslate nohighlight">\(n\)</span>개의 관측(observations)을 <strong>훈련 데이터</strong>(training data)라고 한다. 우리는 이러한 훈련 관측을 사용하여 <span class="math notranslate nohighlight">\(f\)</span>를 추정하는 모형을 훈련시킨다. 우리의 목표는 훈련 데이터에 통계적 학습 기법을 적용하여 <span class="math notranslate nohighlight">\(f\)</span>를 추정하는 것이다.</p>
<p><strong>파라미터형 방법</strong></p>
<p>추정에 있어서 파라미터형(parametric) 방법은 모형 기반(model-based) 접근 방식으로서 다음과 같은 2단계 절차를 거친다.</p>
<ul class="simple">
<li><p>첫째, 먼저 <span class="math notranslate nohighlight">\(f\)</span> 함수의 형태 또는 모양에 대해 가정한다. 즉 모형을 선택한다. 가장 간단한 가정은 <span class="math notranslate nohighlight">\(f\)</span>가 <span class="math notranslate nohighlight">\(X\)</span>에 대해 선형(linear)이라는 것이다.즉 <strong>선형 모형</strong>(linear model)은 다음과 같다.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ f(X) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 +...+ \beta_p X_p \tag{5.3}\]</div>
<ul class="simple">
<li><p>둘째, 모형을 선택한 후에는 훈련 데이터를 사용하여 모형을 <strong>피팅</strong>(fitting: 적합)시키거나 훈련시키는 절차가 필요하다. 패션쇼 모델의 신체 사이즈를 잘 측정해서 의상을 몸에 잘 맞게 피팅시키는 작업에 해당한다.</p></li>
</ul>
<p>위 식 5.3과 같은 선형 모형의 경우에는 <strong>파라미터</strong>(parameter) <span class="math notranslate nohighlight">\(\beta_0, \beta_1,...,\beta_p\)</span>를 추정해야 한다. 파라미터는 특정 시스템을 정의하거나 분류하는 데 도움이 될 수 있는 제반 특징을 일컫는 말이다(Wikipedia, “<a class="reference external" href="https://en.wikipedia.org/wiki/Parameter">Parameter</a>”).</p>
<blockquote>
<div><p><strong>참고:</strong> 일반적으로 파라미터를 컴퓨터 공학 쪽에서는 “매개변수”로 번역하고, 통계학이나 계량경제학에서는 “모수”(즉, population parameter의 개념)로 번역한다. 이 두 가지 우리말 용어간에 어감 상 간극이 아주 크게 느껴지는데, 이는 파라미터 개념에 대한 접근의 차이 때문으로 여겨진다. 이 책에서는 그냥 “파라미터”로 적기로 한다.</p>
</div></blockquote>
<p>파라미터형 방법은 <span class="math notranslate nohighlight">\(f\)</span>를 추정하는 문제를 일련의 파라미터를 추정하는 것으로 단순화시킨다. 완전히 임의의 <span class="math notranslate nohighlight">\(f\)</span> 함수를 피팅하는 것보다 식 5.3과 같은 선형의 모형을 설정하고 <span class="math notranslate nohighlight">\(\beta_0, \beta_1,...,\beta_p\)</span>와 같은 일련의 파라미터를 추정하는 것이 훨씬 쉽다. 파라미터형 접근은 옷으로 말한다면 기성복인 셈이다. 형태가 갖춰진 기성복을 놓고 품이나 길이만 몸에 맞추는 식이다.</p>
<p>이처럼 <span class="math notranslate nohighlight">\(f\)</span>에 대해 파라미터형 형태를 가정하면 <span class="math notranslate nohighlight">\(f\)</span> 추정 문제를 단순화할 수 있다. 나중에 다시 나오겠지만, 식 5.3과 같은 선형 회귀 모형을 피팅하는 가장 일반적인 방법은 <strong>통상최소제곱</strong>(OLS: ordinary least squares) 방식이다.</p>
<p>한편, 파라미터형 접근 방식의 잠재적 단점은 우리가 선택한 모형이 <span class="math notranslate nohighlight">\(f\)</span>의 실제 형태와 일반적으로 일치하지 않을 것이라는 점이다. 선택한 모형이 실제 <span class="math notranslate nohighlight">\(f\)</span>와 차이가 날수록 추정은 부정확해질 것이다.</p>
<p><strong>비파라미터형 방법</strong></p>
<p>비파라미터형(non-parametric) 방법은 <span class="math notranslate nohighlight">\(f\)</span>의 함수 형태를 명시적으로 가정하지 않는다. 대신에 가능한 한 각 데이터 포인트에 가까운 추정값을 사용하여 <span class="math notranslate nohighlight">\(f\)</span>의 형태를 구축해가는 방식이다.</p>
<p>이러한 접근법이 파라미터형 접근에 비해 지니는 장점은 <span class="math notranslate nohighlight">\(f\)</span>에 대해 특정 함수 형태를 가정하지 않음으로써 <span class="math notranslate nohighlight">\(f\)</span>에 대해 훨씬 넓은 범위의 형태를 대상으로 한다는 점이다.</p>
<p>반면, 비파라미터형 접근의 단점은 <span class="math notranslate nohighlight">\(f\)</span>를 정확히 추정하기 위해서는 파라미터형 접근에 비해 훨씬 많은 수의 관측이 필요다는 점과 <strong>과적합</strong>(overfit) 가능성 등이다.</p>
</section>
<section id="id9">
<h3>모형 유연성과 해석력의 상충 관계<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<p>모형의 <strong>유연성</strong>(flexibility)과 <strong>해석력</strong>(interpretability) 간에는 상충(tradeoff) 관계가 있다. 즉, 모형의 유연성이 높아질수록(다시 말하면, <span class="math notranslate nohighlight">\(f\)</span>의 함수 형태를 복잡하게 설정할수록) 해석이 어려워진다. 반대로 모형이 단순할수록 해석력이 좋아진다.</p>
<p>가장 유연성이 낮은 모형에 속하는 선형 모형의 경우에는 <span class="math notranslate nohighlight">\(Y\)</span>가 <span class="math notranslate nohighlight">\(X_1,..., X_p\)</span>와 어떤 관계를 맺고 있는지가 분명하다. 가령 <span class="math notranslate nohighlight">\(X_1\)</span>의 변화가 <span class="math notranslate nohighlight">\(Y\)</span>에 미치는 영향의 크기는 <span class="math notranslate nohighlight">\(X_1\)</span>의 계수인 <span class="math notranslate nohighlight">\(\beta_1\)</span>이다. 하지만 모형의 유연성이 높아질수록 이런 관계가 단순하지 않고 복잡해진다. 스플라인(spline) 모형이나 부스팅(boosting) 방법 등은 <span class="math notranslate nohighlight">\(f\)</span> 추정이 복잡하여 예측변수와 반응변수 간의 관계 역시 복잡해진다.</p>
</section>
<section id="id10">
<h3>회귀와 분류<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>변수는 크게 <strong>정량적</strong>(quantitative) 변수와 <strong>정성적</strong>(qualitative) 변수 두 가지로 나눌 수 있다. 정성적 변수를 범주형(categorical) 변수라고도 한다.</p>
<p>정량적 변수는 숫자 값을 갖는다. 예를 들어 사람의 나이, 키, 소득, 그리고 집값이나 주가 등이 있다. 이에 반해 정성적 변수는 숫자가 아니라 범주를 나타내는 값을 갖는다. 정성적 변수의 예로는 성별(남성, 여성), 구매한 제품 브랜드(브랜드 A, B, C), 채무 불이행 여부(예, 아니요) 등이다.</p>
<p>반응변수가 정량적인 경우를 <strong>회귀</strong>(regression) 문제라고 부르고, 정성적 반응과 관련된 문제를 <strong>분류</strong>(classification) 문제라고 한다. 양자의 구별이 명확하지 않는 경우도 있다. 가령 <strong>로지스틱 회귀</strong>(logistic regression)는 회귀 분석의 형태지만, 반응변수가 정성적인 경우로서 분류의 문제에 속한다.</p>
</section>
</section>
<section id="id11">
<h2>5.3 모형의 정확도 평가<a class="headerlink" href="#id11" title="Link to this heading">#</a></h2>
<p>어떤 모형을 주어진 데이터에 피팅시켰다고 하자. 이때 피팅의 적합도(goodness of fit)를 평가하는 방법은 해당 모형에 의해 예측된 반응값이 실제 반응값과 얼마나 차이가 나는지, 즉 <strong>오차</strong>(error)의 크기를 보는 것이다.</p>
<p>회귀 설정에서 모형의 정확도를 평가하는 데 사용되는 지표 중의 하나는 다음의 <strong>평균제곱오차</strong>(MSE: mean squared error)이다.</p>
<div class="math notranslate nohighlight">
\[
{\rm MSE} = \frac{1}{n} \sum_{i=1}^n \left( y_i - \hat f (x_i) \right)^2 \tag{5.4}
\]</div>
<p>여기서 <span class="math notranslate nohighlight">\(y_i\)</span>는 <span class="math notranslate nohighlight">\(i\)</span>번째 반응의 실제값이고, <span class="math notranslate nohighlight">\(\hat f(x_i)\)</span>는 <span class="math notranslate nohighlight">\(i\)</span>번째 반응의 예측(추정)값이다. 이 식에서 알 수 있듯이 MSE는 모형에 의해 예측(추정)된 반응값이 실제 반응값과 평균적으로 얼마나 차이가 나는지를 계산한 것이다.</p>
<p>모형을 훈련 데이터에 피팅시켰을 때의 MSE를 “<strong>훈련 MSE</strong>”라 하고, 테스트 데이터에 피팅시켰을 때의 MSE를 “<strong>테스트 MSE</strong>”라 한다. <strong>테스트 데이터</strong>(test data)는 모형을 훈련시키는 데 전혀 사용되지 않은 데이터를 말한다. 우리에게 중요한 것은 훈련 MSE가 아니라 테스트 MSE이다. 아무리 훈련 MSE가 좋아도 테스트 MSE가 나쁘면 좋은 모형이라 할 수 없다.</p>
<section id="mse">
<h3>테스트 MSE가 중요한 이유<a class="headerlink" href="#mse" title="Link to this heading">#</a></h3>
<p>훈련 데이터가 아니라 테스트 데이터에 대한 예측에 관심이 있는 이유는 무엇일까? 가령 지금까지의 주가를 이용해 미래의 주식 가격을 예측하는 알고리즘을 개발하는 데 관심이 있다고 해보자. 우리는 지난 6개월 동안의 주식 수익률을 사용해 주가 예측 모델을 만들 수 있다. 그런데 우리는 이 모델이 지난주 주가를 얼마나 잘 예측하는지는 별로 신경쓰지 않는다. 대신 내일의 가격이나 다음 달 주가를 얼마나 잘 예측하는지에 관심이 있다.</p>
<p>또 다른 예로, 우리가 여러 환자에 대한 임상 측정값(예: 체중, 혈압, 키, 나이, 질병의 가족력)과 각 환자에게 당뇨병이 있는지 여부에 대한 정보가 있다고 하자. 이러한 임상 측정을 기반으로 당뇨병 위험을 예측하는 통계적 학습 방법을 훈련시킬 수 있다. 우리는 이런 예측 모델을 사용해 새로운 환자의 당뇨병 위험을 정확하게 예측하기를 원하지, 이 모델을 만드는 데 사용된 환자의 당뇨병 위험에 대해서는 그다지 관심이 없다. 왜냐하면 이들에 대해서는 누가 당뇨병 환자인지 이미 알고 있기 때문이다.</p>
<p>수학적으로 표현하면, 우리는 통계적 학습 기법을 훈련 관측 <span class="math notranslate nohighlight">\(\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}\)</span>에 적용하여 <span class="math notranslate nohighlight">\(\hat f\)</span>에 대한 추정치를 얻는다. 그런 다음, 예측값 <span class="math notranslate nohighlight">\(\hat f(x_1), \hat f(x_2),..., \hat f(x_n)\)</span>을 계산한다. 만약 이것들이 <span class="math notranslate nohighlight">\(y_1, y_2,..., y_n\)</span>과 유사할 경우, 위 식 5.4로 주어진 훈련 MSE는 작다.</p>
<p>그러나 정작 우리가 알고 싶은 것은 <span class="math notranslate nohighlight">\(\hat f(x_i)\)</span>가 <span class="math notranslate nohighlight">\(y_i\)</span>와 유사한지 여부가 아니다. 그것보다는 통계적 학습 방법을 훈련하는 데 사용되지 않은 테스트 관측 <span class="math notranslate nohighlight">\((x_0,y_0)\)</span>에 대한 예측값 <span class="math notranslate nohighlight">\(\hat f(x_0)\)</span>이 <span class="math notranslate nohighlight">\(y_0\)</span>와 얼마나 유사한지가 중요하다. 우리는 여러 모델 중에서 훈련 MSE가 가장 낮은 모델이 아니라 테스트 MSE가 가장 낮은 모델을 선택하기를 원한다. 즉, 테스트 MSE(보다 정확히 표현하면, 테스트 관측 <span class="math notranslate nohighlight">\((x_0,y_0)\)</span>에 대한 평균제곱예측오차)를 다음과 같은 식으로 계산할 수 있는데, 이 값이 가장 작은 모델을 선택하기를 원한다.</p>
<div class="math notranslate nohighlight">
\[{\rm Ave} \left(y_0 - \hat f(x_0)\right)^2 \tag{5.5}\]</div>
<p>이 테스트 MSE를 최소화하는 모델을 어떤 식으로 찾는 것이 좋을까? 경우에 따라서는 테스트 데이터세트를 사용할 수 있다. 즉, 통계적 학습 방법을 훈련시키는 데 사용되지 않은 관측 세트를 이용하는 것이다. 이런 테스트 관측에 대해  식 5.5를 평가하여 테스트 MSE가 가장 작은 모델을 선택하는 것이다.</p>
<p>그러나 테스트 관측이 따로 주어지지 않는 경우에는 어떻게 할까? 이 경우 그냥 훈련 MSE(식 5.4)를 최소화하는 모델을 선택하는 것을 생각할 수 있다. 그러나 이 전략에는 근본적인 문제가 있다. 훈련 MSE가 낮다고 해서 테스트 MSE도 낮다는 보장이 없기 때문이다. 현실적으로 많은 통계적 방법이 훈련 세트 MSE를 최소화하는 방식으로 계수를 추정하는데, 이 경우 훈련 MSE는 매우 작을 수 있지만 테스트 MSE는 아주 큰 경우가 있다.</p>
</section>
<section id="id12">
<h3>모델의 유연성과 테스트 MSE<a class="headerlink" href="#id12" title="Link to this heading">#</a></h3>
<p>그림 5.1은 훈련 오차와 테스트 오차가 많이 다를 수 있다는 것을 간단한 실험으로 보여준다. 원래 앞의 식 5.1에서 우리는 <span class="math notranslate nohighlight">\(f\)</span> 함수의 진짜 형태를 알지 못하고 주어진 데이터를 이용해 단지 추정만 할 수 있을 뿐이다. 그런데 여기서는 우리가 실제 <span class="math notranslate nohighlight">\(f\)</span>를 알고 있다고 가정하고, 거꾸로 거기에서 데이터를 발생시켜 <span class="math notranslate nohighlight">\(f\)</span>를 추정하는 실험을 해보자.(이런 식의 작업을 시뮬레이션이라고 한다.)</p>
<p>그림 5.1의 왼쪽 패널에서 검은색 굵은 곡선이 (이 시뮬레이션에서 사용할) <span class="math notranslate nohighlight">\(f\)</span> 함수의 <strong>실제</strong>(true) 형태이다. 먼저 이 진짜 함수를 이용해 관측(작은 동그라미)들을 생성시킨다. 그리고 모델의 유연성(flexibility) 수준을 증가시켜가면서 <span class="math notranslate nohighlight">\(f\)</span>를 추정한다.</p>
<p>그림 5.1에서 오렌지색, 하늘색, 녹색 선이 이렇게 해서 얻은 세 가지 추정 결과다. 오렌지색 선은 유연성이 가장 낮은 <strong>선형 회귀</strong> 피팅이다. 그리고 하늘색과 녹색 선은 <strong>평활 스플라인</strong>(smoothing spline)이란 이름의 함수를 피팅한 것이다. 평활 스플라인 중에서는 굴곡이 더 심한 녹색 선이 하늘색 선에 비해 유연성이 더 높다. 그림을 보면, 유연성이 높은 모델일수록 피팅된 곡선이 데이터 포인트에 더 가깝다는 것을 알 수 있다. 그런데 유연성이 가장 높은 녹색 선의 경우 데이터와 가장 잘 매치되기는 하지만, 너무 굴곡이 심해 실제 <span class="math notranslate nohighlight">\(f\)</span>(즉, 검은색 선)와는 잘 맞지 않다는 것을 알 수 있다.</p>
<p><strong>모델의 유연성과 훈련 MSE의 관계</strong></p>
<p>이제 그림 5.1의 오른쪽 패널을 보자. 여기에서는 다양한 유연성 또는 자유도(degrees of freedom)를 지닌 평활 스플라인을 데이터에 피팅시켜 얻은 MSE를 표시한 것이다. 자유도 값이 크다는 것은 모델의 유연성이 높다는 것을 의미한다. 왼쪽 패널에서는 단지 세 가지 종류의 유연성(즉, 자유도)을 가진 모델만 피팅시켰는데, 오른쪽 패널에 나온 곡선은 자유도를 2부터 시작해 30 이상까지 연속적으로 높여가면서 아주 많은 모델을 피팅시킨 결과를 그린 것이다. 실제의 <span class="math notranslate nohighlight">\(f\)</span>에서 훈련 데이터세트를 여러 번 발생시켜 각 모델에 대해 반복적으로 MSE를 구한 다음, 그것들을 평균한 값이다. 회색 선은 훈련 MSE, 그리고 빨간색 선은 테스트 MSE이다.</p>
<p>이 오른쪽 패널에서 오렌지색, 하늘색, 녹색의 사각형 점은 왼쪽 패널에 나와 있는 해당 곡선의 자유도를 지닌 모델의 MSE를 나타낸다. 굴곡이 심한 곡선일수록 자유도가 높고, 직선에 가까울수록 자유도가 낮은데, 직선인 선형 회귀는 자유도가 2로서 가장 낮다. 그림의 결과를 보면, 모델의 유연성이 높을수록 훈련 MSE는 지속적으로 낮아지는 것을 알 수 있다. 이 예에서는 실제 <span class="math notranslate nohighlight">\(f\)</span>가 비선형이기 때문에 선형 피팅(오렌지색)은 <span class="math notranslate nohighlight">\(f\)</span>를 제대로 추정할 만큼 충분히 유연하지 않다. 왼쪽 패널의 세 가지 곡선 중 녹색 선이 가장 유연하여 세 가지 방법 중에서 훈련 MSE가 가장 낮다.</p>
<p><strong>그림 5.1.</strong> 왼쪽: 검은색 굵은 곡선이 실제 <span class="math notranslate nohighlight">\(f\)</span>이고, 여기에서 시뮬레이트된 데이터 포인트가 작은 동그라미로 표시돼 있다. 데이터를 이용해 <span class="math notranslate nohighlight">\(f\)</span>를 추정한 세 가지 결과가 나와 있는데, 선형 회귀 피팅(오렌지색)과 두 개의 평활 스플라인 피팅(하늘색 및 녹색)이다. 오른쪽: 훈련 MSE(회색), 테스트 MSE(빨간색), 테스트 MSE 최소값(점선)이 나와 있다. 세 가지 색깔로 된 사각형 점은 왼쪽 패널에 표시된 세 가지 피팅에 대한 훈련 및 테스트 MSE를 나타낸다.</p>
<p><img alt="시뮬레이션 1" src="https://raw.githubusercontent.com/pilsunchoi/images/main/5-2.png" /></p>
<ul class="simple">
<li><p>그림 출처: ISLP, FIGURE 2.9</p></li>
</ul>
<p>이 예에서 우리는 실제 함수 <span class="math notranslate nohighlight">\(f\)</span>를 알고 있으므로 모형의 유연성을 높여가면서 테스트 세트를 발생시켜 테스트 MSE를 계산할 수 있다. 테스트 MSE는 그림 5.1의 오른쪽 패널에서 빨간색 선으로 표시돼있다. 테스트 MSE는 훈련 MSE와 마찬가지로  유연성이 높아짐에 따라 처음에는 감소한다. 그러나 훈련 MSE와 달리 테스트 MSE는 어느 시점부터 다시 증가하기 시작한다. 결과적으로 오렌지색 및 녹색 모델은 모두 테스트 MSE가 높으며, 하늘색 모델이 테스트 MSE를 최소화한다. 시각적으로도 하늘색 모델이 그림 5.1의 왼쪽 패널에서 <span class="math notranslate nohighlight">\(f\)</span>를 가장 잘 추정하는 것으로 보인다. 이 점을 감안할 때, 하늘색 모델이 다른 두 모델에 비해 테스트 MSE가 가장 낮은 것이 놀라운 일은 아니다. 우리는 실제 <span class="math notranslate nohighlight">\(f\)</span>를 알고 있으므로 앞에서 설명한 “축소불가능 오차”도 알 수 있는데, 그림 5.1 오른쪽 패널에서 수평 점선이 그것이다. 이는 달성 가능한 가장 낮은 테스트 MSE에 해당한다. 따라서 하늘색 선으로 표시된 평활 스플라인 모델은 최적에 가깝다.</p>
</section>
<section id="id13">
<h3>과적합 문제<a class="headerlink" href="#id13" title="Link to this heading">#</a></h3>
<p>그림 5.1의 오른쪽 패널에서 우리는 통계적 학습 기법의 유연성이 증가함에 따라 훈련 MSE는 일관되게, 즉 단조(monotonic) 감소한다는 것과 테스트 MSE는 U자 형태라는 것을 볼 수 있다. 이것은 데이터세트, 그리고 통계 기법에 상관없이 성립하는 통계적 학습의 기본 속성이다. 즉, 모델의 유연성이 높아지면 훈련 MSE는 작아지지만, 테스트 MSE는 오히려 커질 수 있는 것이다.</p>
<p>주어진 통계적 학습 기법이 훈련 MSE는 작지만 테스트 MSE는 클 때 우리는 해당 모델이 데이터에 <strong>과적합</strong>(overfit) 되었다고 말한다. 모델이 훈련 데이터에(만) 지나치게 피팅이 잘 되어 정작 중요한 테스트 데이터에 대해서는 예측력이 떨어지는 것이다. 이것은 모델이 훈련 데이터에서 어떤 패턴을 너무 열심히 찾기 때문에 발생하며, 그 결과 미지의 함수 <span class="math notranslate nohighlight">\(f\)</span>의 실제 속성이 아니라 임의로 발생한 일부 패턴을 찾는 데 초점을 맞추는 것으로 귀결될 수 있다. 훈련 데이터에 과적합되면, 해당 기법이 훈련 데이터에서 찾은 패턴이 테스트 데이터에는 존재하지 않을 가능성이 높기 때문에 테스트 MSE가 매우 커질 수 있다. 현실적으로 대부분의 통계적 학습 기법이 직접 또는 간접적으로 훈련 MSE를 최소화하려고 하기 때문에 테스트 MSE가 훈련 MSE보다 거의 항상 클 것으로 예상할 수 있다.</p>
<p><strong>실제 함수가 거의 선형인 경우</strong></p>
<p>그림 5.2는 또 다른 예로서 실제 함수 <span class="math notranslate nohighlight">\(f\)</span>가 <strong>거의 선형</strong>이라는 것이 앞의 그림 5.1과 다른 점이다. 우리는 여기에서도 모델 유연성이 높아짐에 따라 훈련 MSE는 단조 감소하고 테스트 MSE는 U자 형태라는 것을 볼 수 있다. 그런데 실제 함수의 곡선 정도가 매우 낮기 때문에 테스트 MSE가 처음에만 약간 감소하다가 그 다음부터는 계속 커진다. 유연성이 가장 낮은 최소제곱 피팅(오렌지색)이 유연성이 매우 높은 녹색 모델보다 훨씬 성과가 좋다.</p>
<p><strong>그림 5.2.</strong> 세부 내용은 그림 5.1과 같으며 선형에 훨씬 가까운 <span class="math notranslate nohighlight">\(f\)</span>를 사용했다. 이 설정에서는 선형 회귀가 데이터에 매우 적합하다.</p>
<p><img alt="시뮬레이션 2" src="https://raw.githubusercontent.com/pilsunchoi/images/main/5-3.png" /></p>
<ul class="simple">
<li><p>그림 출처: ISLP, FIGURE 2.10</p></li>
</ul>
<p><strong>실제 함수가 매우 비선형인 경우</strong></p>
<p>마지막으로 그림 5.3은 실제 함수 <span class="math notranslate nohighlight">\(f\)</span>가 <strong>매우 비선형</strong>인 예를 보여준다. 훈련 및 테스트 MSE 곡선은 전체적으로 봤을 때, 여전히 동일한 패턴을 보인다. 즉, 모델 유연성이 높아짐에 따라 훈련 MSE는 단조 감소하고 테스트 MSE는 전체적으로 U자 형태이다. 하지만 실제 <span class="math notranslate nohighlight">\(f\)</span>가 매우 비선형적이어서 테스트 MSE가 처음에 급격히 감소한 다음 아주 약간씩만 증가한다. 여기에서는 유연성이 가장 낮은 최소제곱 피팅(오렌지색)의 성과가 가장 좋지 않다.</p>
<p><strong>그림 5.3.</strong> 세부 내용은 그림 5.1과 같으며 선형과는 아주 거리가 먼 <span class="math notranslate nohighlight">\(f\)</span>를 사용했다. 이 설정에서 선형 회귀는 데이터에 매우 적합하지 않다.</p>
<p><img alt="시뮬레이션 3" src="https://raw.githubusercontent.com/pilsunchoi/images/main/5-4.png" /></p>
<ul class="simple">
<li><p>그림 출처: ISLP, FIGURE 2.11</p></li>
</ul>
</section>
<section id="id14">
<h3>편향-분산 트레이드오프<a class="headerlink" href="#id14" title="Link to this heading">#</a></h3>
<p>앞의 그림 5.1-5.3에서 우리는 테스트 MSE 곡선이 U자 모양이라는 것을 알았다. 이것은 통계적 학습 방법의 <strong>편향</strong>(bias)과 <strong>분산</strong>(variance)이라는 두 가지 경합적 속성 때문이다.</p>
<p>통계적 학습 방법의 분산과 편향은 무엇을 의미하는가? 우선 <strong>분산</strong>은 훈련 세트가 달라짐에 따라 <span class="math notranslate nohighlight">\(\hat f\)</span>가 어느 정도나 바뀌는지를 나타낸다. 사실 훈련 세트에 따라 <span class="math notranslate nohighlight">\(\hat f\)</span>가 달라지는 것은 당연하나, 이상적으로는 <span class="math notranslate nohighlight">\(f\)</span>에 대한 추정이 훈련 세트 간에 너무 많이 달라지지 않아야 한다. 그러나 분산이 높은 추정 기법의 경우에는 훈련 데이터의 작은 변화가 <span class="math notranslate nohighlight">\(\hat f\)</span>를 크게 변화시킬 수 있다.</p>
<p>일반적으로 유연한 모델일수록 분산이 더 높은 경향이 있다. 앞의 그림 5.1 왼쪽 패널의 녹색 선과 오렌지색 선을 생각해보자. 유연한 녹색 선은 관측들에 매우 가깝다. 따라서 주어진 데이터 포인트 중 하나를 변경하면 <span class="math notranslate nohighlight">\(\hat f\)</span> 모양이 상당히 바뀔 수 있으며, 그렇기 때문에 분산이 높다. 대조적으로, 오렌지색의 최소제곱 선은 상대적으로 유연하지 않기 때문에 분산이 낮다. 관측을 한두 개 이동시켜도 선의 위치가 크게 바뀔 가능성이 없기 때문이다.</p>
<p>한편, <strong>편향</strong>은 극도로 복잡할 수 있는 실생활의 문제를 훨씬 단순한 모델로 근사함으로써 발생하는 오차를 의미한다. 예를 들어, 선형 회귀는 <span class="math notranslate nohighlight">\(Y\)</span>와 <span class="math notranslate nohighlight">\(X_1,X_2,...,X_p\)</span> 사이에 선형 관계가 있다고 가정한다. 실생활의 문제가 실제로 그렇게 단순한 선형 관계를 가질 가능성은 거의 없으므로 선형 회귀를 수행하면 의심할 여지없이 <span class="math notranslate nohighlight">\(f\)</span> 추정에 어느 정도 편향이 발생한다.</p>
<p>그림 5.3의 경우, 실제 <span class="math notranslate nohighlight">\(f\)</span>가 비선형이므로 아무리 많은 훈련 관측이 제공되더라도 선형 회귀를 사용하여 이를 정확하게 추정하는 것은 불가능하다. 즉, 선형 회귀는 이 예에서 높은 편향을 초래한다. 물론 그림 5.2에서는 실제 <span class="math notranslate nohighlight">\(f\)</span>가 선형에 매우 가깝기 때문에 충분한 데이터가 주어지면 선형 회귀가 <span class="math notranslate nohighlight">\(f\)</span>를 거의 정확히 추정할 것이다. 일반적으로 더 유연한 통계적 방법일수록 편향이 작다.</p>
<p>결국 유연한 방법을 사용할수록 분산은 커지고 편향은 작아지는 경향이 있다. 이 두 개의 상대적인 변화에 의해 테스트 MSE가 증가하는지 아니면 감소하는지가 결정된다. 통계적 기법의 유연성이 증가하면 초기에는 분산이 커지는 것에 비해 편향이 더 빨리 작아지는 경향이 있다. 결과적으로 테스트 MSE가 감소한다. 그러나 유연성의 증가는 어느 시점부터 편향에 거의 영향을 미치지 않지만 분산을 크게 증가시키기 시작한다. 이 국면에서는 테스트 MSE가 증가하게 된다. 그림 5.1-5.3의 오른쪽 패널에서 테스트 MSE를 보면, 형태는 달라도 전체적으로 처음에는 작아지다가 점차 다시 커지는 패턴을 보이고 있다.</p>
<p>테스트 MSE에 있어서 편향과 분산 간의 상충 관계를 <strong>편향-분산 트레이드오프</strong>(bias-variance trade-off)라고 한다. 통계적 학습 방법이 테스트 세트에서 좋은 성능을 갖기 위해서는 편향이 작아야 할 뿐만 아니라 분산도 작아야 한다. 그러나 현실적으로는 편향은 매우 낮지만 분산이 높은 방법(예: 훈련 관측을 모두 통과하는 곡선을 그리는 방법)이거나 분산은 매우 낮지만 편향이 높은 방법(예: 데이터를 수평선으로 피팅하는 방법)을 얻을 가능성이 높기 때문에 이를 “트레이드오프”라고 한다.</p>
<p>어느 분석에서든 분산과 편향 둘 다 낮은 방법을 찾는 것이 가장 중요한 목표 중 하나이다. 이 책에서 우리는 유연성이 아주 높아 본질적으로 편향을 제거할 수 있는 기법들도 배우지만, 이런 기법들이 선형 회귀와 같은 훨씬 간단한 방법보다 더 높은 예측력을 보장하지는 않는다.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="04_%EC%A0%84%EC%9E%90%EC%83%81%EA%B1%B0%EB%9E%98_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">4장 전자상거래 데이터 분석</p>
      </div>
    </a>
    <a class="right-next"
       href="06_%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">6장 선형 회귀</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">5.1 개념</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">통계적 학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vs">지도학습 vs. 비지도학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-q-a">ChatGPT Q&amp;A</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">데이터 사례</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">5.2 회귀 모형</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">예측</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">추론</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">추정</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">모형 유연성과 해석력의 상충 관계</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">회귀와 분류</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">5.3 모형의 정확도 평가</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mse">테스트 MSE가 중요한 이유</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">모델의 유연성과 테스트 MSE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">과적합 문제</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">편향-분산 트레이드오프</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 최필선 민인식
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>